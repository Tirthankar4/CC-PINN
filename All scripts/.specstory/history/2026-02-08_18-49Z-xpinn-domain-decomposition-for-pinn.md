<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 5c7c166e-9f8c-422b-80b1-cb6197c99623 (2026-02-08 18:49Z) -->

# XPINN domain decomposition for PINN (2026-02-08 18:49Z)

_**User**_

The current codebase has a methods folder, which is currently empty. This was made for future additions to improve PINN performance. One idea proposed to me was using XPINN style domain decomposition. I tried it eariler with a half ready script, but due to various issues, the implementation was not good, preventing proper experimentation. I do want to properly implement XPINN style domain decomposition though, and test it thoroughly. But before making up any codes or scripts, have a look at the codebase, and give a high level description of how would someone go about implementing that. No codes necessary, just a qualitative discussion to plan well for future

---

_**Agent (model claude-4.6-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user wants me to explore their codebase to understand its structure and then provide a high-level qualitative discussion about how to implement XPINN-style domain decomposition for their PINN (Physics-Informed Neural Network) project. Let me first explore the codebase to understand the current architecture.</details></think>

---

Let me explore the codebase to understand the current architecture before discussing the XPINN implementation plan.

---

<tool-use data-tool-type="unknown" data-tool-name="task_v2">
<details>
<summary>Tool use: **task_v2**</summary>


Parameters:

```json
{
  "description": "Explore PINN codebase structure",
  "prompt": "Explore the codebase at c:\\Users\\tirth\\Documents\\Projects\\GRINN\\Power spectrum perturbations thoroughly. I need to understand:\n\n1. The overall directory structure (all folders and key files)\n2. How the PINN model is defined and trained (architecture, loss function, training loop)\n3. How the domain/problem is set up (spatial and temporal domains, initial/boundary conditions)\n4. How data flows through the system (config -&gt; model -&gt; training -&gt; evaluation)\n5. What the &#96;methods&#96; folder is (currently empty) and how it might plug in\n6. What physics equations are being solved (the PDE residuals)\n7. How the current training pipeline works end-to-end\n\nPlease read key files like config.py, any model definition files, training scripts, and utility files. Return a comprehensive summary of the architecture, the physics being solved, and how training/evaluation works.",
  "subagentType": "explore",
  "model": "composer-1",
  "name": "explore"
}
```
Additional data:

```json
{
  "status": "success",
  "composerData": "{\"_v\":13,\"composerId\":\"task-toolu_01P5YZ6grPQVvzJUd3G8rUf2\",\"richText\":\"\",\"hasLoaded\":true,\"text\":\"\",\"fullConversationHeadersOnly\":[{\"bubbleId\":\"14570353-65d3-4f23-962b-72cb17d581dd\",\"type\":2},{\"bubbleId\":\"865b39ec-49cc-4e21-a445-e65618ec08bd\",\"type\":2},{\"bubbleId\":\"2dc7fc89-7905-4c02-b279-3ccda342577a\",\"type\":2},{\"bubbleId\":\"f8ee58ee-8101-4e62-ba01-cd1b4c8898f2\",\"type\":2},{\"bubbleId\":\"c9256496-1f54-479b-bbbe-22d173536814\",\"type\":2},{\"bubbleId\":\"394b99e2-2f42-4b0d-b19e-6703a7aa7369\",\"type\":2},{\"bubbleId\":\"b8f3a2f6-333c-44ac-9961-671ae1053f7b\",\"type\":2},{\"bubbleId\":\"78e73cef-4a9a-4e45-ad02-5732d955f44d\",\"type\":2},{\"bubbleId\":\"e792fd93-f5d0-45d2-8255-d0c06be4af5a\",\"type\":2},{\"bubbleId\":\"757df35f-7c88-435f-b15d-cb6f9630a589\",\"type\":2},{\"bubbleId\":\"2d3c9f3b-1f90-46fc-868d-f43cab571fe0\",\"type\":2},{\"bubbleId\":\"f82f4338-5560-4e53-bf25-e0861ef87ffb\",\"type\":2},{\"bubbleId\":\"340a5959-c0c1-4bc9-ad99-164614dcd2b8\",\"type\":2},{\"bubbleId\":\"39f80e3f-c455-47b9-92ef-33e1516fc5f8\",\"type\":2},{\"bubbleId\":\"1fed6519-fb12-4f63-963d-381b3a1e23bf\",\"type\":2},{\"bubbleId\":\"c466cb41-dcc1-406e-b870-a57a6275e291\",\"type\":2},{\"bubbleId\":\"fec2f57b-d770-46d9-9e58-b2634185bbbb\",\"type\":2},{\"bubbleId\":\"af9d1e09-3b07-4e4f-a9e2-13344459ab7c\",\"type\":2},{\"bubbleId\":\"db51e550-7f74-4420-898d-c9e75c5ec41e\",\"type\":2},{\"bubbleId\":\"6497f34b-862f-4275-bb4a-4f73f1579f7a\",\"type\":2},{\"bubbleId\":\"af0cbb02-9df6-4771-b507-1174802de390\",\"type\":2},{\"bubbleId\":\"6c591aa0-e21a-4337-98c4-50524218e1c5\",\"type\":2},{\"bubbleId\":\"3fe2bc75-68fe-4c5f-979f-f88348af3870\",\"type\":2}],\"conversationMap\":{\"14570353-65d3-4f23-962b-72cb17d581dd\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"4d7c8e2b-c622-497c-ae02-3934f31e924e\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.713Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nExploring the codebase. Starting with the directory structure, then examining key files.\\\\n\\\"}\",\"865b39ec-49cc-4e21-a445-e65618ec08bd\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"2ea4afb1-7595-4aa2-8031-bca86656ed89\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.713Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_9fb558f0-52d7-4d9c-9323-bd3b80987f1\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_9fb558f0-52d7-4d9c-9323-bd3b80987f1\\\",\\\"status\\\":\\\"loading\\\",\\\"name\\\":\\\"list_dir_v2\\\",\\\"rawArgs\\\":\\\"{}\\\",\\\"tool\\\":39,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\"}\\\",\\\"result\\\":\\\"{}\\\"},\\\"capabilityType\\\":15}\",\"2dc7fc89-7905-4c02-b279-3ccda342577a\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"c5527c49-178f-4bf7-811e-087f36512697\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.713Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_cf78cedb-648e-44ee-a635-ad4b7939b80\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_cf78cedb-648e-44ee-a635-ad4b7939b80\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"glob_file_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.py\\\\\\\"}\\\",\\\"tool\\\":42,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directories\\\\\\\":[{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"files\\\\\\\":[{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\config.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\extract_static_plot.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\lax_mass_conservation_gpu.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Interactive.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\train.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\package_for_kaggle.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\initial_conditions.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\compare_model.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\analyze_numerical.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\__init__.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\numerical_solvers\\\\\\\\\\\\\\\\LAX_torch.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\numerical_solvers\\\\\\\\\\\\\\\\LAX.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\__init__.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\diagnose_comparison.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\compare_initial_phi.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\test_initial_conditions_3d.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\test_lax_integration.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\test_lax_solvers.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\find_good_seeds.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\fd_diagnostics.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\model_architecture.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\fft_vs_pinn.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\compare_laplacian_operators_gpu.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\compare_models_with_fd.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\numerical_solvers\\\\\\\\\\\\\\\\__init__.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\__init__.py\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\__init__.py\\\\\\\"}],\\\\\\\"totalFiles\\\\\\\":34}]}\\\"},\\\"capabilityType\\\":15}\",\"f8ee58ee-8101-4e62-ba01-cd1b4c8898f2\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"c65fb4d3-5557-4676-8a98-53e73410121b\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.713Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_9771fdfa-915a-432a-b89b-cc489296cb3\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_9771fdfa-915a-432a-b89b-cc489296cb3\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"glob_file_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.yaml\\\\\\\"}\\\",\\\"tool\\\":42,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.yaml\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directories\\\\\\\":[{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\"}]}\\\"},\\\"capabilityType\\\":15}\",\"c9256496-1f54-479b-bbbe-22d173536814\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"c5508370-966c-4876-bff3-3039622fa98e\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_6359d048-4095-4c6b-8183-89c16ac4694\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_6359d048-4095-4c6b-8183-89c16ac4694\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"glob_file_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.yml\\\\\\\"}\\\",\\\"tool\\\":42,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.yml\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directories\\\\\\\":[{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\"}]}\\\"},\\\"capabilityType\\\":15}\",\"394b99e2-2f42-4b0d-b19e-6703a7aa7369\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"383ecf81-8ea4-44bd-a5af-57408415d25e\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_f4ee76c4-e4da-4b11-8138-733bbcfc059\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_f4ee76c4-e4da-4b11-8138-733bbcfc059\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"glob_file_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.json\\\\\\\"}\\\",\\\"tool\\\":42,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.json\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directories\\\\\\\":[{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"files\\\\\\\":[{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\.project.json\\\\\\\"}],\\\\\\\"totalFiles\\\\\\\":1}]}\\\"},\\\"capabilityType\\\":15}\",\"b8f3a2f6-333c-44ac-9961-671ae1053f7b\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"12a17d58-f847-410a-befd-b8e9d0cdd2c6\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_79be03c3-45ff-48fa-a62a-017fbafb51a\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_79be03c3-45ff-48fa-a62a-017fbafb51a\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"glob_file_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.md\\\\\\\"}\\\",\\\"tool\\\":42,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"globPattern\\\\\\\":\\\\\\\"*.md\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directories\\\\\\\":[{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\",\\\\\\\"files\\\\\\\":[{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\.what-is-this.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-13Z-pinn-and-lax-solver-comparison.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-17Z-explore-project-structure-and-physics.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_14-48Z-static-image-from-3d-html-visualization.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-31_18-55Z-power-spectrum-initial-conditions-for-molecular-clouds.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_17-49Z-pinn-initial-condition-learning-setup.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_13-43Z-courant-number-configuration-for-lax-solver.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-31_19-29Z-agentic-ai-concepts-for-research-project.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-30_18-02Z-plot-and-colorbar-reversion-issue.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-26_13-05Z-multi-stage-training-code-removal.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_17-27Z-training-process-with-config-values.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_16-26Z-3d-interactive-pinn-plots-with-user-time-selection.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-58Z-pinn-batch-processing-logic.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-05Z-3d-power-spectrum-comparison-plot-verification.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-24_16-39Z-residual-heatmap-gradient-and-scale-issues.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-23_13-45Z-multi-stage-training-for-physics-informed-neural-networks.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-22_15-06Z-pinn-long-term-learning-diagnostics.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-22_13-20Z-training-diagnostics-plot-scope.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-22_13-11Z-pinn-performance-diagnostics.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_20-01Z-zmax-setting-discrepancy-in-train-py.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-50Z-transformer-architecture-for-pinn.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-45Z-grinn-paper-limitations-and-future-scope.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-20_19-10Z-pinn-3d-power-spectrum-learning-issues.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-19_17-59Z-training-diagnostics-3d-empty-plots.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-19_17-43Z-2d-system-circular-transformation.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_19-13Z-pinn-long-timescale-performance-issues.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_16-51Z-lax-solver-function-in-&#96;compare-model-py&#96;.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_13-16Z-lax-solver-torch-function-update.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_11-01Z-powershell-error-lines-1-21.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_10-55Z-training-script-organization.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_10-34Z-training-diagnostics-scripts-enabled-by-config.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_10-18Z-mlp-pinn-high-tmax-issues.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-08_17-39Z-icml-paper-latex-formatting.md\\\\\\\"},{\\\\\\\"relPath\\\\\\\":\\\\\\\"../.\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\DIAGNOSTICS_GUIDE.md\\\\\\\"}],\\\\\\\"totalFiles\\\\\\\":37}]}\\\"},\\\"capabilityType\\\":15}\",\"78e73cef-4a9a-4e45-ad02-5732d955f44d\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"5be148d2-a4c7-41bc-bcc5-9f2cd7ebdd3a\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nReading key files to understand the architecture:\\\\n\\\"}\",\"e792fd93-f5d0-45d2-8255-d0c06be4af5a\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"70a2c75d-89f8-4719-8699-988a75ff634b\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_40c9b121-5cb5-4334-aa35-f29c76673be\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_40c9b121-5cb5-4334-aa35-f29c76673be\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\config.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\config.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\config.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"import numpy as np\\\\\\\\n\\\\\\\\n# Random seed for reproducibility across all functions\\\\\\\\nRANDOM_SEED = 78\\\\\\\\n\\\\\\\\n# Perturbation selection: \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"sinusoidal\\\\\\\\\\\\\\\"\\\\\\\\nPERTURBATION_TYPE = \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nxmin = 0.0\\\\\\\\nymin = 0.0\\\\\\\\nzmin = 0.0\\\\\\\\ncs = 1.0\\\\\\\\nrho_o = 1.0\\\\\\\\nconst = 1.0\\\\\\\\nG = 1.0\\\\\\\\n\\\\\\\\n# Collocation point parameters\\\\\\\\nN_0 = 25000  # Number of initial condition points\\\\\\\\nN_r = 50000 # Number of residual/collocation points\\\\\\\\nDIMENSION = 2  # Spatial dimension\\\\\\\\n\\\\\\\\nBATCH_SIZE = 75000  # Max collocation points per mini-batch (controls peak GPU memory)\\\\\\\\nNUM_BATCHES = 1  # Mini-batches per optimizer step; gradients accumulate, memory stays constant\\\\\\\\n\\\\\\\\na = 0.1\\\\\\\\n\\\\\\\\ntmin = 0.\\\\\\\\ntmax = 3.0\\\\\\\\n\\\\\\\\nnum_neurons = 64\\\\\\\\nharmonics = 3\\\\\\\\nnum_layers = 5\\\\\\\\nDEFAULT_ACTIVATION = 'sin'  # Default activation function for PINN ('sin', 'tanh', 'relu', etc.)\\\\\\\\n\\\\\\\\nwave = 7.0\\\\\\\\nk = 2 * np.pi / wave\\\\\\\\nnum_of_waves = 2.0\\\\\\\\n\\\\\\\\niteration_adam_2D = 1001\\\\\\\\niteration_lbgfs_2D = 201\\\\\\\\n\\\\\\\\nIC_WEIGHT = 1.0\\\\\\\\n\\\\\\\\n# Extra collocation points at t=0 to strongly enforce Poisson equation\\\\\\\\nN_POISSON_IC = 0  # Number of extra spatial points at t=0 for Poisson\\\\\\\\nPOISSON_IC_WEIGHT = 0.0  # Weight for Poisson residual at t=0\\\\\\\\nPHI_MEAN_CONSTRAINT_WEIGHT = 0.0  # Weight for mean(Ï†)=0 constraint at t=0 (fixes gauge freedom)\\\\\\\\n\\\\\\\\n# Output/snapshot controls\\\\\\\\nSAVE_STATIC_SNAPSHOTS = False\\\\\\\\n\\\\\\\\n# Directory to save snapshots; default keeps Kaggle working dir\\\\\\\\nSNAPSHOT_DIR = \\\\\\\\\\\\\\\"/kaggle/working/\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Training diagnostics\\\\\\\\nENABLE_TRAINING_DIAGNOSTICS = True  # Enable automatic training diagnostics plots and logging\\\\\\\\n\\\\\\\\n# Density growth comparison plot controls\\\\\\\\nPLOT_DENSITY_GROWTH = False\\\\\\\\nGROWTH_PLOT_TMAX = 4.0\\\\\\\\nGROWTH_PLOT_DT = 0.1\\\\\\\\n\\\\\\\\nKX = k\\\\\\\\nKY = 0\\\\\\\\nKZ = 0\\\\\\\\nTIMES_1D = [2.5, 3.0, 3.5] # 1D cross-section times to plot (used for sinusoidal panel plots\\\\\\\\nFD_N_1D = 300  # Grid points for 1D LAX (when used)\\\\\\\\nFD_N_2D = 300  # Grid points per dimension for 2D LAX\\\\\\\\nFD_N_3D = 300  # Grid points per dimension for 3D LAX slices\\\\\\\\nFD_NU_SINUSOIDAL = 0.5  # Courant number for LAX solver\\\\\\\\nSLICE_Y = 0.6  # Default y slice for visualization/cross-sections\\\\\\\\nSLICE_Z = 0.6  # Default z slice for visualization/cross-sections\\\\\\\\nSHOW_LINEAR_THEORY = False\\\\\\\\n\\\\\\\\n# 3D Interactive plot settings\\\\\\\\nENABLE_INTERACTIVE_3D = True  # Toggle interactive 3D plot generation\\\\\\\\nINTERACTIVE_3D_RESOLUTION = 50  # Grid resolution per axis\\\\\\\\nINTERACTIVE_3D_TIME_STEPS = 10  # Number of time steps in slider\\\\\\\\n\\\\\\\\n# Power spectrum parameters\\\\\\\\nN_GRID = 400  # Grid resolution for power spectrum generation\\\\\\\\nN_GRID_3D = 400 #In 3D\\\\\\\\nFD_NU_POWER = 0.25  # Courant number for LAX solver\\\\\\\\nPOWER_EXPONENT = -4  # Power spectrum exponent\\\\\\\\nSTARTUP_DT = 0.01 # Time offset after which PDE is enforced (ICs remain at t=0)\\\\\\\\nUSE_PARAMETERIZATION = \\\\\\\\\\\\\\\"exponential\\\\\\\\\\\\\\\"  # Options: \\\\\\\\\\\\\\\"exponential\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"linear\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"none\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":86}\\\"},\\\"capabilityType\\\":15}\",\"757df35f-7c88-435f-b15d-cb6f9630a589\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"20c04e68-2c4f-400b-92d3-7fb5436b06eb\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_b5135995-eef8-4446-90d3-c57e9f47875\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_b5135995-eef8-4446-90d3-c57e9f47875\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\train.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\train.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\train.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":482}\\\"},\\\"capabilityType\\\":15}\",\"2d3c9f3b-1f90-46fc-868d-f43cab571fe0\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"22b7b634-35b9-4d6d-8a3b-a28088ae6f61\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_f552e7ec-00f0-4e12-a691-ba8480bdcfb\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_f552e7ec-00f0-4e12-a691-ba8480bdcfb\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\model_architecture.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\model_architecture.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\model_architecture.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"import numpy as np\\\\\\\\n\\\\\\\\nimport torch\\\\\\\\nimport torch.nn as nn\\\\\\\\n#from torch.autograd import Variable\\\\\\\\nfrom config import rho_o, num_neurons, num_layers, PERTURBATION_TYPE, DEFAULT_ACTIVATION, STARTUP_DT, USE_PARAMETERIZATION\\\\\\\\n\\\\\\\\nclass Sin(nn.Module):\\\\\\\\n    def forward(self, input):\\\\\\\\n        return torch.sin(input)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef get_activation(activation_type):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Factory function to create activation function instances.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        activation_type: String identifier ('sin', 'tanh', 'relu', 'elu')\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        nn.Module activation function\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    activation_type = activation_type.lower()\\\\\\\\n    if activation_type == 'sin':\\\\\\\\n        return Sin()\\\\\\\\n    elif activation_type == 'tanh':\\\\\\\\n        return nn.Tanh()\\\\\\\\n    elif activation_type == 'relu':\\\\\\\\n        return nn.ReLU()\\\\\\\\n    elif activation_type == 'elu':\\\\\\\\n        return nn.ELU()\\\\\\\\n    else:\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\\"Unknown activation type: {activation_type}. Choose from 'sin', 'tanh', 'relu', 'elu'.\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nclass PINN(nn.Module):\\\\\\\\n    def __init__(self, num_neurons=num_neurons, num_layers=num_layers, n_harmonics=1, activation_type=DEFAULT_ACTIVATION):\\\\\\\\n        super(PINN, self).__init__()\\\\\\\\n        self.num_neurons = num_neurons\\\\\\\\n        self.n_harmonics = n_harmonics\\\\\\\\n        self.num_layers = max(2, int(num_layers))  # total Linear layers including output\\\\\\\\n        self.activation_type = activation_type\\\\\\\\n        \\\\\\\\n        # Domain extents for periodic embeddings (set via set_domain)\\\\\\\\n        self.xmin = None\\\\\\\\n        self.xmax = None\\\\\\\\n        self.ymin = None\\\\\\\\n        self.ymax = None\\\\\\\\n        self.zmin = None\\\\\\\\n        self.zmax = None\\\\\\\\n    \\\\\\\\n    # Helper to build a branch with dynamic depth\\\\\\\\n        def _make_branch(in_dim, out_dim):\\\\\\\\n            layers = []\\\\\\\\n            # First layer\\\\\\\\n            layers.append(nn.Linear(in_dim, self.num_neurons))\\\\\\\\n            # Hidden layers: total linear layers = self.num_layers; we already added 1; \\\\\\\\n            # add (self.num_layers - 2) hidden Linear blocks with activations after each\\\\\\\\n            for _ in range(self.num_layers - 2):\\\\\\\\n                layers.append(get_activation(self.activation_type))\\\\\\\\n                layers.append(nn.Linear(self.num_neurons, self.num_neurons))\\\\\\\\n            # Activation before output if there is at least one hidden block\\\\\\\\n            if self.num_layers &gt; 2:\\\\\\\\n                layers.append(get_activation(self.activation_type))\\\\\\\\n            # Output layer\\\\\\\\n            layers.append(nn.Linear(self.num_neurons, out_dim))\\\\\\\\n            return nn.Sequential(*layers)\\\\\\\\n\\\\\\\\n    # 1D branch (periodic x features + t)\\\\\\\\n        in_dim_1d = 2*self.n_harmonics + 1\\\\\\\\n        self.branch_1d = _make_branch(in_dim_1d, 3)\\\\\\\\n        \\\\\\\\n    # 2D branch (periodic x,y features + t)\\\\\\\\n        in_dim_2d = 4*self.n_harmonics + 1\\\\\\\\n        self.branch_2d = _make_branch(in_dim_2d, 4)\\\\\\\\n        \\\\\\\\n    # 3D branch (periodic x,y,z features + t)\\\\\\\\n        in_dim_3d = 6*self.n_harmonics + 1\\\\\\\\n        self.branch_3d = _make_branch(in_dim_3d, 5)\\\\\\\\n\\\\\\\\n\\\\\\\\n    def set_domain(self, rmin, rmax, dimension):\\\\\\\\n        # rmin/rmax exclude time; follow ASTPN usage\\\\\\\\n        if dimension &gt;= 1:\\\\\\\\n            self.xmin, self.xmax = float(rmin[0]), float(rmax[0])\\\\\\\\n        if dimension &gt;= 2:\\\\\\\\n            self.ymin, self.ymax = float(rmin[1]), float(rmax[1])\\\\\\\\n        if dimension &gt;= 3:\\\\\\\\n            self.zmin, self.zmax = float(rmin[2]), float(rmax[2])\\\\\\\\n\\\\\\\\n    def _periodic_features(self, u, umin, umax):\\\\\\\\n        # u is [N,1]\\\\\\\\n        L = umax - umin\\\\\\\\n        theta = 2*np.pi*(u - umin)/L\\\\\\\\n        features = []\\\\\\\\n\\\\\\\\n        for k in range(1, self.n_harmonics+1):\\\\\\\\n            \\\\\\\\n            scale = 1.0 / np.sqrt(k)\\\\\\\\n\\\\\\\\n            features.append(scale * torch.sin(k*theta))\\\\\\\\n            features.append(scale * torch.cos(k*theta))\\\\\\\\n\\\\\\\\n        return torch.cat(features, dim=1) if len(features) &gt; 0 else u\\\\\\\\n\\\\\\\\n    def _prepare_coordinate_features(self, X):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Prepare periodic features for all spatial coordinates.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            X: List of coordinates [x, ...spatial..., t]\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Tuple (features, t_tensor, dimension)\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        x, t = X[0], X[-1]\\\\\\\\n        x = x.unsqueeze(-1) if x.dim() == 1 else x\\\\\\\\n        t = t.unsqueeze(-1) if t.dim() == 1 else t\\\\\\\\n        dimension = len(X)\\\\\\\\n        \\\\\\\\n        if dimension == 2:\\\\\\\\n            if self.xmin is None or self.xmax is None:\\\\\\\\n                raise RuntimeError(\\\\\\\\\\\\\\\"Domain not set: call net.set_domain for dimension=1\\\\\\\\\\\\\\\")\\\\\\\\n            x_feat = self._periodic_features(x, self.xmin, self.xmax)\\\\\\\\n            features = torch.cat([x_feat, t], dim=1)\\\\\\\\n        \\\\\\\\n        elif dimension == 3:\\\\\\\\n            if self.xmin is None or self.xmax is None or self.ymin is None or self.ymax is None:\\\\\\\\n                raise RuntimeError(\\\\\\\\\\\\\\\"Domain not set: call net.set_domain for dimension=2\\\\\\\\\\\\\\\")\\\\\\\\n            y = X[1].unsqueeze(-1) if X[1].dim() == 1 else X[1]\\\\\\\\n            x_feat = self._periodic_features(x, self.xmin, self.xmax)\\\\\\\\n            y_feat = self._periodic_features(y, self.ymin, self.ymax)\\\\\\\\n            features = torch.cat([x_feat, y_feat, t], dim=1)\\\\\\\\n        \\\\\\\\n        elif dimension == 4:\\\\\\\\n            if (self.xmin is None or self.xmax is None or\\\\\\\\n                self.ymin is None or self.ymax is None or\\\\\\\\n                self.zmin is None or self.zmax is None):\\\\\\\\n                raise RuntimeError(\\\\\\\\\\\\\\\"Domain not set: call net.set_domain for dimension=3\\\\\\\\\\\\\\\")\\\\\\\\n            y = X[1].unsqueeze(-1) if X[1].dim() == 1 else X[1]\\\\\\\\n            z = X[2].unsqueeze(-1) if X[2].dim() == 1 else X[2]\\\\\\\\n            x_feat = self._periodic_features(x, self.xmin, self.xmax)\\\\\\\\n            y_feat = self._periodic_features(y, self.ymin, self.ymax)\\\\\\\\n            z_feat = self._periodic_features(z, self.zmin, self.zmax)\\\\\\\\n            features = torch.cat([x_feat, y_feat, z_feat, t], dim=1)\\\\\\\\n        \\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Expected len(X) in [2, 3, 4] but got {dimension}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        return features, t, dimension\\\\\\\\n    \\\\\\\\n    def _apply_density_constraint(self, outputs, t):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Apply hard density constraint with causality enforcement for power spectrum perturbations.\\\\\\\\n        \\\\\\\\n        For power spectrum (non-sinusoidal):\\\\\\\\n        - For t &lt; STARTUP_DT: Density is frozen at Ïâ‚€ (causality - information hasn't propagated)\\\\\\\\n        - For t &gt;= STARTUP_DT: Density evolves based on USE_PARAMETERIZATION:\\\\\\\\n          * \\\\\\\\\\\\\\\"exponential\\\\\\\\\\\\\\\": Ï = Ïâ‚€ Ã— exp(clamp((t - STARTUP_DT) Ã— ÏÌ‚, -10, 10))\\\\\\\\n            (ensures strictly positive density)\\\\\\\\n          * \\\\\\\\\\\\\\\"linear\\\\\\\\\\\\\\\": Ï = Ïâ‚€ + (t - STARTUP_DT) Ã— ÏÌ‚\\\\\\\\n            (linear growth from initial condition)\\\\\\\\n          * \\\\\\\\\\\\\\\"none\\\\\\\\\\\\\\\": Ï = ÏÌ‚\\\\\\\\n            (direct network prediction, no transformation)\\\\\\\\n        \\\\\\\\n        The causality constraint (STARTUP_DT) is enforced for all parameterizations.\\\\\\\\n        This ensures density remains at initial conditions until information has had time\\\\\\\\n        to propagate across the domain (finite signal speed).\\\\\\\\n        \\\\\\\\n        For sinusoidal: No constraint (returns as-is).\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            outputs: Raw network outputs [ÏÌ‚, vx, vy?, vz?, phi]\\\\\\\\n            t: Time tensor\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Modified outputs with density constraint applied [Ï, vx, vy?, vz?, phi]\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if str(PERTURBATION_TYPE).lower() == \\\\\\\\\\\\\\\"sinusoidal\\\\\\\\\\\\\\\":\\\\\\\\n            return outputs\\\\\\\\n        \\\\\\\\n        # Causality constraint for power spectrum:\\\\\\\\n        # Density frozen at Ïâ‚€ for t &lt; STARTUP_DT (information propagation delay)\\\\\\\\n        rho_hat = outputs[:, 0:1]\\\\\\\\n        other = outputs[:, 1:]\\\\\\\\n        \\\\\\\\n        # Create mask for causality: 1.0 where t &gt;= STARTUP_DT, 0.0 where t &lt; STARTUP_DT\\\\\\\\n        causal_mask = (t &gt;= STARTUP_DT).float()\\\\\\\\n        \\\\\\\\n        # Effective time: zero for t &lt; STARTUP_DT, (t - STARTUP_DT) for t &gt;= STARTUP_DT\\\\\\\\n        t_effective = torch.clamp(t - STARTUP_DT, min=0.0)\\\\\\\\n        \\\\\\\\n        # Apply parameterization based on config\\\\\\\\n        parameterization = str(USE_PARAMETERIZATION).lower()\\\\\\\\n        \\\\\\\\n        if parameterization == \\\\\\\\\\\\\\\"exponential\\\\\\\\\\\\\\\":\\\\\\\\n            # Exponential parameterization: Ï = Ïâ‚€ * exp(t_eff * ÏÌ‚)\\\\\\\\n            # For t &lt; STARTUP_DT: t_eff = 0, so exp(0) = 1, thus Ï = Ïâ‚€\\\\\\\\n            # For t &gt;= STARTUP_DT: Ï evolves exponentially\\\\\\\\n            rho = rho_o * torch.exp(torch.clamp(t_effective * rho_hat, min=-10, max=10))\\\\\\\\n            \\\\\\\\n        elif parameterization == \\\\\\\\\\\\\\\"linear\\\\\\\\\\\\\\\":\\\\\\\\n            # Linear parameterization: Ï = Ïâ‚€ + t_eff * ÏÌ‚\\\\\\\\n            # For t &lt; STARTUP_DT: t_eff = 0, so Ï = Ïâ‚€\\\\\\\\n            # For t &gt;= STARTUP_DT: Ï grows linearly\\\\\\\\n            rho = rho_o + t_effective * rho_hat\\\\\\\\n            \\\\\\\\n        elif parameterization == \\\\\\\\\\\\\\\"none\\\\\\\\\\\\\\\":\\\\\\\\n            # No parameterization: direct prediction with causality enforcement\\\\\\\\n            # For t &lt; STARTUP_DT: Ï = Ïâ‚€ (frozen at initial condition)\\\\\\\\n            # For t &gt;= STARTUP_DT: Ï = ÏÌ‚ (network output directly)\\\\\\\\n            rho = causal_mask * rho_hat + (1 - causal_mask) * rho_o\\\\\\\\n            \\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Invalid USE_PARAMETERIZATION: '{USE_PARAMETERIZATION}'. \\\\\\\\\\\\\\\"\\\\\\\\n                           f\\\\\\\\\\\\\\\"Choose from: 'exponential', 'linear', 'none'\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        return torch.cat([rho, other], dim=1)\\\\\\\\n    \\\\\\\\n    def forward(self, X):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Forward pass of PINN.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            X: List of coordinates [x, ...spatial..., t]\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Network predictions [rho, vx, vy?, vz?, phi]\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        features, t, dimension = self._prepare_coordinate_features(X)\\\\\\\\n        \\\\\\\\n        # Select appropriate branch based on dimension\\\\\\\\n        if dimension == 2:\\\\\\\\n            outputs = self.branch_1d(features)\\\\\\\\n        elif dimension == 3:\\\\\\\\n            outputs = self.branch_2d(features)\\\\\\\\n        elif dimension == 4:\\\\\\\\n            outputs = self.branch_3d(features)\\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Unexpected dimension: {dimension}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        return self._apply_density_constraint(outputs, t)\\\\\\\\n        \\\\\\\\ndef init_weights(m):\\\\\\\\n    if isinstance(m, nn.Linear):\\\\\\\\n        torch.nn.init.xavier_uniform_(m.weight)\\\\\\\\n        m.bias.data.fill_(0.01)\\\\\\\\n\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":247}\\\"},\\\"capabilityType\\\":15}\",\"f82f4338-5560-4e53-bf25-e0861ef87ffb\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"274ad8f9-fcd0-46a3-877a-8fdaafe77cd8\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_890bbf96-ef21-4087-a78c-c284312b0c6\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_890bbf96-ef21-4087-a78c-c284312b0c6\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"from core.data_generator import col_gen\\\\\\\\nfrom core.data_generator import diff\\\\\\\\n\\\\\\\\nimport numpy as np\\\\\\\\n\\\\\\\\nimport torch\\\\\\\\nimport torch.nn as nn\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\nfrom config import cs, const, G, rho_o\\\\\\\\n\\\\\\\\nclass ASTPN(col_gen):\\\\\\\\n    \\\\\\\\n    def __init__(self, rmin=[0,0,0,0], rmax=[1,1,1,1], N_0 = 1000, N_b=1000, N_r=3000, dimension=1):\\\\\\\\n        super().__init__(rmin,rmax, N_0,0,N_r, dimension)  # N_b set to 0 due to hard constraints\\\\\\\\n        \\\\\\\\n       \\\\\\\\n        self.coord_Lx, self.coord_Rx = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=1)\\\\\\\\n        \\\\\\\\n        if dimension == 2:\\\\\\\\n            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\\n\\\\\\\\n        if dimension == 3:\\\\\\\\n            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\\n            self.coord_Lz, self.coord_Rz = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=3)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef pde_residue(colloc, net, dimension = 1):\\\\\\\\n    \\\\\\\\n    '''\\\\\\\\n    This is the main function that returns all the PDE residue\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        colloc: Collocation points\\\\\\\\n        net: Neural network\\\\\\\\n        dimension: Spatial dimension (1, 2, or 3)\\\\\\\\n    '''\\\\\\\\n    \\\\\\\\n    return pde_residue_standard(colloc, net, dimension)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef pde_residue_standard(colloc, net, dimension = 1):\\\\\\\\n    \\\\\\\\n    '''\\\\\\\\n    Standard PDE residues (network predicts rho directly)\\\\\\\\n    '''\\\\\\\\n    net_outputs = net(colloc)\\\\\\\\n    \\\\\\\\n    x = colloc[0]\\\\\\\\n    \\\\\\\\n    if dimension == 1:\\\\\\\\n        t = colloc[1]\\\\\\\\n\\\\\\\\n    elif dimension == 2:\\\\\\\\n        y = colloc[1]\\\\\\\\n        t = colloc[2]\\\\\\\\n\\\\\\\\n    elif dimension == 3:\\\\\\\\n        y = colloc[1]\\\\\\\\n        z = colloc[2]\\\\\\\\n        t = colloc[3]\\\\\\\\n    \\\\\\\\n    rho, vx = net_outputs[:,0:1], net_outputs[:,1:2]\\\\\\\\n\\\\\\\\n    if dimension == 1:\\\\\\\\n\\\\\\\\n        phi = net_outputs[:,2:3]\\\\\\\\n\\\\\\\\n        rho_t = diff(rho,t,order=1)  \\\\\\\\n        rho_x = diff(rho,x,order=1)\\\\\\\\n\\\\\\\\n        vx_t = diff(vx, t,order=1)\\\\\\\\n        vx_x = diff(vx, x,order=1)\\\\\\\\n        \\\\\\\\n        phi_x = diff(phi,x,order=1)\\\\\\\\n        phi_x_x = diff(phi,x,order=2)\\\\\\\\n\\\\\\\\n    elif dimension == 2:\\\\\\\\n\\\\\\\\n        vy = net_outputs[:,2:3]\\\\\\\\n        phi = net_outputs[:,3:4]\\\\\\\\n\\\\\\\\n        rho_t = diff(rho,t,order=1)  \\\\\\\\n        rho_x = diff(rho,x,order=1)\\\\\\\\n        rho_y = diff(rho,y,order=1)\\\\\\\\n\\\\\\\\n        vx_t = diff(vx, t,order=1)\\\\\\\\n        vy_t = diff(vy, t,order=1)\\\\\\\\n\\\\\\\\n        vx_x = diff(vx, x,order=1)\\\\\\\\n        vx_y = diff(vx, y,order=1)\\\\\\\\n        vy_x = diff(vy, x,order=1)\\\\\\\\n        vy_y = diff(vy, y,order=1)\\\\\\\\n        \\\\\\\\n        phi_x = diff(phi,x,order=1)\\\\\\\\n        phi_x_x = diff(phi,x,order=2)\\\\\\\\n\\\\\\\\n        phi_y = diff(phi,y,order=1)\\\\\\\\n        phi_y_y = diff(phi,y,order=2)\\\\\\\\n\\\\\\\\n    elif dimension == 3:\\\\\\\\n        vy = net_outputs[:,2:3]\\\\\\\\n        vz = net_outputs[:,3:4]\\\\\\\\n        phi = net_outputs[:,4:5]\\\\\\\\n\\\\\\\\n        rho_t = diff(rho,t,order=1)  \\\\\\\\n        rho_x = diff(rho,x,order=1)\\\\\\\\n        rho_y = diff(rho,y,order=1)\\\\\\\\n        rho_z = diff(rho,z,order=1)\\\\\\\\n\\\\\\\\n        vx_t = diff(vx, t,order=1)\\\\\\\\n        vy_t = diff(vy, t,order=1)\\\\\\\\n        vz_t = diff(vz, t,order=1)\\\\\\\\n\\\\\\\\n        vx_x = diff(vx, x,order=1)\\\\\\\\n        vy_x = diff(vy, x,order=1)\\\\\\\\n        vz_x = diff(vz, x,order=1)\\\\\\\\n\\\\\\\\n        vx_y = diff(vx, y,order=1)\\\\\\\\n        vy_y = diff(vy, y,order=1)\\\\\\\\n        vz_y = diff(vz, y,order=1)\\\\\\\\n        \\\\\\\\n        vx_z = diff(vx, z,order=1)\\\\\\\\n        vy_z = diff(vy, z,order=1)\\\\\\\\n        vz_z = diff(vz, z,order=1)\\\\\\\\n        \\\\\\\\n        phi_x = diff(phi,x,order=1)\\\\\\\\n        phi_x_x = diff(phi,x,order=2)\\\\\\\\n\\\\\\\\n        phi_y = diff(phi,y,order=1)\\\\\\\\n        phi_y_y = diff(phi,y,order=2)\\\\\\\\n    \\\\\\\\n        phi_z = diff(phi,z,order=1)\\\\\\\\n        phi_z_z = diff(phi,z,order=2)\\\\\\\\n\\\\\\\\n    \\\\\\\\n    ## The residues from the equations\\\\\\\\n\\\\\\\\n    if dimension == 1:\\\\\\\\n        rho_r = rho_t + vx * rho_x + rho * vx_x\\\\\\\\n        vx_r = rho*vx_t + rho*(vx*vx_x) + cs*cs*rho_x +rho*phi_x\\\\\\\\n        phi_r = phi_x_x - const*(rho - rho_o)\\\\\\\\n\\\\\\\\n        return rho_r, vx_r, phi_r\\\\\\\\n\\\\\\\\n    elif dimension == 2:\\\\\\\\n        rho_r = rho_t + vx * rho_x + vy * rho_y + rho * vx_x + rho * vy_y\\\\\\\\n        vx_r = rho*vx_t + rho*(vx*vx_x + vy*vx_y) + cs*cs*rho_x + rho*phi_x\\\\\\\\n        vy_r = rho*vy_t + rho*(vy*vy_y + vx*vy_x) + cs*cs*rho_y + rho*phi_y\\\\\\\\n        phi_r = phi_x_x + phi_y_y - const*(rho - rho_o)\\\\\\\\n\\\\\\\\n        return rho_r, vx_r, vy_r, phi_r\\\\\\\\n    \\\\\\\\n    elif dimension == 3:\\\\\\\\n        rho_r = rho_t + vx * rho_x + rho * vx_x + vy *rho_y + rho * vy_y + vz *rho_z +rho * vz_z\\\\\\\\n        vx_r = rho*vx_t + rho*(vx*vx_x + vy*vx_y+vz*vx_z) + cs*cs*rho_x + rho*phi_x\\\\\\\\n        vy_r = rho*vy_t + rho*(vy*vy_y + vx*vy_x+vz*vy_z) + cs*cs*rho_y + rho*phi_y\\\\\\\\n        vz_r = rho*vz_t + rho*(vz*vz_z + vx*vz_x+vy*vz_y) + cs*cs*rho_z + rho*phi_z\\\\\\\\n        phi_r = phi_x_x + phi_y_y +phi_z_z - const*(rho - rho_o)\\\\\\\\n        \\\\\\\\n        return rho_r,vx_r,vy_r,vz_r,phi_r\\\\\\\\n\\\\\\\\n\\\\\\\\ndef poisson_residue_only(colloc, net, dimension=1):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Compute only the Poisson equation residual: âˆ‡Â²Ï† - const*(Ï - Ïâ‚€)\\\\\\\\n    \\\\\\\\n    This is used for extra enforcement at t=0 (Option 3: Pure ML approach).\\\\\\\\n    By evaluating Poisson residual on many t=0 points, we ensure Ï† is \\\\\\\\n    correctly initialized without using numerical solvers.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        colloc: Collocation points [x, (y), (z), t]\\\\\\\\n        net: Neural network\\\\\\\\n        dimension: Spatial dimension (1, 2, or 3)\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        phi_r: Poisson residual tensor\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    net_outputs = net(colloc)\\\\\\\\n    \\\\\\\\n    x = colloc[0]\\\\\\\\n    \\\\\\\\n    if dimension == 1:\\\\\\\\n        t = colloc[1]\\\\\\\\n        phi = net_outputs[:, 2:3]\\\\\\\\n        phi_x_x = diff(phi, x, order=2)\\\\\\\\n        \\\\\\\\n    elif dimension == 2:\\\\\\\\n        y = colloc[1]\\\\\\\\n        t = colloc[2]\\\\\\\\n        phi = net_outputs[:, 3:4]\\\\\\\\n        phi_x_x = diff(phi, x, order=2)\\\\\\\\n        phi_y_y = diff(phi, y, order=2)\\\\\\\\n        \\\\\\\\n    elif dimension == 3:\\\\\\\\n        y = colloc[1]\\\\\\\\n        z = colloc[2]\\\\\\\\n        t = colloc[3]\\\\\\\\n        phi = net_outputs[:, 4:5]\\\\\\\\n        phi_x_x = diff(phi, x, order=2)\\\\\\\\n        phi_y_y = diff(phi, y, order=2)\\\\\\\\n        phi_z_z = diff(phi, z, order=2)\\\\\\\\n    \\\\\\\\n    # Get density\\\\\\\\n    rho = net_outputs[:, 0:1]\\\\\\\\n    \\\\\\\\n    # Compute Poisson residual\\\\\\\\n    if dimension == 1:\\\\\\\\n        phi_r = phi_x_x - const*(rho - rho_o)\\\\\\\\n    elif dimension == 2:\\\\\\\\n        phi_r = phi_x_x + phi_y_y - const*(rho - rho_o)\\\\\\\\n    elif dimension == 3:\\\\\\\\n        phi_r = phi_x_x + phi_y_y + phi_z_z - const*(rho - rho_o)\\\\\\\\n    \\\\\\\\n    return phi_r\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":215}\\\"},\\\"capabilityType\\\":15}\",\"340a5959-c0c1-4bc9-ad99-164614dcd2b8\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"3dedec8e-7635-4500-b14d-fd51f7acde33\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_53e600a7-3dc6-4862-b3a7-725b51290c9\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_53e600a7-3dc6-4862-b3a7-725b51290c9\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":443}\\\"},\\\"capabilityType\\\":15}\",\"39f80e3f-c455-47b9-92ef-33e1516fc5f8\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"0e911951-1e1f-4549-976c-a202aca27836\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_6312fb1a-3c46-454e-a31e-02aa449c7d5\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_6312fb1a-3c46-454e-a31e-02aa449c7d5\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":701}\\\"},\\\"capabilityType\\\":15}\",\"1fed6519-fb12-4f63-963d-381b3a1e23bf\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"0c7a2174-7dd8-4af2-a7bf-0eb433bf82b4\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_0fa5c751-6f78-4097-946b-8584ac76ab2\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_0fa5c751-6f78-4097-946b-8584ac76ab2\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":422}\\\"},\\\"capabilityType\\\":15}\",\"c466cb41-dcc1-406e-b870-a57a6275e291\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"fc8190ed-ac03-4812-b0d4-59e3c80c024e\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_17292af2-cfd8-42c7-beaa-8205bad8956\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_17292af2-cfd8-42c7-beaa-8205bad8956\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\initial_conditions.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\initial_conditions.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\initial_conditions.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":573}\\\"},\\\"capabilityType\\\":15}\",\"fec2f57b-d770-46d9-9e58-b2634185bbbb\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"ef7f289f-30f2-4dee-92f9-383639df57f7\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_94b49274-3adb-4682-aa8d-c40986d61d5\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_94b49274-3adb-4682-aa8d-c40986d61d5\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"# Enhancement methods for PINN training\\\\\\\\n\\\\\\\\n\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":3}\\\"},\\\"capabilityType\\\":15}\",\"af9d1e09-3b07-4e4f-a9e2-13344459ab7c\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"42bcea2b-ba3a-4ac5-b8d6-b8f88429f8df\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nReviewing additional files for context:\\\\n\\\"}\",\"db51e550-7f74-4420-898d-c9e75c5ec41e\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"73ed6de6-8664-4134-a13c-6bc14d92d9dc\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_449c7b4b-561b-4c22-9f20-bbf714c479f\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_449c7b4b-561b-4c22-9f20-bbf714c479f\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\",\\\\\\\"offset\\\\\\\":1,\\\\\\\"limit\\\\\\\":100}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\",\\\\\\\"offset\\\\\\\":1,\\\\\\\"limit\\\\\\\":100,\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"import os\\\\\\\\nimport numpy as np\\\\\\\\nimport torch\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nfrom matplotlib.gridspec import GridSpec\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TrainingDiagnostics:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Comprehensive diagnostics for PINN performance analysis.\\\\\\\\n    \\\\\\\\n    TWO DIAGNOSTIC MODES:\\\\\\\\n    \\\\\\\\n    1. LONG-TERM EVOLUTION MODE (2D, 3D sinusoidal, 3D power spectrum at t&gt;0)\\\\\\\\n       Focus: Why does PINN fail at long times?\\\\\\\\n       Generates 6 diagnostic plots:\\\\\\\\n         - Training diagnostics: Loss convergence and balance\\\\\\\\n         - PDE residual evolution: When/where/which equations fail\\\\\\\\n         - Conservation violations: Mass and momentum drift\\\\\\\\n         - Temporal error accumulation: How errors compound over time\\\\\\\\n         - Spectral bias analysis: Frequency damping and mode evolution\\\\\\\\n         - Solution stability: Detecting unphysical behavior\\\\\\\\n    \\\\\\\\n    2. IC FITTING MODE (3D power spectrum only)\\\\\\\\n       Focus: Why can't PINN fit complex initial conditions?\\\\\\\\n       Generates 5 diagnostic plots:\\\\\\\\n         - Training diagnostics: Loss convergence with IC component breakdown\\\\\\\\n         - IC spatial comparison: Predicted vs true IC fields\\\\\\\\n         - IC power spectrum: Scale-by-scale fit quality\\\\\\\\n         - IC component convergence: Which component fails to converge\\\\\\\\n         - IC metrics summary: Correlation and RMS error statistics\\\\\\\\n    \\\\\\\\n    All diagnostics run automatically when ENABLE_TRAINING_DIAGNOSTICS = True\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, save_dir='./diagnostics/', dimension=2, perturbation_type='power_spectrum'):\\\\\\\\n        self.save_dir = save_dir\\\\\\\\n        self.dimension = dimension\\\\\\\\n        self.perturbation_type = str(perturbation_type).lower()\\\\\\\\n        self.is_3d_power_spectrum = (dimension == 3 and self.perturbation_type == 'power_spectrum')\\\\\\\\n        \\\\\\\\n        os.makedirs(save_dir, exist_ok=True)\\\\\\\\n\\\\\\\\n        # Storage for tracking metrics over iterations\\\\\\\\n        self.history = {\\\\\\\\n            'iteration': [],\\\\\\\\n            'total_loss': [],\\\\\\\\n            'pde_loss': [],\\\\\\\\n            'ic_loss': [],\\\\\\\\n            'mean_rho': [],\\\\\\\\n            'max_rho': [],\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        # Additional tracking for 3D power spectrum IC diagnostics\\\\\\\\n        if self.is_3d_power_spectrum:\\\\\\\\n            self.history.update({\\\\\\\\n                'ic_rho': [],\\\\\\\\n                'ic_vx': [],\\\\\\\\n                'ic_vy': [],\\\\\\\\n                'ic_vz': [],\\\\\\\\n                'ic_phi': [],\\\\\\\\n            })\\\\\\\\n\\\\\\\\n    def _prepare_inputs(self, geomtime_col):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Normalize collocation inputs to the model's expected format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if isinstance(geomtime_col, (list, tuple)):\\\\\\\\n            return geomtime_col\\\\\\\\n        # Single tensor [N, D] -&gt; list of [N,1]\\\\\\\\n        return [geomtime_col[:, i:i+1] for i in range(geomtime_col.shape[1])]\\\\\\\\n\\\\\\\\n    def log_iteration(self, iteration, model, loss_dict, geomtime_col, ic_component_losses=None):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Call this every N iterations during training.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            iteration: Current iteration number\\\\\\\\n            model: PINN model\\\\\\\\n            loss_dict: Dictionary with 'total', 'PDE', 'IC' losses\\\\\\\\n            geomtime_col: Collocation points\\\\\\\\n            ic_component_losses: (Optional) Dict with component IC losses for 3D power spectrum\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.history['iteration'].append(iteration)\\\\\\\\n        self.history['total_loss'].append(float(loss_dict.get('total', np.nan)))\\\\\\\\n        self.history['pde_loss'].append(float(loss_dict.get('PDE', loss_dict.get('pde', np.nan))))\\\\\\\\n        self.history['ic_loss'].append(float(loss_dict.get('IC', loss_dict.get('ic', np.nan))))\\\\\\\\n\\\\\\\\n        # Compute diagnostics from current model state\\\\\\\\n        with torch.no_grad():\\\\\\\\n            inputs = self._prepare_inputs(geomtime_col)\\\\\\\\n            pred = model(inputs)\\\\\\\\n            # Use first channel as density/log-density proxy\\\\\\\\n            rho = pred[:, 0].detach().cpu().numpy()\\\\\\\\n\\\\\\\\n            # Density statistics\\\\\\\\n            self.history['mean_rho'].append(np.nanmean(rho))\\\\\\\\n            self.history['max_rho'].append(np.nanmax(rho))\\\\\\\\n        \\\\\\\\n        # Track component IC losses for 3D power spectrum\\\\\\\\n        if self.is_3d_power_spectrum and ic_component_losses is not None:\\\\\\\\n            self.history['ic_rho'].append(float(ic_component_losses.get('rho', np.nan)))\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":2114}\\\"},\\\"capabilityType\\\":15}\",\"6497f34b-862f-4275-bb4a-4f73f1579f7a\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"f130c442-af24-42b7-b761-acfa43cdde22\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_321b4aa7-fab3-4de9-8be8-a234c6601fa\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_321b4aa7-fab3-4de9-8be8-a234c6601fa\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\numerical_solvers\\\\\\\\\\\\\\\\LAX.py\\\\\\\",\\\\\\\"offset\\\\\\\":1,\\\\\\\"limit\\\\\\\":100}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\numerical_solvers\\\\\\\\\\\\\\\\LAX.py\\\\\\\",\\\\\\\"offset\\\\\\\":1,\\\\\\\"limit\\\\\\\":100,\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\numerical_solvers\\\\\\\\\\\\\\\\LAX.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"import numpy as np\\\\\\\\nimport os\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nimport scipy\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\nfrom typing import Optional\\\\\\\\n\\\\\\\\n## For the FFT solver\\\\\\\\n\\\\\\\\nfrom numpy.fft import fft, ifft, fft2, ifft2, fftn, ifftn\\\\\\\\n\\\\\\\\nfrom config import RANDOM_SEED, DIMENSION\\\\\\\\n\\\\\\\\n# Import wave vector components and physical constants for 2D sinusoidal perturbations\\\\\\\\ntry:\\\\\\\\n    from config import KX, KY, KZ, cs, rho_o, const, G\\\\\\\\nexcept ImportError:\\\\\\\\n    # Fallback if config not available\\\\\\\\n    KX = 2*np.pi/7.0  # Default wavelength\\\\\\\\n    KY = 0.0\\\\\\\\n    KZ = 0.0\\\\\\\\n    cs = 1.0\\\\\\\\n    rho_o = 1.0\\\\\\\\n    const = 1.0\\\\\\\\n    G = 1.0\\\\\\\\n\\\\\\\\nnp.random.seed(RANDOM_SEED)\\\\\\\\n#tf.random.set_seed(1234)\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass DomainParams:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Domain parameters for the simulation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Lx: float  # Domain size in x direction\\\\\\\\n    Ly: float  # Domain size in y direction\\\\\\\\n    nx: int  # Number of grid points in x direction\\\\\\\\n    ny: int  # Number of grid points in y direction\\\\\\\\n    Lz: Optional[float] = None  # Domain size in z direction (for 3D)\\\\\\\\n    nz: Optional[int] = None  # Number of grid points in z direction (for 3D)\\\\\\\\n    \\\\\\\\n    @property\\\\\\\\n    def dx(self) -&gt; float:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Grid spacing in x direction.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.Lx / self.nx\\\\\\\\n    \\\\\\\\n    @property\\\\\\\\n    def dy(self) -&gt; float:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Grid spacing in y direction.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.Ly / self.ny\\\\\\\\n    \\\\\\\\n    @property\\\\\\\\n    def dz(self) -&gt; Optional[float]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Grid spacing in z direction (for 3D).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.Lz / self.nz if self.Lz is not None and self.nz is not None else None\\\\\\\\n    \\\\\\\\n    @property\\\\\\\\n    def is_3d(self) -&gt; bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if this is a 3D domain.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.Lz is not None and self.nz is not None\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass SimulationParams:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Simulation parameters for the LAX solver.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    time: float  # Simulation time\\\\\\\\n    N: int  # Grid resolution (Nx = Ny = N)\\\\\\\\n    nu: float  # Courant number\\\\\\\\n    lam: float  # Wavelength\\\\\\\\n    num_of_waves: int  # Number of waves in domain\\\\\\\\n    rho_1: float  # Density perturbation amplitude\\\\\\\\n    gravity: bool = False  # Whether to include self-gravity\\\\\\\\n    isplot: Optional[bool] = None  # Whether to plot results\\\\\\\\n    comparison: Optional[bool] = None  # Whether to compare with linear theory\\\\\\\\n    animation: Optional[bool] = None  # Whether to animate\\\\\\\\n    use_velocity_ps: bool = False  # Whether to use power spectrum velocity initialization\\\\\\\\n    ps_index: float = -3.0  # Power spectrum index\\\\\\\\n    vel_rms: float = 0.02  # RMS velocity amplitude\\\\\\\\n    random_seed: Optional[int] = None  # Random seed for reproducibility\\\\\\\\n    vx0_shared: Optional[np.ndarray] = None  # Shared initial x-velocity field\\\\\\\\n    vy0_shared: Optional[np.ndarray] = None  # Shared initial y-velocity field\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass SimulationResult:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Result container for LAX solver simulations.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    dimension: int  # 1, 2, or 3\\\\\\\\n    density: np.ndarray  # Density field\\\\\\\\n    velocity_components: list  # List of velocity arrays [vx, vy, ...] or [vx, vy, vz]\\\\\\\\n    coordinates: dict  # Dict with 'x', 'y' (2D/3D), 'z' (3D) coordinate arrays\\\\\\\\n    metadata: dict  # Dict with time, iterations, rho_max, etc.\\\\\\\\n    potential: Optional[np.ndarray] = None  # Gravitational potential (if gravity=True)\\\\\\\\n    linear_theory_comparison: Optional[dict] = None  # Optional linear theory comparison data\\\\\\\\n\\\\\\\\n\\\\\\\\n# ============================================================================\\\\\\\\n# Helper Functions\\\\\\\\n# ============================================================================\\\\\\\\n\\\\\\\\ndef compute_jeans_length(c_s, rho_o, const, G):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":1888}\\\"},\\\"capabilityType\\\":15}\",\"af0cbb02-9df6-4771-b507-1174802de390\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"7bbfe1e8-6eb9-4ba0-aed2-c0c70366ed32\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_e74fa1e0-b820-466d-aefd-f003b0191ab\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_e74fa1e0-b820-466d-aefd-f003b0191ab\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"list_dir_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\visualization\\\\\\\",\\\\\\\"ignore\\\\\\\":[],\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_e74fa1e0-b820-466d-aefd-f003b0191ab\\\\\\\"}\\\",\\\"tool\\\":39,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\visualization\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directoryTreeRoot\\\\\\\":{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\visualization\\\\\\\",\\\\\\\"childrenFiles\\\\\\\":[{\\\\\\\"name\\\\\\\":\\\\\\\"__init__.py\\\\\\\"},{\\\\\\\"name\\\\\\\":\\\\\\\"Interactive.py\\\\\\\"},{\\\\\\\"name\\\\\\\":\\\\\\\"Plotting.py\\\\\\\"}],\\\\\\\"childrenWereProcessed\\\\\\\":true}}\\\"},\\\"capabilityType\\\":15}\",\"6c591aa0-e21a-4337-98c4-50524218e1c5\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"017af262-d682-48ca-bb5d-56ca64f297f4\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_4df2f766-8c9c-4332-acae-a73157b9d5b\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_4df2f766-8c9c-4332-acae-a73157b9d5b\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"class|def\\\\\\\",\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":false,\\\\\\\"headLimit\\\\\\\":50,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_4df2f766-8c9c-4332-acae-a73157b9d5b\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"class|def\\\\\\\",\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":false}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"class|def\\\\\\\",\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\"visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":13,\\\\\\\"content\\\\\\\":\\\\\\\"def _clear_cuda_cache():\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":33,\\\\\\\"content\\\\\\\":\\\\\\\"def find_max_contrast_slice(rho_volume, z_coords):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":62,\\\\\\\"content\\\\\\\":\\\\\\\"def find_max_density_slice(rho_volume, z_coords):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":86,\\\\\\\"content\\\\\\\":\\\\\\\"def analyze_z_variation(rho_volume, z_coords, t, save_dir=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":158,\\\\\\\"content\\\\\\\":\\\\\\\"def _timed_call(label, fn, *args, **kwargs):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":176,\\\\\\\"content\\\\\\\":\\\\\\\"def _get_fd_nu():\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":179,\\\\\\\"content\\\\\\\":\\\\\\\"def _build_input_list(x_tensor, t_tensor, y_tensor=None, z_tensor=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":192,\\\\\\\"content\\\\\\\":\\\\\\\"def _split_outputs(outputs):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":207,\\\\\\\"content\\\\\\\":\\\\\\\"def set_shared_velocity_fields(vx_np, vy_np, vz_np=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":221,\\\\\\\"content\\\\\\\":\\\\\\\"def _call_unified_3d_solver(time, lam, num_of_waves, rho_1, nu=None,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":232,\\\\\\\"content\\\\\\\":\\\\\\\"        nu: Courant number (defaults to config based on perturbation type)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":233,\\\\\\\"content\\\\\\\":\\\\\\\"        use_velocity_ps: Whether to use power spectrum IC (defaults to config)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":234,\\\\\\\"content\\\\\\\":\\\\\\\"        ps_index: Power spectrum index (defaults to POWER_EXPONENT)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":235,\\\\\\\"content\\\\\\\":\\\\\\\"        vel_rms: Velocity RMS amplitude (defaults to a*cs)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":236,\\\\\\\"content\\\\\\\":\\\\\\\"        random_seed: Random seed (defaults to RANDOM_SEED)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":237,\\\\\\\"content\\\\\\\":\\\\\\\"        save_times: Optional list of times to save snapshots (default: None)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":243,\\\\\\\"content\\\\\\\":\\\\\\\"    # Use config defaults if not specified\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":336,\\\\\\\"content\\\\\\\":\\\\\\\"def get_fd_default_params():\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":338,\\\\\\\"content\\\\\\\":\\\\\\\"    Get default FD parameters that match PINN training configuration.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":357,\\\\\\\"content\\\\\\\":\\\\\\\"def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":379,\\\\\\\"content\\\\\\\":\\\\\\\"def add_interface_lines(ax, xmin, xmax, ymin, ymax):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":391,\\\\\\\"content\\\\\\\":\\\\\\\"def plot_function(net, time_array, initial_params, velocity=False, isplot=False, animation=False):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":528,\\\\\\\"content\\\\\\\":\\\\\\\"def Two_D_surface_plots(net, time, initial_params, ax=None, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", fd_cache=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":641,\\\\\\\"content\\\\\\\":\\\\\\\"def create_2d_animation(net, initial_params, time_points=None, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", fps=2, save_path=None, fixed_colorbar=True, verbose=False):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":648,\\\\\\\"content\\\\\\\":\\\\\\\"        time_points: Array of time points for animation (default: 50 points from 0 to 2.0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":802,\\\\\\\"content\\\\\\\":\\\\\\\"    # Do not save the initial frame by default; animation frames and optional snapshots cover needs\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":804,\\\\\\\"content\\\\\\\":\\\\\\\"    def animate(frame):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":997,\\\\\\\"content\\\\\\\":\\\\\\\"def create_2d_surface_plots(net, initial_params, time_points=None, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", fd_cache=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1004,\\\\\\\"content\\\\\\\":\\\\\\\"        time_points: List of time points to plot (default: [0.0, 0.5, 1.0, 1.5, 2.0])\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1038,\\\\\\\"content\\\\\\\":\\\\\\\"def create_1d_comparison_plots(net, initial_params, time_array_1d=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1045,\\\\\\\"content\\\\\\\":\\\\\\\"        time_array_1d: List of time points for 1D plots (default: [0.5, 1.0, 1.5])\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1134,\\\\\\\"content\\\\\\\":\\\\\\\"        v_limu_default = 0.055\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1135,\\\\\\\"content\\\\\\\":\\\\\\\"        v_liml_default = -0.055\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1138,\\\\\\\"content\\\\\\\":\\\\\\\"        v_limu_default = 0.6\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1139,\\\\\\\"content\\\\\\\":\\\\\\\"        v_liml_default = -0.6\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1151,\\\\\\\"content\\\\\\\":\\\\\\\"        # Ensure limits are at least as wide as default, but expand if data exceeds them\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1152,\\\\\\\"content\\\\\\\":\\\\\\\"        v_liml_actual = min(v_liml_actual, v_liml_default)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1153,\\\\\\\"content\\\\\\\":\\\\\\\"        v_limu_actual = max(v_limu_actual, v_limu_default)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1155,\\\\\\\"content\\\\\\\":\\\\\\\"        v_liml_actual = v_liml_default\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1156,\\\\\\\"content\\\\\\\":\\\\\\\"        v_limu_actual = v_limu_default\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1174,\\\\\\\"content\\\\\\\":\\\\\\\"def create_growth_comparison_plot(net, initial_params, time_array_growth=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1181,\\\\\\\"content\\\\\\\":\\\\\\\"        time_array_growth: Array of time points for growth analysis (default: 10 points from 0.1 to tmax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1242,\\\\\\\"content\\\\\\\":\\\\\\\"def compute_fd_data_cache(initial_params, time_points, N=200, nu=None,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1252,\\\\\\\"content\\\\\\\":\\\\\\\"        use_velocity_ps: Whether to use velocity power spectrum (defaults to config)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1253,\\\\\\\"content\\\\\\\":\\\\\\\"        ps_index: Power spectrum index (defaults to POWER_EXPONENT)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1254,\\\\\\\"content\\\\\\\":\\\\\\\"        vel_rms: Velocity RMS amplitude (defaults to a*cs)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1255,\\\\\\\"content\\\\\\\":\\\\\\\"        random_seed: Random seed (defaults to RANDOM_SEED)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1263,\\\\\\\"content\\\\\\\":\\\\\\\"    # Use config defaults if not specified\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1434,\\\\\\\"content\\\\\\\":\\\\\\\"                class SimpleResult:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1435,\\\\\\\"content\\\\\\\":\\\\\\\"                    def __init__(self):\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":77,\\\\\\\"totalMatchedLines\\\\\\\":77,\\\\\\\"clientTruncated\\\\\\\":true}}}}}\\\"},\\\"capabilityType\\\":15}\",\"3fe2bc75-68fe-4c5f-979f-f88348af3870\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"d16cf419-fdd4-42d5-8d8e-a8d0d2cdb206\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.714Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\n## **1. Overall Directory Structure**\\\\n\\\\n&#96;&#96;&#96;\\\\nPower spectrum perturbations/\\\\nâ”œâ”€â”€ config.py                    # Central configuration file\\\\nâ”œâ”€â”€ train.py                     # Main training entry point\\\\nâ”œâ”€â”€ core/\\\\nâ”‚   â”œâ”€â”€ model_architecture.py   # PINN neural network definition\\\\nâ”‚   â”œâ”€â”€ losses.py               # PDE residual computation &amp; loss functions\\\\nâ”‚   â”œâ”€â”€ data_generator.py       # Collocation point generation\\\\nâ”‚   â””â”€â”€ initial_conditions.py    # IC functions (sinusoidal &amp; power spectrum)\\\\nâ”œâ”€â”€ training/\\\\nâ”‚   â”œâ”€â”€ trainer.py              # Training loop (Adam + L-BFGS)\\\\nâ”‚   â”œâ”€â”€ physics.py              # Closure functions &amp; batched loss computation\\\\nâ”‚   â””â”€â”€ training_diagnostics.py # Diagnostic plotting &amp; analysis\\\\nâ”œâ”€â”€ numerical_solvers/\\\\nâ”‚   â”œâ”€â”€ LAX.py                  # Finite-difference reference solver\\\\nâ”‚   â””â”€â”€ LAX_torch.py            # PyTorch version of LAX solver\\\\nâ”œâ”€â”€ visualization/\\\\nâ”‚   â”œâ”€â”€ Plotting.py             # 2D/3D visualization &amp; animations\\\\nâ”‚   â””â”€â”€ Interactive.py         # Interactive 3D HTML plots\\\\nâ”œâ”€â”€ methods/\\\\nâ”‚   â””â”€â”€ __init__.py             # Empty - placeholder for future methods\\\\nâ””â”€â”€ utilities/                  # Various diagnostic &amp; comparison scripts\\\\n&#96;&#96;&#96;\\\\n\\\\n## **2. PINN Model Architecture**\\\\n\\\\n**Location:** &#96;core/model_architecture.py&#96;\\\\n\\\\n**Architecture:**\\\\n- Multi-branch MLP with dimension-specific branches:\\\\n  - 1D: &#96;branch_1d&#96; â†’ outputs &#96;[Ï, vx, Ï†]&#96;\\\\n  - 2D: &#96;branch_2d&#96; â†’ outputs &#96;[Ï, vx, vy, Ï†]&#96;\\\\n  - 3D: &#96;branch_3d&#96; â†’ outputs &#96;[Ï, vx, vy, vz, Ï†]&#96;\\\\n- Periodic embeddings: Fourier features for spatial coordinates (sin/cos harmonics)\\\\n- Configurable depth: &#96;num_layers&#96; (default 5), &#96;num_neurons&#96; (default 64), &#96;harmonics&#96; (default 3)\\\\n- Activation: Configurable (&#96;sin&#96;, &#96;tanh&#96;, &#96;relu&#96;, &#96;elu&#96;), default &#96;sin&#96;\\\\n- Density constraint: For power spectrum perturbations, applies causality (&#96;STARTUP_DT&#96;) and parameterization (&#96;exponential&#96;, &#96;linear&#96;, or &#96;none&#96;)\\\\n\\\\n**Key features:**\\\\n- Hard periodic BCs via periodic embeddings\\\\n- Domain-aware: &#96;set_domain()&#96; configures spatial bounds for periodic features\\\\n- Density parameterization: For power spectrum, density evolves via &#96;Ï = Ïâ‚€ Ã— exp(t_eff Ã— ÏÌ‚)&#96; after &#96;STARTUP_DT&#96;\\\\n\\\\n## **3. Domain/Problem Setup**\\\\n\\\\n**Spatial domain:**\\\\n- Configurable dimensions: 1D, 2D, or 3D (via &#96;DIMENSION&#96;)\\\\n- Domain size: &#96;[xmin, xmax]&#96;, &#96;[ymin, ymax]&#96;, &#96;[zmin, zmax]&#96; computed from &#96;lam * num_of_waves&#96;\\\\n- Periodic boundaries enforced via periodic embeddings\\\\n\\\\n**Temporal domain:**\\\\n- &#96;tmin = 0.0&#96;, &#96;tmax = 3.0&#96; (configurable)\\\\n- &#96;STARTUP_DT = 0.01&#96;: Causality delay for power spectrum perturbations\\\\n\\\\n**Initial conditions:**\\\\n- Two perturbation types:\\\\n  1. Sinusoidal: &#96;Ï(x,0) = Ïâ‚€ + Ïâ‚cos(kÂ·x)&#96;, velocity from linear theory\\\\n  2. Power spectrum: &#96;Ï(x,0) = Ïâ‚€&#96; (uniform), velocity from Gaussian random field with &#96;P(k) âˆ k^(-4)&#96;\\\\n- Shared velocity fields: For power spectrum, consistent ICs between PINN and FD solver via &#96;initialize_shared_velocity_fields()&#96;\\\\n\\\\n**Boundary conditions:**\\\\n- Periodic (hard via periodic embeddings)\\\\n- No explicit BC loss (&#96;N_b = 0&#96;)\\\\n\\\\n## **4. Data Flow**\\\\n\\\\n**Configuration â†’ Model â†’ Training â†’ Evaluation:**\\\\n\\\\n1. **Config (&#96;config.py&#96;):**\\\\n   - Physical: &#96;cs&#96;, &#96;rho_o&#96;, &#96;G&#96;, &#96;const&#96;, &#96;lam&#96;, &#96;a&#96;, &#96;num_of_waves&#96;\\\\n   - Training: &#96;N_0&#96;, &#96;N_r&#96;, &#96;BATCH_SIZE&#96;, &#96;NUM_BATCHES&#96;, &#96;iteration_adam_2D&#96;, &#96;iteration_lbgfs_2D&#96;\\\\n   - Model: &#96;num_neurons&#96;, &#96;num_layers&#96;, &#96;harmonics&#96;, &#96;DEFAULT_ACTIVATION&#96;\\\\n\\\\n2. **Data generation (&#96;core/data_generator.py&#96;):**\\\\n   - &#96;ASTPN&#96; generates collocation points:\\\\n     - IC points: &#96;N_0&#96; points at &#96;t=0&#96;\\\\n     - Domain points: &#96;N_r&#96; points with &#96;t â‰¥ STARTUP_DT&#96;\\\\n     - Optional Poisson IC points: Extra &#96;t=0&#96; points for Poisson enforcement\\\\n\\\\n3. **Model initialization (&#96;train.py&#96;):**\\\\n   - Create &#96;PINN&#96; network\\\\n   - Set domain bounds via &#96;net.set_domain()&#96;\\\\n   - Initialize optimizers (Adam + L-BFGS)\\\\n\\\\n4. **Training (&#96;training/trainer.py&#96; + &#96;training/physics.py&#96;):**\\\\n   - Batched closure: Mini-batches with gradient accumulation\\\\n   - Loss components:\\\\n     - IC loss: MSE between predicted and true ICs\\\\n     - PDE loss: MSE of PDE residuals\\\\n     - Optional Poisson IC loss: Extra enforcement at &#96;t=0&#96;\\\\n   - Two-phase optimization:\\\\n     - Phase 1: Adam (&#96;iteration_adam_2D&#96; iterations)\\\\n     - Phase 2: L-BFGS (&#96;iteration_lbgfs_2D&#96; iterations)\\\\n\\\\n5. **Evaluation/Visualization:**\\\\n   - Training diagnostics: Real-time loss tracking, residual heatmaps, conservation checks\\\\n   - Post-training: 2D animations, 1D cross-sections, 3D interactive plots\\\\n   - Comparison: FD solver (&#96;LAX.py&#96;) for reference solutions\\\\n\\\\n## **5. Methods Folder**\\\\n\\\\n**Location:** &#96;methods/__init__.py&#96; (currently empty)\\\\n\\\\n**Purpose:** Placeholder for future enhancement methods. Code references suggest XPINN (Extended PINN) decomposition:\\\\n- &#96;methods.xpinn_decomposition&#96; referenced in &#96;data_generator.py&#96; (&#96;get_exterior_boundary_info&#96;)\\\\n- Subdomain collocation generation (&#96;geo_time_coord_subdomain&#96;)\\\\n- Likely intended for domain decomposition methods (XPINN, cPINN, etc.)\\\\n\\\\n## **6. Physics Equations (PDE Residuals)**\\\\n\\\\n**Location:** &#96;core/losses.py&#96; â†’ &#96;pde_residue_standard()&#96;\\\\n\\\\n**System:** Jeans instability in self-gravitating fluid dynamics\\\\n\\\\n**Equations solved:**\\\\n\\\\n**1D:**\\\\n- Continuity: &#96;âˆ‚Ï/âˆ‚t + vxÂ·âˆ‚Ï/âˆ‚x + ÏÂ·âˆ‚vx/âˆ‚x = 0&#96;\\\\n- Momentum (x): &#96;ÏÂ·âˆ‚vx/âˆ‚t + ÏÂ·(vxÂ·âˆ‚vx/âˆ‚x) + csÂ²Â·âˆ‚Ï/âˆ‚x + ÏÂ·âˆ‚Ï†/âˆ‚x = 0&#96;\\\\n- Poisson: &#96;âˆ‚Â²Ï†/âˆ‚xÂ² - constÂ·(Ï - Ïâ‚€) = 0&#96;\\\\n\\\\n**2D:**\\\\n- Continuity: &#96;âˆ‚Ï/âˆ‚t + vxÂ·âˆ‚Ï/âˆ‚x + vyÂ·âˆ‚Ï/âˆ‚y + ÏÂ·(âˆ‚vx/âˆ‚x + âˆ‚vy/âˆ‚y) = 0&#96;\\\\n- Momentum (x): &#96;ÏÂ·âˆ‚vx/âˆ‚t + ÏÂ·(vxÂ·âˆ‚vx/âˆ‚x + vyÂ·âˆ‚vx/âˆ‚y) + csÂ²Â·âˆ‚Ï/âˆ‚x + ÏÂ·âˆ‚Ï†/âˆ‚x = 0&#96;\\\\n- Momentum (y): &#96;ÏÂ·âˆ‚vy/âˆ‚t + ÏÂ·(vyÂ·âˆ‚vy/âˆ‚y + vxÂ·âˆ‚vy/âˆ‚x) + csÂ²Â·âˆ‚Ï/âˆ‚y + ÏÂ·âˆ‚Ï†/âˆ‚y = 0&#96;\\\\n- Poisson: &#96;âˆ‚Â²Ï†/âˆ‚xÂ² + âˆ‚Â²Ï†/âˆ‚yÂ² - constÂ·(Ï - Ïâ‚€) = 0&#96;\\\\n\\\\n**3D:** (adds z-components similarly)\\\\n\\\\n**Physical constants:**\\\\n- &#96;cs&#96;: Sound speed\\\\n- &#96;rho_o&#96;: Background density\\\\n- &#96;const&#96;: Coupling constant for gravity\\\\n- &#96;G&#96;: Gravitational constant\\\\n- &#96;jeans&#96;: Jeans length (critical wavelength for instability)\\\\n\\\\n## **7. Training Pipeline (End-to-End)**\\\\n\\\\n**Entry point:** &#96;train.py&#96;\\\\n\\\\n**Step-by-step:**\\\\n\\\\n1. **Setup:**\\\\n   - Load config\\\\n   - Set device (CUDA/MPS/CPU)\\\\n   - Calculate domain bounds (&#96;xmax = xmin + lam * num_of_waves&#96;)\\\\n   - Initialize shared velocity fields (for power spectrum)\\\\n\\\\n2. **Model creation:**\\\\n   - Instantiate &#96;PINN&#96; with config parameters\\\\n   - Move to device\\\\n   - Create optimizers (Adam lr=0.001, L-BFGS with strong Wolfe)\\\\n\\\\n3. **Collocation generation:**\\\\n   - Create &#96;ASTPN&#96; collocation model\\\\n   - Generate IC points (&#96;collocation_IC&#96;) at &#96;t=0&#96;\\\\n   - Generate domain points (&#96;collocation_domain&#96;) with &#96;t â‰¥ STARTUP_DT&#96;\\\\n   - Optional: Generate Poisson IC points (&#96;collocation_poisson_ic&#96;)\\\\n\\\\n4. **Training loop (&#96;training/trainer.py&#96;):**\\\\n   - **Adam phase:**\\\\n     - For each iteration: &#96;closure_batched()&#96; computes batched loss\\\\n     - Loss = IC loss + PDE loss + optional Poisson IC loss\\\\n     - Gradient accumulation over &#96;NUM_BATCHES&#96; mini-batches\\\\n     - Gradient clipping (max_norm=1.0)\\\\n     - Diagnostics logged every 50 iterations\\\\n   - **L-BFGS phase:**\\\\n     - Uses &#96;closure_batched_cached()&#96; with fixed batch indices\\\\n     - Multiple closure calls per step for line search\\\\n     - Same loss structure as Adam phase\\\\n\\\\n5. **Loss computation (&#96;training/physics.py&#96;):**\\\\n   - **IC loss:** MSE between network predictions and true ICs at &#96;t=0&#96;\\\\n     - For sinusoidal: Explicit &#96;cos(kÂ·x)&#96; density\\\\n     - For power spectrum: Uniform density, power spectrum velocity\\\\n   - **PDE loss:** MSE of PDE residuals at domain collocation points\\\\n     - Computed via automatic differentiation (&#96;diff()&#96;)\\\\n     - Normalized by physical scales\\\\n   - **Poisson IC loss:** Optional extra enforcement at &#96;t=0&#96;\\\\n\\\\n6. **Post-training:**\\\\n   - Save model to &#96;SNAPSHOT_DIR/GRINN/model.pth&#96;\\\\n   - GPU cleanup (move model to CPU, delete optimizer state)\\\\n   - Comprehensive diagnostics:\\\\n     - Training convergence plots\\\\n     - Residual heatmaps (spatiotemporal PDE violations)\\\\n     - Conservation law checks\\\\n     - Spectral evolution analysis\\\\n     - Temporal statistics\\\\n   - Visualization:\\\\n     - 2D animations (density &amp; velocity)\\\\n     - 1D cross-sections (sinusoidal case)\\\\n     - 3D interactive plots (3D case)\\\\n     - Density growth plots (optional)\\\\n\\\\n**Key features:**\\\\n- Batched training: Memory-efficient via mini-batches\\\\n- Gradient accumulation: Constant memory regardless of &#96;NUM_BATCHES&#96;\\\\n- Diagnostics: Real-time tracking and post-training analysis\\\\n- Causality enforcement: &#96;STARTUP_DT&#96; delay for power spectrum perturbations\\\\n- Density parameterization: Ensures positive density via exponential/linear transformations\\\\n\\\\nThis implements a Physics-Informed Neural Network for solving the Jeans instability problem in self-gravitating fluid dynamics, with support for both sinusoidal and power spectrum initial conditions.\\\"}\"},\"status\":\"completed\",\"context\":{\"composers\":[],\"selectedCommits\":[],\"selectedPullRequests\":[],\"selectedImages\":[],\"folderSelections\":[],\"fileSelections\":[],\"selections\":[],\"terminalSelections\":[],\"selectedDocs\":[],\"externalLinks\":[],\"cursorRules\":[],\"cursorCommands\":[],\"gitPRDiffSelections\":[],\"subagentSelections\":[],\"browserSelections\":[],\"mentions\":{\"composers\":{},\"selectedCommits\":{},\"selectedPullRequests\":{},\"gitDiff\":[],\"gitDiffFromBranchToMain\":[],\"selectedImages\":{},\"folderSelections\":{},\"fileSelections\":{},\"terminalFiles\":{},\"selections\":{},\"terminalSelections\":{},\"selectedDocs\":{},\"externalLinks\":{},\"diffHistory\":[],\"cursorRules\":{},\"cursorCommands\":{},\"uiElementSelections\":[],\"consoleLogs\":[],\"ideEditorsState\":[],\"gitPRDiffSelections\":{},\"subagentSelections\":{},\"browserSelections\":{}}},\"generatingBubbleIds\":[],\"isReadingLongFile\":false,\"codeBlockData\":{},\"originalFileStates\":{},\"newlyCreatedFiles\":[],\"newlyCreatedFolders\":[],\"createdAt\":1770577156793,\"hasChangedContext\":false,\"activeTabsShouldBeReactive\":true,\"capabilities\":[{\"type\":30,\"data\":{}},{\"type\":15,\"data\":{\"bubbleDataMap\":\"{}\"}}],\"name\":\"Explore PINN codebase structure\",\"isFileListExpanded\":false,\"browserChipManuallyDisabled\":false,\"browserChipManuallyEnabled\":false,\"unifiedMode\":\"agent\",\"forceMode\":\"edit\",\"usageData\":{},\"allAttachedFileCodeChunksUris\":[],\"modelConfig\":{\"modelName\":\"composer-1\",\"maxMode\":false},\"subComposerIds\":[],\"capabilityContexts\":[],\"todos\":[],\"isQueueExpanded\":true,\"hasUnreadMessages\":false,\"gitHubPromptDismissed\":false,\"totalLinesAdded\":0,\"totalLinesRemoved\":0,\"addedFiles\":0,\"removedFiles\":0,\"isDraft\":false,\"isCreatingWorktree\":false,\"isApplyingWorktree\":false,\"isUndoingWorktree\":false,\"applied\":false,\"pendingCreateWorktree\":false,\"isBestOfNSubcomposer\":false,\"isBestOfNParent\":false,\"bestOfNJudgeWinner\":false,\"isSpec\":false,\"isProject\":false,\"isSpecSubagentDone\":false,\"stopHookLoopCount\":0,\"speculativeSummarizationEncryptionKey\":\"grwF2f3lBWL+5w8j1iM9vQSIs1UeNsY8qsMEroaz/G0=\",\"isNAL\":true,\"planModeSuggestionUsed\":false,\"debugModeSuggestionUsed\":false,\"conversationState\":\"~\",\"queueItems\":[],\"isAgentic\":true}"
}
```
Result:

```json
{
  "agentId": "6cf0b0fe-827a-4eff-aa28-759f8855aaff"
}
```
Status: **completed**


</details>
</tool-use>

---

<tool-use data-tool-type="unknown" data-tool-name="task_v2">
<details>
<summary>Tool use: **task_v2**</summary>


Parameters:

```json
{
  "description": "Find XPINN references in codebase",
  "prompt": "Search the codebase at c:\\Users\\tirth\\Documents\\Projects\\GRINN\\Power spectrum perturbations for any existing references to XPINN, domain decomposition, subdomain, or related concepts. Check:\n\n1. Any imports or references to &#96;methods.xpinn_decomposition&#96; or similar\n2. Any subdomain-related functions in data_generator.py\n3. Any interface/boundary stitching logic\n4. Any commented-out or partial XPINN code\n5. The methods/__init__.py file contents\n\nAlso read the full contents of:\n- core/data_generator.py (to understand collocation point generation and any subdomain references)\n- core/losses.py (to understand how PDE residuals are computed - important for understanding what needs to change for XPINN)\n- training/trainer.py (to understand the training loop structure)\n- training/physics.py (to understand the closure/loss computation)\n\nReturn detailed findings about any existing XPINN scaffolding and the exact structure of these key files.",
  "subagentType": "explore",
  "model": "composer-1",
  "name": "explore"
}
```
Additional data:

```json
{
  "status": "success",
  "composerData": "{\"_v\":13,\"composerId\":\"task-toolu_01Kn8HfrrwmAi9bt1fMG1Rwx\",\"richText\":\"\",\"hasLoaded\":true,\"text\":\"\",\"fullConversationHeadersOnly\":[{\"bubbleId\":\"cbdb7ec2-2d57-45ca-9a4e-1a0422721eb9\",\"type\":2},{\"bubbleId\":\"46a50e62-954b-4be2-902e-7692f56cc78f\",\"type\":2},{\"bubbleId\":\"fa225635-4090-434e-bc67-5ec46796bc63\",\"type\":2},{\"bubbleId\":\"3ce7a236-1fc7-4f5c-a1b0-8bd1605cc663\",\"type\":2},{\"bubbleId\":\"260acfff-29a5-4a29-833d-5e109987abeb\",\"type\":2},{\"bubbleId\":\"d469619f-9a4b-478c-936d-10ed3be3c82d\",\"type\":2},{\"bubbleId\":\"ddfe2c9e-bb47-425a-b3fb-c7854ef9012f\",\"type\":2},{\"bubbleId\":\"42ac6f28-3deb-431b-8014-c5debaa44083\",\"type\":2},{\"bubbleId\":\"80762fd5-91e2-480d-b9cc-8b63fd09fcc0\",\"type\":2},{\"bubbleId\":\"6b6dfe1a-fb86-4d25-9428-cd70f1f30dfa\",\"type\":2},{\"bubbleId\":\"ba3d4c12-b704-42f0-8a22-8c49169685cf\",\"type\":2},{\"bubbleId\":\"7796a49f-d997-402c-a4e7-a034c17aa499\",\"type\":2},{\"bubbleId\":\"3ee58c4e-2c65-47e8-b7b9-36d3b67feba6\",\"type\":2},{\"bubbleId\":\"339dd4c8-ab45-4637-befd-9a96767b069b\",\"type\":2},{\"bubbleId\":\"65b67be5-286a-42c7-95a4-f2a67c820e15\",\"type\":2},{\"bubbleId\":\"0544c272-6681-4ef1-8edd-277edfc1dae0\",\"type\":2},{\"bubbleId\":\"09222754-1d9f-4972-a043-5a9bee286359\",\"type\":2},{\"bubbleId\":\"054589bf-2781-41b5-9c2a-62747af75e55\",\"type\":2},{\"bubbleId\":\"2b5cccb0-3e8a-434b-bb8d-8270e3831f81\",\"type\":2},{\"bubbleId\":\"9b87580c-a74a-43a6-9d69-2c04fb17b589\",\"type\":2},{\"bubbleId\":\"e4d1c351-618f-42a5-81bd-e0b2091bbef7\",\"type\":2},{\"bubbleId\":\"999b18f0-0a37-4d90-8839-c27532c75930\",\"type\":2},{\"bubbleId\":\"69e0e98c-70be-4bd2-a0fd-bdbecac85779\",\"type\":2}],\"conversationMap\":{\"cbdb7ec2-2d57-45ca-9a4e-1a0422721eb9\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"c52e410f-cd73-483e-8ce2-1d06146748f3\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.716Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nSearching for XPINN-related references and reading the requested files.\\\\n\\\"}\",\"46a50e62-954b-4be2-902e-7692f56cc78f\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"7be7c807-baf9-4676-944b-945af9d25804\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.716Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_4e11f2eb-ad21-41cd-9cef-9b7537e46a9\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_4e11f2eb-ad21-41cd-9cef-9b7537e46a9\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"XPINN|xpinn|X-PINN|x-pinn\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_4e11f2eb-ad21-41cd-9cef-9b7537e46a9\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"XPINN|xpinn|X-PINN|x-pinn\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"XPINN|xpinn|X-PINN|x-pinn\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_18-49Z-xpinn-domain-decomposition-for-pinn.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"# XPINN domain decomposition for PINN (2026-02-08 18:49Z)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":9,\\\\\\\"content\\\\\\\":\\\\\\\"The current codebase has a methods folder, which is currently empty. This was made for future additions to improve PINN performance. One idea proposed to me was using XPINN style domain decomposition. I tried it eariler with a half ready script, but due to various issues, the implementation was not good, preventing proper experimentation. I do want to properly implement XPINN style domain decomposition though, and test it thoroughly. But before making up any codes or scripts, have a look at the codebase, and give a high level description of how would someone go about implementing that. No codes necessary, just a qualitative discussion to plan well for future\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-13Z-pinn-and-lax-solver-comparison.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_01Ge7Gp3bAyP6gPHvnm5Xage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2181a25a-ff2a-4ce1-a9d1-d46ecaab11f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c3b0e4e0-e73f-4892-8e4d-03cc82eb0ea8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"34bfe595-59cb-4523-bff5-3f4300330ed0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"33540af8-647a-4e47-82a4-9cdb1e12ed91\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a711058d-5b60-4bd9-aadb-bbcdf5a05997\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f2453eb5-db26-4a76-a33d-fd8c048e33e7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"80d06c8b-c1a8-43d0-a429-96e1a89e3d9b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ca1c992e-415f-4d0f-8865-aa6db3640726\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"9abf266b-2593-4837-8938-c423f6d17585\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"29295441-351f-480f-9a9b-386f8377b75b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"99fb6f39-d980-49ff-8f5c-57e29b5c79f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ebaedb63-e0c4-4546-a7f6-c32f773c06d6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a907e52a-dd [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-17Z-explore-project-structure-and-physics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"                \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1451,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1467,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2686,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2694,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3053,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3057,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3420,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3428,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        rho_0 =  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3452,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3456,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3496,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3500,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3560,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3568,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3584,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3588,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3592,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3596,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3600,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3604,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3652,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3656,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3660,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3668,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4562,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5344,\\\\\\\"content\\\\\\\":\\\\\\\"              \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5622,\\\\\\\"content\\\\\\\":\\\\\\\"              \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5634,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Perfect! Now I have a comprehensive understanding of the codebase. Let me create a plan for removing all causal training and XPINN-related code.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5638,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove all causal training and XPINN domain decomposition code from the codebase, simplifying to a single standard PINN implementation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5682,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Let me replace the predict_xpinn function calls throughout with a simple approach. Given the size of this file, let me use a more targeted approach - replace all predict_xpinn calls:\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5686,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"+     # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5702,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"      # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5775,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Good! Now I have a better understanding. This is about using Physics-Informed Neural Networks (PINNs) and Extended PINNs (XPINNs) to solve cosmological density perturbation equations (self-gravitating fluid dynamics). Let me read a bit more to understand the specific problem they're solving.&amp;lt;/details&amp;gt;&amp;lt;/think&amp;gt;\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5779,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Perfect! Now I have a clear understanding. This is about using Physics-Informed Neural Networks (PINNs) and Extended PINNs (XPINNs) to solve cosmological density perturbation equations governing self-gravitating fluid dynamics. The key innovations seem to be:\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5783,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Based on exploring your codebase, I can see you're working on using Physics-Informed Neural Networks (PINNs) and Extended PINNs (XPINNs) to solve cosmological density perturbation equations. Here's a draft abstract following ICML constraints (single paragraph, 4-6 sentences):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5787,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Simulating the evolution of cosmological density perturbations governed by self-gravitating fluid dynamics remains computationally expensive, particularly for long-time integration with complex initial conditions. We introduce GRINN (Gravitational Residual-Informed Neural Networks), a physics-informed neural network framework that learns to solve the coupled Euler-Poisson system for density, velocity, and gravitational potential fields without requiring numerical grid-based solvers. Our approach integrates several key innovations: extended PINN (XPINN) domain decomposition for spatial scalability, causal training strategies with temporal curriculum learning for accurate long-time evolution, and a pure neural method for enforcing the Poisson equation at initial conditions. We demonstrate that GRINN achieves competitive accuracy compared to traditional finite-difference methods while naturally handling complex power spectrum initial conditions and avoiding t [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5816,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\"\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2774,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2803,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3410,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3689,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4522,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4551,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14638,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14647,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    Legacy compatibility wrapper - XPINN no longer supported.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14693,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    Legacy compatibility function - does nothing now that XPINN is removed.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14717,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14722,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14770,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False  \\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14827,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14832,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            output_0 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14846,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14927,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14932,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14968,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14973,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14997,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15087,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN animations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15092,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15139,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN animations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15144,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            pred_first = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15163,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15168,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            pred_last = predict_xpinn(nets, pt_x, pt_y, pt_t_last, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15215,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15220,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15234,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15239,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15258,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15263,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15734,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Handle both single network and list of networks (XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15744,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15795,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN density-growth visualization not supported for DIMENSION=3.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15800,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15867,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15913,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15918,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16171,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16176,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16265,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        # Add interface lines for XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16270,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17033,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17042,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    Legacy compatibility wrapper - XPINN no longer supported.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17088,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    Legacy compatibility function - does nothing now that XPINN is removed.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17112,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17117,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17165,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False  \\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17222,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17227,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            output_0 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17241,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17322,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17327,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17363,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17368,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17392,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17482,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN animations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17487,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17534,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN animations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17539,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            pred_first = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17558,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17563,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            pred_last = predict_xpinn(nets, pt_x, pt_y, pt_t_last, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17610,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17615,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17629,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17634,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17653,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17658,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18129,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Handle both single network and list of networks (XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18139,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18190,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN density-growth visualization not supported for DIMENSION=3.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18195,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18262,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18308,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18313,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18566,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18571,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18660,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        # Add interface lines for XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18665,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":20631,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False  \\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":20944,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":21087,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":21989,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False  \\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":22302,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":22445,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        use_xpinn = False\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":31077,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_019aNmsGakgw5VbE2Soqf7P3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b530dce-d1e9-4fc1-a61b-33f822115c6a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a89bb8c4-b830-4dca-a69b-74bdc6bbb79e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"49c90654-5f1c-487e-8e5d-01d0e7d99f87\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b8e7ad8-4676-4a3a-bf19-c48fae4dbbb7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f6a38903-c908-4c54-b5a4-801a38b9c87a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"90a27c62-d770-447d-be4d-1cd0669127f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"4ac40ee8-f125-44bc-bc87-3352c7db6894\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"02473f18-b861-43a0-95c0-b4271492196e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2}],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conversationMap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"approximateLintErrors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"lints\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"codebaseContextChunks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pullRequests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"atta [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-26_13-05Z-multi-stage-training-code-removal.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":504,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam,  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":528,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_ [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-58Z-pinn-batch-processing-logic.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2053,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam,  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2086,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_ [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-05Z-3d-power-spectrum-comparison-plot-verification.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":543,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":576,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":623,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":635,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"diffString\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"          pt_x = Variable(torch.from_numpy(X).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n          pt_y = Variable(torch.from_numpy(Y).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n-         pt_z = Variable(torch.from_numpy(Z).float(), requires_grad=True).to(device) if Z is not None else None\\\\\\\\\\\\\\\\n+         # For 3D power spectrum, align PINN z-slice with cached FD z\\\\\\\\\\\\\\\\n+         if Z is not None and fd_cache is not None and t in fd_cache and DIMENSION == 3:\\\\\\\\\\\\\\\\n+             z_val_use = fd_cache[t].get('z_val', SLICE_Z)\\\\\\\\\\\\\\\\n+             Z_use = z_val_use * np.ones_like(X)\\\\\\\\\\\\\\\\n+             pt_z = Variable(torch.from_numpy(Z_use).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n+         else:\\\\\\\\\\\\\\\\n+             pt_z = Variable(torch.from_numpy(Z).float(), requires_grad=True).to(device) if Z is not None else None\\\\\\\\\\\\\\\\n          pt_t = Variable(torch.from_numpy(t_arr).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n          if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":648,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":697,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":722,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1112,\\\\\\\"content\\\\\\\":\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1237,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1279,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1321,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1363,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1405,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1430,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-23_13-45Z-multi-stage-training-for-physics-informed-neural-networks.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":710,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        vx_0 = fun_vx_0(lam, jeans, v_1, collocatio [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":734,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        vx_0 = fun_vx_0(lam, jeans, v_1, co [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":961,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":986,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1244,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1269,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2262,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2312,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2547,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2597,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2645,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2669,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2717,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2749,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3485,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3528,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3619,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3710,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-50Z-transformer-architecture-for-pinn.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":250,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Temporal decomposition** - like XPINN but in time\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-45Z-grinn-paper-limitations-and-future-scope.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":125,\\\\\\\"content\\\\\\\":\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":300,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several well-vetted ideas from recent research that could help mitigate the failure modes you observed when \\\\\\\\\\\\\\\\(t_\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\max\\\\\\\\\\\\\\\\}\\\\\\\\\\\\\\\\) is highâ€”especially over-smoothing, momentum drift, and loss of dynamic richness. You asked for no code; I focus on high-level strategies and references.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Diagnostics â†’ What to Aim For&lt;br/&gt;&lt;br/&gt;Based on your failure â€” perturbations collapsing toward a near-uniform state, severe drift in conserved quantities, spectral power loss â€” the strategies below target:&lt;br/&gt;&lt;br/&gt;- restoring sensitivity to **high frequencies / growing modes**  &lt;br/&gt;- improving conservation of **mass, momentum, etc.**  &lt;br/&gt;- ensuring **temporal causality** so that errors donâ€™t accumulate disproportionately at later times  &lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Mitigation Strategies&lt;br/&gt;&lt;br/&gt;Below are methods, grouped by theme, with pros/cons, as seen in recent literature.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;### 1. Enforcing Conservation Laws Hard&lt;br/&gt;&lt;br/&gt;Since mo [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"# Causal training and XPinn configuration cleanup (2026-01-14 06:30Z)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":9,\\\\\\\"content\\\\\\\":\\\\\\\"In @config.py you will see many options for causal training configuration and xpinn domain decomposition configuration. I dont need these options, or more specifically, any code related to causal training and xpinn. I want to clean up the scripts and remove codes related to these\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16,\\\\\\\"content\\\\\\\":\\\\\\\"The user wants to clean up their codebase by removing all code related to causal training and XPINN domain decomposition. Looking at the config.py, I can see there are many configuration options for both:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":19,\\\\\\\"content\\\\\\\":\\\\\\\"2. XPINN Domain Decomposition Configuration (lines 113-143)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":23,\\\\\\\"content\\\\\\\":\\\\\\\"2. Search the codebase to identify all files that use XPINN features\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":30,\\\\\\\"content\\\\\\\":\\\\\\\"I'll help you clean up the codebase by removing all causal training and XPINN-related code. Let me first search through the codebase to identify all files that contain references to these features.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":55,\\\\\\\"content\\\\\\\":\\\\\\\"                &lt;summary&gt;Tool use: **codebase_search** â€¢ Searched codebase \\\\\\\\\\\\\\\"Where is XPINN domain decomposition implemented and used?\\\\\\\\\\\\\\\" â€¢ **12** results&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":61,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L305-409 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":62,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L308-439 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":63,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L284-369 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":65,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L41 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":70,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L372-468 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":98,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"USE_XPINN|XPINN|xpinn\\\\\\\\\\\\\\\" â€¢ 13 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":116,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;.\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\xpinn_decomposition.py&#96; |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":146,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;details&gt;&lt;summary&gt;Tool use: **read_file** â€¢ Read file: methods/xpinn_decomposition.py&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":175,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"from methods\\\\\\\\\\\\\\\\.causal_training|from methods\\\\\\\\\\\\\\\\.xpinn_decomposition\\\\\\\\\\\\\\\" â€¢ 3 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":222,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"closure_xpinn|causal_gamma|causal_mode|residual_tracker\\\\\\\\\\\\\\\" in \\\\\\\\\\\\\\\"training/physics.py\\\\\\\\\\\\\\\" â€¢ 0 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":241,\\\\\\\"content\\\\\\\":\\\\\\\"Perfect! Now I have a comprehensive understanding of the codebase. Let me create a plan for removing all causal training and XPINN-related code.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":255,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove Causal &amp;amp; XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":258,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete causal_training.py and xpinn_decomposition.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":263,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":268,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove XPINN and causal branches from train.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":273,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove train_xpinn and causal params from trainer.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":278,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove causal/xpinn closures from physics.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":283,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove XPINN_Loss class from losses.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":288,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove predict_xpinn from Plotting.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":298,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove all causal training and XPINN domain decomposition code from the codebase, simplifying to a single standard PINN implementation.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":310,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"planUri\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file:///c%3A/Users/tirth/.cursor/plans/remove_causal_%26_xpinn_f0f99ce6.plan.md\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":312,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"pinnedName\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove Causal &amp;amp; XPINN\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":322,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete causal_training.py and xpinn_decomposition.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":327,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":332,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove XPINN and causal branches from train.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":337,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove train_xpinn and causal params from trainer.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":342,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove causal/xpinn closures from physics.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":347,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove XPINN_Loss class from losses.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":352,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove predict_xpinn from Plotting.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":363,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"planUri\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\.cursor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\plans\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\remove_causal_&amp;amp;_xpinn_f0f99ce6.plan.md\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":385,\\\\\\\"content\\\\\\\":\\\\\\\"The user wants me to implement the plan to remove all causal training and XPINN code. I need to:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":395,\\\\\\\"content\\\\\\\":\\\\\\\"1. Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":396,\\\\\\\"content\\\\\\\":\\\\\\\"2. Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":397,\\\\\\\"content\\\\\\\":\\\\\\\"3. Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":398,\\\\\\\"content\\\\\\\":\\\\\\\"4. Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":399,\\\\\\\"content\\\\\\\":\\\\\\\"5. Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":400,\\\\\\\"content\\\\\\\":\\\\\\\"6. Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":401,\\\\\\\"content\\\\\\\":\\\\\\\"7. Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":408,\\\\\\\"content\\\\\\\":\\\\\\\"I'll implement the plan to remove all causal training and XPINN code from your codebase. Let me start by marking the first todo as in progress and begin the cleanup.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":415,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":416,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":417,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":418,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":419,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":420,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":421,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":443,\\\\\\\"content\\\\\\\":\\\\\\\"Explanation: Deleting the entire XPINN domain decomposition module as it's no longer needed\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":458,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":459,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":460,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":461,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":462,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":463,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":464,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":515,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== XPINN Domain Decomposition Configuration ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":516,\\\\\\\"content\\\\\\\":\\\\\\\"- USE_XPINN = False  # Toggle XPINN on/off (False = original single PINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":538,\\\\\\\"content\\\\\\\":\\\\\\\"- XPINN_OPTIMIZER_STRATEGY = 'unified'  # 'unified' = single optimizer, 'separate' = one per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":539,\\\\\\\"content\\\\\\\":\\\\\\\"- XPINN_ALTERNATING_TRAINING = False  # True = alternate subdomains, False = simultaneous\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":540,\\\\\\\"content\\\\\\\":\\\\\\\"- USE_XPINN_BATCHING = False  # True = use mini-batch processing for XPINN (reduces GPU memory)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":561,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":562,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":563,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":564,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":565,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":566,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":567,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":586,\\\\\\\"content\\\\\\\":\\\\\\\"- from training.trainer import train, train_xpinn\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":592,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, DEFAULT_ACTIVATION, RANDOM_SEED\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":593,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import N_INTERFACE, XPINN_OPTIMIZER_STRATEGY, USE_MULTI_GPU, CACHE_IC_VALUES, STARTUP_DT\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":601,\\\\\\\"content\\\\\\\":\\\\\\\"- from core.losses import ASTPN, XPINN_Loss\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":615,\\\\\\\"content\\\\\\\":\\\\\\\"- import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":616,\\\\\\\"content\\\\\\\":\\\\\\\"- from methods.xpinn_decomposition import (setup_xpinn_devices, setup_xpinn_networks,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":617,\\\\\\\"content\\\\\\\":\\\\\\\"-                                          setup_xpinn_collocation, setup_xpinn_interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":618,\\\\\\\"content\\\\\\\":\\\\\\\"-                                          cache_xpinn_initial_conditions)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":629,\\\\\\\"content\\\\\\\":\\\\\\\"Now let me remove the XPINN-specific saving logic from train.py:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":644,\\\\\\\"content\\\\\\\":\\\\\\\"- def _save_trained_models(nets, use_xpinn):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":652,\\\\\\\"content\\\\\\\":\\\\\\\"-         if not use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":674,\\\\\\\"content\\\\\\\":\\\\\\\"Now let me remove the entire XPINN mode section and simplify the training logic:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":689,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== MODE SWITCHING: ORIGINAL PINN vs XPINN ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":691,\\\\\\\"content\\\\\\\":\\\\\\\"- if not USE_XPINN:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":880,\\\\\\\"content\\\\\\\":\\\\\\\"-     # ==================== XPINN MULTI-NETWORK MODE ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":881,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(\\\\\\\\\\\\\\\"Running in XPINN mode (domain decomposition)...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":884,\\\\\\\"content\\\\\\\":\\\\\\\"-     num_subdomains = xpinn_utils.get_num_subdomains(NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":888,\\\\\\\"content\\\\\\\":\\\\\\\"-     subdomain_devices, num_gpus = setup_xpinn_devices(num_subdomains, device, USE_MULTI_GPU)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":891,\\\\\\\"content\\\\\\\":\\\\\\\"-     nets = setup_xpinn_networks(num_subdomains, subdomain_devices, xmin, xmax, ymin, ymax, \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":896,\\\\\\\"content\\\\\\\":\\\\\\\"-     subdomain_collocs, subdomain_ic_collocs = setup_xpinn_collocation(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":902,\\\\\\\"content\\\\\\\":\\\\\\\"-     interfaces, interface_collocs = setup_xpinn_interfaces(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":907,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Create XPINN loss model\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":909,\\\\\\\"content\\\\\\\":\\\\\\\"-         xpinn_loss_model = XPINN_Loss(rmin=[xmin, ymin, zmin, tmin], rmax=[xmax, ymax, zmax, tmax], dimension=DIMENSION)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":911,\\\\\\\"content\\\\\\\":\\\\\\\"-         xpinn_loss_model = XPINN_Loss(rmin=[xmin, ymin, tmin], rmax=[xmax, ymax, tmax], dimension=DIMENSION)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":956,\\\\\\\"content\\\\\\\":\\\\\\\"-         cached_ic_values = cache_xpinn_initial_conditions(num_subdomains, subdomain_ic_collocs, ic_functions)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":965,\\\\\\\"content\\\\\\\":\\\\\\\"-         optimizer = None  # Will use per-subdomain optimizers in train_xpinn\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":969,\\\\\\\"content\\\\\\\":\\\\\\\"-         if XPINN_OPTIMIZER_STRATEGY == 'unified':\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":978,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Train XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":980,\\\\\\\"content\\\\\\\":\\\\\\\"-     train_xpinn(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":988,\\\\\\\"content\\\\\\\":\\\\\\\"-         xpinn_loss_model=xpinn_loss_model,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":999,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(f\\\\\\\\\\\\\\\"[Timing] XPINN training completed in {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1054,\\\\\\\"content\\\\\\\":\\\\\\\"- _save_trained_models(nets, USE_XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1069,\\\\\\\"content\\\\\\\":\\\\\\\"-         if not USE_XPINN:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1073,\\\\\\\"content\\\\\\\":\\\\\\\"-             # For XPINN, optimizers might be None or per-subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1081,\\\\\\\"content\\\\\\\":\\\\\\\"-         if not USE_XPINN:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1155,\\\\\\\"content\\\\\\\":\\\\\\\"- if not USE_XPINN:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1184,\\\\\\\"content\\\\\\\":\\\\\\\"-     # XPINN multi-network visualization\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1185,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(\\\\\\\\\\\\\\\"Creating XPINN visualizations...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1189,\\\\\\\"content\\\\\\\":\\\\\\\"-         print(\\\\\\\\\\\\\\\"XPINN visualizations created successfully!\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1191,\\\\\\\"content\\\\\\\":\\\\\\\"-         print(\\\\\\\\\\\\\\\"XPINN 3D animations are not yet supported.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1193,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Sinusoidal cross-section plot for XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1197,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Density growth plot for XPINN as well\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1223,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1224,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1225,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1226,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1227,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1228,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1229,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1327,\\\\\\\"content\\\\\\\":\\\\\\\"Now let me remove the entire train_xpinn function:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1343,\\\\\\\"content\\\\\\\":\\\\\\\"- def train_xpinn(nets, subdomain_collocs, interface_collocs, subdomain_ic_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1344,\\\\\\\"content\\\\\\\":\\\\\\\"-                 ic_functions, interfaces, exterior_boundaries, xpinn_loss_model,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1348,\\\\\\\"content\\\\\\\":\\\\\\\"-     Training loop for XPINN with multiple networks.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1361,\\\\\\\"content\\\\\\\":\\\\\\\"-         xpinn_loss_model: XPINN_Loss instance\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1373,\\\\\\\"content\\\\\\\":\\\\\\\"-     from training.physics import closure_xpinn, closure_xpinn_batched, _random_batch_indices, _make_batch_tensors\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1380,\\\\\\\"content\\\\\\\":\\\\\\\"-     from config import XPINN_ALTERNATING_TRAINING, USE_XPINN_BATCHING\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1394,\\\\\\\"content\\\\\\\":\\\\\\\"-         if USE_XPINN_BATCHING:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1401,\\\\\\\"content\\\\\\\":\\\\\\\"-                 return lambda: closure_xpinn_batched(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1402,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1408,\\\\\\\"content\\\\\\\":\\\\\\\"-                 return lambda: closure_xpinn(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1409,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1415,\\\\\\\"content\\\\\\\":\\\\\\\"-     xpinn_diagnostics = TrainingDiagnostics(save_dir='./diagnostics/') if ENABLE_TRAINING_DIAGNOSTICS else None\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1447,\\\\\\\"content\\\\\\\":\\\\\\\"-                     pde_loss = xpinn_loss_model.compute_pde_loss(colloc, nets[sub_idx])\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1448,\\\\\\\"content\\\\\\\":\\\\\\\"-                     ic_loss = xpinn_loss_model.compute_ic_loss(colloc_ic, nets[sub_idx], ic_functions, cached_ic)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1475,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     sol_loss = xpinn_loss_model.compute_interface_solution_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1477,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     res_loss = xpinn_loss_model.compute_interface_residual_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1480,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     sol_loss = xpinn_loss_model.compute_interface_solution_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1482,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     res_loss = xpinn_loss_model.compute_interface_residual_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1503,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Diagnostics for XPINN (aggregate) every 50 iterations\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1504,\\\\\\\"content\\\\\\\":\\\\\\\"-             if i % 50 == 0 and len(nets) &amp;gt; 0 and len(subdomain_collocs) &amp;gt; 0 and xpinn_diagnostics is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1506,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_diagnostics.log_iteration(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1517,\\\\\\\"content\\\\\\\":\\\\\\\"-                     print(f\\\\\\\\\\\\\\\"[WARN] XPINN diagnostics logging failed at {i}: {_diag_err}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1527,\\\\\\\"content\\\\\\\":\\\\\\\"-                 print(f\\\\\\\\\\\\\\\"XPINN Training Loss at {i} (Adam, per-subdomain) = {avg_loss:.2e}\\\\\\\\\\\\\\\", flush=True)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1531,\\\\\\\"content\\\\\\\":\\\\\\\"-             if XPINN_ALTERNATING_TRAINING:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1538,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Diagnostics for XPINN unified every 50 iterations\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1539,\\\\\\\"content\\\\\\\":\\\\\\\"-             if i % 50 == 0 and len(nets) &amp;gt; 0 and len(subdomain_collocs) &amp;gt; 0 and xpinn_diagnostics is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1541,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_diagnostics.log_iteration(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1552,\\\\\\\"content\\\\\\\":\\\\\\\"-                     print(f\\\\\\\\\\\\\\\"[WARN] XPINN diagnostics logging failed at {i}: {_diag_err}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1556,\\\\\\\"content\\\\\\\":\\\\\\\"-                     print(f\\\\\\\\\\\\\\\"XPINN Training Loss at {i} (Adam) = {loss.item():.2e}\\\\\\\\\\\\\\\", flush=True)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1590,\\\\\\\"content\\\\\\\":\\\\\\\"-                     pde_loss = xpinn_loss_model.compute_pde_loss(colloc, current_net)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1591,\\\\\\\"content\\\\\\\":\\\\\\\"-                     ic_loss = xpinn_loss_model.compute_ic_loss(colloc_ic, current_net, ic_functions, cached_ic)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1608,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 sol_loss = xpinn_loss_model.compute_interface_solution_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1610,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 res_loss = xpinn_loss_model.compute_interface_residual_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1633,\\\\\\\"content\\\\\\\":\\\\\\\"-                     pde_loss = xpinn_loss_model.compute_pde_loss(colloc, current_net)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1634,\\\\\\\"content\\\\\\\":\\\\\\\"-                     ic_loss = xpinn_loss_model.compute_ic_loss(colloc_ic, current_net, ic_functions, cached_ic)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1649,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 sol_loss = xpinn_loss_model.compute_interface_solution_loss(colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1650,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 res_loss = xpinn_loss_model.compute_interface_residual_loss(colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1672,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Generate diagnostic plots at the end of XPINN training\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1673,\\\\\\\"content\\\\\\\":\\\\\\\"-     if xpinn_diagnostics is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1676,\\\\\\\"content\\\\\\\":\\\\\\\"-             xpinn_diagnostics.plot_diagnostics(final_iteration)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1678,\\\\\\\"content\\\\\\\":\\\\\\\"-             print(f\\\\\\\\\\\\\\\"[WARN] Final XPINN diagnostics plotting failed: {_diag_err}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1680,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(\\\\\\\\\\\\\\\"XPINN training completed.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1698,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1699,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1700,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1701,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1702,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1703,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1704,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1740,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L495 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1741,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L532 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1749,\\\\\\\"content\\\\\\\":\\\\\\\"Now let me remove the causal import and update closure_batched signature, then remove the xpinn closures:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1916,\\\\\\\"content\\\\\\\":\\\\\\\"Now let me remove the XPINN closure functions. Let me find where they are:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1928,\\\\\\\"content\\\\\\\":\\\\\\\"Let me find the end of the XPINN functions to remove them completely:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1934,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"^def closure_xpinn\\\\\\\\\\\\\\\" in \\\\\\\\\\\\\\\"training/physics.py\\\\\\\\\\\\\\\" â€¢ 2 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1941,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L463 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1942,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L500 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1958,\\\\\\\"content\\\\\\\":\\\\\\\"Let me read the end of the file to see where the XPINN functions end:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1970,\\\\\\\"content\\\\\\\":\\\\\\\"Perfect, now let me remove the entire XPINN section:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2011,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== XPINN Physics Calculations ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2013,\\\\\\\"content\\\\\\\":\\\\\\\"- def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2017,\\\\\\\"content\\\\\\\":\\\\\\\"-     Closure function for XPINN training with multiple networks.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2020,\\\\\\\"content\\\\\\\":\\\\\\\"-         xpinn_loss_model: XPINN_Loss instance\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2037,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Compute total XPINN loss (passing cached IC if available)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2038,\\\\\\\"content\\\\\\\":\\\\\\\"-     total_loss, loss_dict = xpinn_loss_model.compute_total_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2050,\\\\\\\"content\\\\\\\":\\\\\\\"- def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2054,\\\\\\\"content\\\\\\\":\\\\\\\"-     Batched closure function for XPINN training with multiple networks.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2058,\\\\\\\"content\\\\\\\":\\\\\\\"-         xpinn_loss_model: XPINN_Loss instance\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2131,\\\\\\\"content\\\\\\\":\\\\\\\"-         batch_loss, batch_loss_dict = xpinn_loss_model.compute_total_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2148,\\\\\\\"content\\\\\\\":\\\\\\\"-     # For batched XPINN, we need to compute breakdown from the last batch\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2169,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2170,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2171,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2172,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2173,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2174,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2175,\\\\\\\"content\\\\\\\":\\\\\\\"- [ ] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2196,\\\\\\\"content\\\\\\\":\\\\\\\"- class XPINN_Loss:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2198,\\\\\\\"content\\\\\\\":\\\\\\\"-     XPINN Loss computation for domain decomposition.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2209,\\\\\\\"content\\\\\\\":\\\\\\\"-         Initialize XPINN loss computer.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2404,\\\\\\\"content\\\\\\\":\\\\\\\"-         Compute total XPINN loss aggregating all components.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2489,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2490,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2491,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2492,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2493,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2494,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2495,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2505,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"^def predict_xpinn\\\\\\\\\\\\\\\" in \\\\\\\\\\\\\\\"visualization/Plotting.py\\\\\\\\\\\\\\\" â€¢ 1 match&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2512,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):&#96; | L351 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2544,\\\\\\\"content\\\\\\\":\\\\\\\"Let me check if there are other XPINN or interface-related references:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2550,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"predict_xpinn|add_interface_lines|NUM_SUBDOMAINS|SHOW_INTERFACE|INTERFACE_AVERAGING\\\\\\\\\\\\\\\" in \\\\\\\\\\\\\\\"visualization/Plotting.py\\\\\\\\\\\\\\\" â€¢ 26 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2557,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY&#96; | L168 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2558,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):&#96; | L351 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2570,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;output_0 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)&#96; | L527 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2571,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)&#96; | L652 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2573,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)&#96; | L777 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2574,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;pred_first = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)&#96; | L818 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2575,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;pred_last = predict_xpinn(nets, pt_x, pt_y, pt_t_last, xmin, xmax, ymin, ymax)&#96; | L834 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2576,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)&#96; | L897 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2579,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)&#96; | L1668 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2580,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)&#96; | L1849 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2581,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)&#96; | L2377 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2590,\\\\\\\"content\\\\\\\":\\\\\\\"I see there are many calls to predict_xpinn and add_interface_lines. Since the file is very large and we're removing XPINN entirely, let me update the imports first, then remove the functions, then replace all calls with standard single network prediction. Let me start:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2605,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2621,\\\\\\\"content\\\\\\\":\\\\\\\"Let me replace the predict_xpinn function calls throughout with a simple approach. Given the size of this file, let me use a more targeted approach - replace all predict_xpinn calls:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2634,\\\\\\\"content\\\\\\\":\\\\\\\"  def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2636,\\\\\\\"content\\\\\\\":\\\\\\\"-     Predict solution using XPINN with multiple networks.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2639,\\\\\\\"content\\\\\\\":\\\\\\\"+     Legacy compatibility wrapper - XPINN no longer supported.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2653,\\\\\\\"content\\\\\\\":\\\\\\\"-     import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2667,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_bounds = xpinn_utils.get_subdomain_bounds(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2708,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_bounds = xpinn_utils.get_subdomain_bounds(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2724,\\\\\\\"content\\\\\\\":\\\\\\\"+             raise ValueError(\\\\\\\\\\\\\\\"Multi-network XPINN is no longer supported\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2734,\\\\\\\"content\\\\\\\":\\\\\\\"+     Legacy compatibility function - does nothing now that XPINN is removed.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2764,\\\\\\\"content\\\\\\\":\\\\\\\"+     # XPINN removed - this function is now a no-op for compatibility\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2783,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2784,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2785,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2786,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2787,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2788,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2789,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2830,\\\\\\\"content\\\\\\\":\\\\\\\"- # - xpinn_decomposition: Domain decomposition (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2865,\\\\\\\"content\\\\\\\":\\\\\\\"- ## XPINN Domain Decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2866,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;USE_XPINN&amp;#96;: Toggle XPINN on/off (False = original single PINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2888,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;XPINN_OPTIMIZER_STRATEGY&amp;#96;: Optimizer strategy ('unified' or 'separate')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2889,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;XPINN_ALTERNATING_TRAINING&amp;#96;: Whether to alternate subdomain training\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2890,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;USE_XPINN_BATCHING&amp;#96;: Whether to use mini-batch processing for XPINN (reduces GPU memory)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2938,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2939,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove all CAUSAL_* and XPINN_* parameters from config.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2940,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN and causal branches from train.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2941,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove train_xpinn and causal params from trainer.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2942,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove causal/xpinn closures from physics.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2943,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove XPINN_Loss class from losses.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2944,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Remove predict_xpinn from Plotting.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2977,\\\\\\\"content\\\\\\\":\\\\\\\"I have successfully removed all causal training and XPINN domain decomposition code from your codebase. Here's what was done:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2981,\\\\\\\"content\\\\\\\":\\\\\\\"2. **&#96;methods/xpinn_decomposition.py&#96;** - Complete XPINN domain decomposition module (470 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2987,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed all &#96;XPINN_*&#96;, &#96;USE_XPINN&#96;, &#96;NUM_SUBDOMAINS_*&#96;, &#96;INTERFACE_*&#96;, &#96;SUBDOMAIN_CONFIGS&#96; parameters (31 lines, lines 113-143)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2990,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed all causal and XPINN imports\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2991,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed XPINN mode block (~120 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2994,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed XPINN visualization block\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2998,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed &#96;train_xpinn&#96; function entirely (~340 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3006,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed &#96;closure_xpinn&#96; and &#96;closure_xpinn_batched&#96; functions entirely (~150 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3009,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed &#96;XPINN_Loss&#96; class entirely (~280 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3013,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed XPINN-related imports\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3014,\\\\\\\"content\\\\\\\":\\\\\\\"   - Replaced &#96;predict_xpinn&#96; function with simple compatibility wrapper (now handles single network or list with one network)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3022,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed comments about causal_training and xpinn_decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3025,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed XPINN section (lines 70-105)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3048,\\\\\\\"content\\\\\\\":\\\\\\\"The error shows that &#96;DEFAULT_ACTIVATION&#96; is being imported in &#96;core/model_architecture.py&#96; but it no longer exists in &#96;config.py&#96; because I removed it as part of the XPINN cleanup. I need to check what this parameter was used for and either:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3056,\\\\\\\"content\\\\\\\":\\\\\\\"I see the issue! The &#96;DEFAULT_ACTIVATION&#96; parameter was removed from &#96;config.py&#96; but it's still being imported in &#96;core/model_architecture.py&#96;. This parameter is actually needed for the standard PINN architecture, not just XPINN. Let me fix this by adding it back to config.py:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3090,\\\\\\\"content\\\\\\\":\\\\\\\"Perfect! I've fixed the error. The issue was that &#96;DEFAULT_ACTIVATION&#96; was removed from &#96;config.py&#96; when we cleaned up the XPINN configuration, but it's still needed by &#96;core/model_architecture.py&#96; for the standard PINN. I've added it back to the config file with the default value of &#96;'sin'&#96;.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3181,\\\\\\\"content\\\\\\\":\\\\\\\"      # XPINN removed - this function is now a no-op for compatibility\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3211,\\\\\\\"content\\\\\\\":\\\\\\\"update @package_for_kaggle.py to remove causal training and xpinn references\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3217,\\\\\\\"content\\\\\\\":\\\\\\\"I'll update the &#96;package_for_kaggle.py&#96; file to remove references to the deleted causal training and XPINN modules:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3233,\\\\\\\"content\\\\\\\":\\\\\\\"-     (\\\\\\\\\\\\\\\"methods/xpinn_decomposition.py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"methods.xpinn_decomposition\\\\\\\\\\\\\\\"),\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3246,\\\\\\\"content\\\\\\\":\\\\\\\"- &#96;(\\\\\\\\\\\\\\\"methods/xpinn_decomposition.py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"methods.xpinn_decomposition\\\\\\\\\\\\\\\")&#96;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3248,\\\\\\\"content\\\\\\\":\\\\\\\"The &#96;package_for_kaggle.py&#96; script will now correctly bundle only the existing modules without trying to include the removed causal training and XPINN files.\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-08_17-39Z-icml-paper-latex-formatting.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":1370,\\\\\\\"content\\\\\\\":\\\\\\\"Good! Now I have a better understanding. This is about using Physics-Informed Neural Networks (PINNs) and Extended PINNs (XPINNs) to solve cosmological density perturbation equations (self-gravitating fluid dynamics). Let me read a bit more to understand the specific problem they're solving.&lt;/details&gt;&lt;/think&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1391,\\\\\\\"content\\\\\\\":\\\\\\\"Perfect! Now I have a clear understanding. This is about using Physics-Informed Neural Networks (PINNs) and Extended PINNs (XPINNs) to solve cosmological density perturbation equations governing self-gravitating fluid dynamics. The key innovations seem to be:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1394,\\\\\\\"content\\\\\\\":\\\\\\\"2. XPINN domain decomposition for scalability\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1403,\\\\\\\"content\\\\\\\":\\\\\\\"Based on exploring your codebase, I can see you're working on using Physics-Informed Neural Networks (PINNs) and Extended PINNs (XPINNs) to solve cosmological density perturbation equations. Here's a draft abstract following ICML constraints (single paragraph, 4-6 sentences):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1411,\\\\\\\"content\\\\\\\":\\\\\\\"Simulating the evolution of cosmological density perturbations governed by self-gravitating fluid dynamics remains computationally expensive, particularly for long-time integration with complex initial conditions. We introduce GRINN (Gravitational Residual-Informed Neural Networks), a physics-informed neural network framework that learns to solve the coupled Euler-Poisson system for density, velocity, and gravitational potential fields without requiring numerical grid-based solvers. Our approach integrates several key innovations: extended PINN (XPINN) domain decomposition for spatial scalability, causal training strategies with temporal curriculum learning for accurate long-time evolution, and a pure neural method for enforcing the Poisson equation at initial conditions. We demonstrate that GRINN achieves competitive accuracy compared to traditional finite-difference methods while naturally handling complex power spectrum initial conditions and avoiding the stability constraints of ex [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1419,\\\\\\\"content\\\\\\\":\\\\\\\"- âœ… **Method**: PINN-based approach (GRINN) with XPINN, causal training, and Poisson constraint\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":357,\\\\\\\"content\\\\\\\":\\\\\\\"def predict_xpinn(nets, x, y, t, xmin, xmax, ymin, ymax):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":359,\\\\\\\"content\\\\\\\":\\\\\\\"    Legacy compatibility wrapper - XPINN no longer supported.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":372,\\\\\\\"content\\\\\\\":\\\\\\\"            raise ValueError(\\\\\\\\\\\\\\\"Multi-network XPINN is no longer supported\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":381,\\\\\\\"content\\\\\\\":\\\\\\\"    Legacy compatibility function - does nothing now that XPINN is removed.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":387,\\\\\\\"content\\\\\\\":\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":396,\\\\\\\"content\\\\\\\":\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":408,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":411,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = False  \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":440,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":442,\\\\\\\"content\\\\\\\":\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":443,\\\\\\\"content\\\\\\\":\\\\\\\"            output_0 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":533,\\\\\\\"content\\\\\\\":\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":545,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":548,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = False\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":572,\\\\\\\"content\\\\\\\":\\\\\\\"    if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":574,\\\\\\\"content\\\\\\\":\\\\\\\"            raise NotImplementedError(\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":575,\\\\\\\"content\\\\\\\":\\\\\\\"        output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":634,\\\\\\\"content\\\\\\\":\\\\\\\"    # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":635,\\\\\\\"content\\\\\\\":\\\\\\\"    if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":646,\\\\\\\"content\\\\\\\":\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":663,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":666,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = False\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":697,\\\\\\\"content\\\\\\\":\\\\\\\"    if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":699,\\\\\\\"content\\\\\\\":\\\\\\\"            raise NotImplementedError(\\\\\\\\\\\\\\\"XPINN animations currently support up to 2D.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":700,\\\\\\\"content\\\\\\\":\\\\\\\"        output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":738,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":740,\\\\\\\"content\\\\\\\":\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\"XPINN animations currently support up to 2D.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":741,\\\\\\\"content\\\\\\\":\\\\\\\"            pred_first = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":756,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":757,\\\\\\\"content\\\\\\\":\\\\\\\"            pred_last = predict_xpinn(nets, pt_x, pt_y, pt_t_last, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":819,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":820,\\\\\\\"content\\\\\\\":\\\\\\\"            output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":850,\\\\\\\"content\\\\\\\":\\\\\\\"            # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":851,\\\\\\\"content\\\\\\\":\\\\\\\"            if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":858,\\\\\\\"content\\\\\\\":\\\\\\\"            # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":859,\\\\\\\"content\\\\\\\":\\\\\\\"            if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1569,\\\\\\\"content\\\\\\\":\\\\\\\"    # Handle both single network and list of networks (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1572,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1575,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = False\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1610,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1612,\\\\\\\"content\\\\\\\":\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\"XPINN density-growth visualization not supported for DIMENSION=3.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1613,\\\\\\\"content\\\\\\\":\\\\\\\"            out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1757,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1760,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = False\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1799,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1801,\\\\\\\"content\\\\\\\":\\\\\\\"                raise NotImplementedError(\\\\\\\\\\\\\\\"XPINN visualizations currently support up to 2D.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1802,\\\\\\\"content\\\\\\\":\\\\\\\"            out = predict_xpinn(nets, pt_x, pt_y, pt_t, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2298,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2301,\\\\\\\"content\\\\\\\":\\\\\\\"        use_xpinn = False\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2341,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2342,\\\\\\\"content\\\\\\\":\\\\\\\"            output_00 = predict_xpinn(nets, pt_x_collocation, pt_y_collocation, pt_t_collocation, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2571,\\\\\\\"content\\\\\\\":\\\\\\\"        # Add interface lines for XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2572,\\\\\\\"content\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2,\\\\\\\"content\\\\\\\":\\\\\\\"Training loop management for PINN and XPINN.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"single PINN and XPINN decomposition training.\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":264,\\\\\\\"content\\\\\\\":\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":274,\\\\\\\"content\\\\\\\":\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":351,\\\\\\\"content\\\\\\\":\\\\\\\"    Distribute collocation points across subdomains for XPINN.\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":512,\\\\\\\"totalMatchedLines\\\\\\\":512}}}}}\\\"},\\\"capabilityType\\\":15}\",\"fa225635-4090-434e-bc67-5ec46796bc63\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"c5c163f8-3460-4720-b340-db4161185af5\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.718Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_712653c1-0925-42ba-b686-87393b40bfa\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_712653c1-0925-42ba-b686-87393b40bfa\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"domain.decomposition|subdomain|sub.domain\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_712653c1-0925-42ba-b686-87393b40bfa\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"domain.decomposition|subdomain|sub.domain\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"domain.decomposition|subdomain|sub.domain\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_18-49Z-xpinn-domain-decomposition-for-pinn.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"# XPINN domain decomposition for PINN (2026-02-08 18:49Z)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":9,\\\\\\\"content\\\\\\\":\\\\\\\"The current codebase has a methods folder, which is currently empty. This was made for future additions to improve PINN performance. One idea proposed to me was using XPINN style domain decomposition. I tried it eariler with a half ready script, but due to various issues, the implementation was not good, preventing proper experimentation. I do want to properly implement XPINN style domain decomposition though, and test it thoroughly. But before making up any codes or scripts, have a look at the codebase, and give a high level description of how would someone go about implementing that. No codes necessary, just a qualitative discussion to plan well for future\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-13Z-pinn-and-lax-solver-comparison.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_01Ge7Gp3bAyP6gPHvnm5Xage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2181a25a-ff2a-4ce1-a9d1-d46ecaab11f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c3b0e4e0-e73f-4892-8e4d-03cc82eb0ea8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"34bfe595-59cb-4523-bff5-3f4300330ed0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"33540af8-647a-4e47-82a4-9cdb1e12ed91\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a711058d-5b60-4bd9-aadb-bbcdf5a05997\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f2453eb5-db26-4a76-a33d-fd8c048e33e7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"80d06c8b-c1a8-43d0-a429-96e1a89e3d9b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ca1c992e-415f-4d0f-8865-aa6db3640726\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"9abf266b-2593-4837-8938-c423f6d17585\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"29295441-351f-480f-9a9b-386f8377b75b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"99fb6f39-d980-49ff-8f5c-57e29b5c79f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ebaedb63-e0c4-4546-a7f6-c32f773c06d6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a907e52a-dd [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-17Z-explore-project-structure-and-physics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":1215,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1219,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1223,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1227,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1763,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Checking the diagnostic code... I'm trying to figure out the actual domain bounds for the PINNâ€”the config defines xmin and ymin as 0, but xmax and ymax seem to be computed from the wave parameters (likely 14.0 based on wave * num_of_waves). The issue is that the conservation check evaluates on [0, 1]Â² while the actual domain appears to be [0, 14]Â², which would throw off the mass calculation. The mass conservation check is really about the relative change in mass, not absolute values, but that doesn't help hereâ€”mass conservation is fundamentally a global property of the entire domain. On a sub-domain like [0, 1]Â², mass can flow in and out through the interior boundaries, so evaluating there wouldn't show conservation even for a perfect solution. The PINN uses periodic features that should match the actual domain, so I need to check what domain is actually being used in the network setup.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4562,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4618,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1. **Implement temporal domain decomposition**: Create a &amp;#96;methods/temporal_decomposition.py&amp;#96; that trains 3 networks on overlapping time windows\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5170,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Ideally I want to push for longer timescales. Even though I have shown that PINNs work for complex power spectrum ICs and not just sinusoidal case of GRINN, being the first paper in application of PINNs to molecular cloud collapse, GRINN had two major strong points to show - one being PINN can learn gravitational collapse, and second that the training time of PINN doesn't scale on dimensions. A major limitation the authors mentioned though was the issue of longer timescale evolution learning, so unless I can do some sort of breakthrough in that, just showing PINNs work for more complex ICs isn't a lot. I have tried a few approaches before only for the PINN to fail miserably, but that's partly my fault since I saw some papers that this technique helps in better learning better performance etc, but none of those were tested on systems having gravitational collapse. So before trying any approach (like domain decomposition, causal training etc etc) I want to k [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5638,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove all causal training and XPINN domain decomposition code from the codebase, simplifying to a single standard PINN implementation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5654,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"-             # Helper to compute and print a detailed loss breakdown for this subdomain (no grad)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5662,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"-         Compute PDE residual loss for a subdomain.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5666,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"-         Compute initial condition loss for a subdomain.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5787,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Simulating the evolution of cosmological density perturbations governed by self-gravitating fluid dynamics remains computationally expensive, particularly for long-time integration with complex initial conditions. We introduce GRINN (Gravitational Residual-Informed Neural Networks), a physics-informed neural network framework that learns to solve the coupled Euler-Poisson system for density, velocity, and gravitational potential fields without requiring numerical grid-based solvers. Our approach integrates several key innovations: extended PINN (XPINN) domain decomposition for spatial scalability, causal training strategies with temporal curriculum learning for accurate long-time evolution, and a pure neural method for enforcing the Poisson equation at initial conditions. We demonstrate that GRINN achieves competitive accuracy compared to traditional finite-difference methods while naturally handling complex power spectrum initial conditions and avoiding t [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6055,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6059,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\\\\\\\\"\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2552,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2562,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2581,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            subdomain_bounds: Tuple (x_min, x_max, y_min, y_max) for 2D\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2605,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            Collocation points list constrained to subdomain\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2629,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2750,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            raise NotImplementedError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Subdomain collocation not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2760,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2769,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2779,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            ny_sub: Number of subdomain splits in y-direction\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2846,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4300,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4310,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4329,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            subdomain_bounds: Tuple (x_min, x_max, y_min, y_max) for 2D\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4353,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            Collocation points list constrained to subdomain\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4377,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4498,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            raise NotImplementedError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Subdomain collocation not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4508,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4517,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4527,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            ny_sub: Number of subdomain splits in y-direction\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4594,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4688,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"- Late-time failures â†’ Try causal training, time-marching, or domain decomposition\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6299,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6754,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":10818,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18798,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":28177,\\\\\\\"content\\\\\\\":\\\\\\\"Checking the diagnostic code... I'm trying to figure out the actual domain bounds for the PINNâ€”the config defines xmin and ymin as 0, but xmax and ymax seem to be computed from the wave parameters (likely 14.0 based on wave * num_of_waves). The issue is that the conservation check evaluates on [0, 1]Â² while the actual domain appears to be [0, 14]Â², which would throw off the mass calculation. The mass conservation check is really about the relative change in mass, not absolute values, but that doesn't help hereâ€”mass conservation is fundamentally a global property of the entire domain. On a sub-domain like [0, 1]Â², mass can flow in and out through the interior boundaries, so evaluating there wouldn't show conservation even for a perfect solution. The PINN uses periodic features that should match the actual domain, so I need to check what domain is actually being used in the network setup.\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-22_15-06Z-pinn-long-term-learning-diagnostics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2570,\\\\\\\"content\\\\\\\":\\\\\\\"3. They mention domain decomposition and evolutionary deep neural networks as potential solutions\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2780,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Proposed Solutions (Domain Decomposition)**: They correctly identified that standard PINNs struggle with long temporal domains, but didn't realize the **root cause was Poisson equation failure**, not just temporal extent.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2805,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Suggested Future Work**: Mentioned advanced techniques (domain decomposition, evolutionary networks)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2840,\\\\\\\"content\\\\\\\":\\\\\\\"4. âœ… The solution is **not** domain decomposition or better hyperparameters\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-45Z-grinn-paper-limitations-and-future-scope.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":23,\\\\\\\"content\\\\\\\":\\\\\\\"3. Domain decomposition and evolutionary deep neural networks could help\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":85,\\\\\\\"content\\\\\\\":\\\\\\\"3. **Potential solutions**: domain decomposition, evolutionary neural networks\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":125,\\\\\\\"content\\\\\\\":\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":129,\\\\\\\"content\\\\\\\":\\\\\\\"- Train separate networks for each subdomain and enforce continuity at boundaries\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":211,\\\\\\\"content\\\\\\\":\\\\\\\"1. **Implement temporal domain decomposition**: Create a &#96;methods/temporal_decomposition.py&#96; that trains 3 networks on overlapping time windows\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_19-13Z-pinn-long-timescale-performance-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":245,\\\\\\\"content\\\\\\\":\\\\\\\"Ideally I want to push for longer timescales. Even though I have shown that PINNs work for complex power spectrum ICs and not just sinusoidal case of GRINN, being the first paper in application of PINNs to molecular cloud collapse, GRINN had two major strong points to show - one being PINN can learn gravitational collapse, and second that the training time of PINN doesn't scale on dimensions. A major limitation the authors mentioned though was the issue of longer timescale evolution learning, so unless I can do some sort of breakthrough in that, just showing PINNs work for more complex ICs isn't a lot. I have tried a few approaches before only for the PINN to fail miserably, but that's partly my fault since I saw some papers that this technique helps in better learning better performance etc, but none of those were tested on systems having gravitational collapse. So before trying any approach (like domain decomposition, causal training etc etc) I want to know exactly what's preventing  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":286,\\\\\\\"content\\\\\\\":\\\\\\\"If this is the culprit: Temporal decomposition or causal training If this is NOT the culprit: Don't waste time on domain decomposition\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":300,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several well-vetted ideas from recent research that could help mitigate the failure modes you observed when \\\\\\\\\\\\\\\\(t_\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\max\\\\\\\\\\\\\\\\}\\\\\\\\\\\\\\\\) is highâ€”especially over-smoothing, momentum drift, and loss of dynamic richness. You asked for no code; I focus on high-level strategies and references.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Diagnostics â†’ What to Aim For&lt;br/&gt;&lt;br/&gt;Based on your failure â€” perturbations collapsing toward a near-uniform state, severe drift in conserved quantities, spectral power loss â€” the strategies below target:&lt;br/&gt;&lt;br/&gt;- restoring sensitivity to **high frequencies / growing modes**  &lt;br/&gt;- improving conservation of **mass, momentum, etc.**  &lt;br/&gt;- ensuring **temporal causality** so that errors donâ€™t accumulate disproportionately at later times  &lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Mitigation Strategies&lt;br/&gt;&lt;br/&gt;Below are methods, grouped by theme, with pros/cons, as seen in recent literature.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;### 1. Enforcing Conservation Laws Hard&lt;br/&gt;&lt;br/&gt;Since mo [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":313,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several broad strategies drawn from recent work that could help mitigate the failure modes you observed when extending tmax. I include **what** they change (loss, sampling, architecture, etc.), **why** they might help, and **trade-offs or caveats**. No codeâ€”just concepts and design levers so you can prioritize which seem promising.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## What seems to go wrong when tmax increases&lt;br/&gt;&lt;br/&gt;From your diagnostics:  &lt;br/&gt;- The solution over time collapses toward smooth, nearly uniform states (â€œdamping outâ€ perturbations).  &lt;br/&gt;- Conservation laws (especially momentum) degrade significantly even when lower tmax works.  &lt;br/&gt;- The laterâ€time PDE residuals dominate, but earlier times are not learned well (loss imbalance).  &lt;br/&gt;&lt;br/&gt;So you want methods that **(i)** preserve perturbation growth or dynamics over time, **(ii)** enforce conservation laws more strictly, and **(iii)** distribute learning effort across time (making later times n [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":355,\\\\\\\"content\\\\\\\":\\\\\\\"- **Integral-form constraints**: Enforce conservation over subdomains via weak/integral forms\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_10-18Z-mlp-pinn-high-tmax-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":165,\\\\\\\"content\\\\\\\":\\\\\\\"- **Causality issues** â†’ Try time-marching/domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1618,\\\\\\\"content\\\\\\\":\\\\\\\"+ - Late-time failures â†’ Try causal training, time-marching, or domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1761,\\\\\\\"content\\\\\\\":\\\\\\\"+ - **Solution**: Causal training, time-marching, domain decomposition in time\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":9,\\\\\\\"content\\\\\\\":\\\\\\\"In @config.py you will see many options for causal training configuration and xpinn domain decomposition configuration. I dont need these options, or more specifically, any code related to causal training and xpinn. I want to clean up the scripts and remove codes related to these\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16,\\\\\\\"content\\\\\\\":\\\\\\\"The user wants to clean up their codebase by removing all code related to causal training and XPINN domain decomposition. Looking at the config.py, I can see there are many configuration options for both:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":19,\\\\\\\"content\\\\\\\":\\\\\\\"2. XPINN Domain Decomposition Configuration (lines 113-143)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":55,\\\\\\\"content\\\\\\\":\\\\\\\"                &lt;summary&gt;Tool use: **codebase_search** â€¢ Searched codebase \\\\\\\\\\\\\\\"Where is XPINN domain decomposition implemented and used?\\\\\\\\\\\\\\\" â€¢ **12** results&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":298,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove all causal training and XPINN domain decomposition code from the codebase, simplifying to a single standard PINN implementation.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":443,\\\\\\\"content\\\\\\\":\\\\\\\"Explanation: Deleting the entire XPINN domain decomposition module as it's no longer needed\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":515,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== XPINN Domain Decomposition Configuration ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":517,\\\\\\\"content\\\\\\\":\\\\\\\"- NUM_SUBDOMAINS_X = 2  # Subdomain splits in x-direction (1 = no split)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":518,\\\\\\\"content\\\\\\\":\\\\\\\"- NUM_SUBDOMAINS_Y = 2  # Subdomain splits in y-direction (1 = no split)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":521,\\\\\\\"content\\\\\\\":\\\\\\\"- N_r_PER_SUBDOMAIN = None  # Residual points per subdomain (None = auto-distribute N_r)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":522,\\\\\\\"content\\\\\\\":\\\\\\\"- N_0_PER_SUBDOMAIN = None  # IC points per subdomain (None = auto-distribute N_0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":528,\\\\\\\"content\\\\\\\":\\\\\\\"- SUBDOMAIN_CONFIGS = [\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":534,\\\\\\\"content\\\\\\\":\\\\\\\"- # Set to None to use global defaults for all subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":536,\\\\\\\"content\\\\\\\":\\\\\\\"- DEFAULT_ACTIVATION = 'sin'  # Default activation (if not specified in SUBDOMAIN_CONFIGS)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":538,\\\\\\\"content\\\\\\\":\\\\\\\"- XPINN_OPTIMIZER_STRATEGY = 'unified'  # 'unified' = single optimizer, 'separate' = one per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":539,\\\\\\\"content\\\\\\\":\\\\\\\"- XPINN_ALTERNATING_TRAINING = False  # True = alternate subdomains, False = simultaneous\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":541,\\\\\\\"content\\\\\\\":\\\\\\\"- USE_MULTI_GPU = True  # True = distribute subdomains across available GPUs\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":544,\\\\\\\"content\\\\\\\":\\\\\\\"- SHOW_INTERFACE_LINES = True  # Draw subdomain boundaries in plots\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":545,\\\\\\\"content\\\\\\\":\\\\\\\"- INTERFACE_AVERAGING = 'mean'  # Combine overlapping predictions: 'mean', 'weighted', 'subdomain1', 'subdomain2'\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":592,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, DEFAULT_ACTIVATION, RANDOM_SEED\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":658,\\\\\\\"content\\\\\\\":\\\\\\\"-                 model_path = os.path.join(model_dir, f\\\\\\\\\\\\\\\"model_subdomain_{i}.pth\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":660,\\\\\\\"content\\\\\\\":\\\\\\\"-             print(f\\\\\\\\\\\\\\\"Saved {len(nets)} subdomain models to {model_dir}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":881,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(\\\\\\\\\\\\\\\"Running in XPINN mode (domain decomposition)...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":883,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Calculate total number of subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":884,\\\\\\\"content\\\\\\\":\\\\\\\"-     num_subdomains = xpinn_utils.get_num_subdomains(NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":885,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(f\\\\\\\\\\\\\\\"Total subdomains: {num_subdomains}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":888,\\\\\\\"content\\\\\\\":\\\\\\\"-     subdomain_devices, num_gpus = setup_xpinn_devices(num_subdomains, device, USE_MULTI_GPU)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":891,\\\\\\\"content\\\\\\\":\\\\\\\"-     nets = setup_xpinn_networks(num_subdomains, subdomain_devices, xmin, xmax, ymin, ymax, \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":893,\\\\\\\"content\\\\\\\":\\\\\\\"-                                  DEFAULT_ACTIVATION, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":896,\\\\\\\"content\\\\\\\":\\\\\\\"-     subdomain_collocs, subdomain_ic_collocs = setup_xpinn_collocation(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":897,\\\\\\\"content\\\\\\\":\\\\\\\"-         num_subdomains, subdomain_devices, xmin, xmax, ymin, ymax, tmin, tmax, N_r, N_0,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":898,\\\\\\\"content\\\\\\\":\\\\\\\"-         STARTUP_DT, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":903,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices, xmin, xmax, ymin, ymax, tmin, tmax, N_INTERFACE,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":904,\\\\\\\"content\\\\\\\":\\\\\\\"-         NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":953,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Cache IC values for each subdomain to avoid recomputation\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":956,\\\\\\\"content\\\\\\\":\\\\\\\"-         cached_ic_values = cache_xpinn_initial_conditions(num_subdomains, subdomain_ic_collocs, ic_functions)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":962,\\\\\\\"content\\\\\\\":\\\\\\\"-     if USE_MULTI_GPU and len(set(subdomain_devices)) &amp;gt; 1:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":963,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Multi-GPU: use per-subdomain optimizers to avoid cross-device gradient issues\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":964,\\\\\\\"content\\\\\\\":\\\\\\\"-         print(\\\\\\\\\\\\\\\"Multi-GPU detected: using per-subdomain Adam optimizers\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":965,\\\\\\\"content\\\\\\\":\\\\\\\"-         optimizer = None  # Will use per-subdomain optimizers in train_xpinn\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":982,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_collocs=subdomain_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":984,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_ic_collocs=subdomain_ic_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":994,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices=subdomain_devices,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1073,\\\\\\\"content\\\\\\\":\\\\\\\"-             # For XPINN, optimizers might be None or per-subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1089,\\\\\\\"content\\\\\\\":\\\\\\\"-                 'subdomain_collocs': subdomain_collocs if 'subdomain_collocs' in locals() else None,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1090,\\\\\\\"content\\\\\\\":\\\\\\\"-                 'subdomain_ic_collocs': subdomain_ic_collocs if 'subdomain_ic_collocs' in locals() else None,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1343,\\\\\\\"content\\\\\\\":\\\\\\\"- def train_xpinn(nets, subdomain_collocs, interface_collocs, subdomain_ic_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1346,\\\\\\\"content\\\\\\\":\\\\\\\"-                 subdomain_devices=None, cached_ic_values=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1350,\\\\\\\"content\\\\\\\":\\\\\\\"-     Manages Adam and L-BFGS optimization for domain decomposition, with support\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1351,\\\\\\\"content\\\\\\\":\\\\\\\"-     for multi-GPU training and per-subdomain optimization.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1354,\\\\\\\"content\\\\\\\":\\\\\\\"-         nets: List of neural networks (one per subdomain)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1355,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_collocs: List of subdomain collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1357,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_ic_collocs: List of IC collocation points per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1367,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices: List of devices per subdomain (for multi-GPU)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1368,\\\\\\\"content\\\\\\\":\\\\\\\"-         cached_ic_values: Precomputed IC values (list of dicts per subdomain)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1376,\\\\\\\"content\\\\\\\":\\\\\\\"-     if subdomain_devices is None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1377,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices = [device] * len(nets)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1382,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Determine if we need per-subdomain optimizers (multi-GPU case)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1383,\\\\\\\"content\\\\\\\":\\\\\\\"-     use_per_subdomain_adam = (optimizer is None)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1385,\\\\\\\"content\\\\\\\":\\\\\\\"-     if use_per_subdomain_adam:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1386,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Multi-GPU: create separate Adam optimizer for each subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1387,\\\\\\\"content\\\\\\\":\\\\\\\"-         print(\\\\\\\\\\\\\\\"Creating per-subdomain Adam optimizers for multi-GPU training...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1398,\\\\\\\"content\\\\\\\":\\\\\\\"-             bs = max(1, bs_global // max(1, num_sub))  # per-subdomain batch size\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1402,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1403,\\\\\\\"content\\\\\\\":\\\\\\\"-                     subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1404,\\\\\\\"content\\\\\\\":\\\\\\\"-                     opt, bs, nb, subdomain_devices, cached_ic_values\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1409,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1410,\\\\\\\"content\\\\\\\":\\\\\\\"-                     subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1411,\\\\\\\"content\\\\\\\":\\\\\\\"-                     opt, subdomain_devices, cached_ic_values\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1417,\\\\\\\"content\\\\\\\":\\\\\\\"-         if use_per_subdomain_adam:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1418,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Per-subdomain Adam training (multi-GPU)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1419,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Process each subdomain completely independently to avoid graph sharing issues\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1420,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_losses = []\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1422,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Track component losses across all subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1432,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Compute PDE and IC loss for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1434,\\\\\\\"content\\\\\\\":\\\\\\\"-                     colloc_orig = subdomain_collocs[sub_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1435,\\\\\\\"content\\\\\\\":\\\\\\\"-                     colloc_ic_orig = subdomain_ic_collocs[sub_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1456,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Accumulate all interface losses for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1460,\\\\\\\"content\\\\\\\":\\\\\\\"-                         subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1461,\\\\\\\"content\\\\\\\":\\\\\\\"-                         interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1463,\\\\\\\"content\\\\\\\":\\\\\\\"-                         # Only compute interface losses where this subdomain participates\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1464,\\\\\\\"content\\\\\\\":\\\\\\\"-                         if sub_idx == subdomain_i or sub_idx == subdomain_j:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1470,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 net1 = nets[subdomain_i]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1471,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 net2 = nets[subdomain_j]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1473,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 # Backprop only to current subdomain's network\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1474,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 if sub_idx == subdomain_i:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1479,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 else:  # sub_idx == subdomain_j\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1494,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Single backward pass for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1497,\\\\\\\"content\\\\\\\":\\\\\\\"-                     subdomain_losses.append(total_loss.item())\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1500,\\\\\\\"content\\\\\\\":\\\\\\\"-                     print(f\\\\\\\\\\\\\\\"Error in subdomain {sub_idx}: {e}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1504,\\\\\\\"content\\\\\\\":\\\\\\\"-             if i % 50 == 0 and len(nets) &amp;gt; 0 and len(subdomain_collocs) &amp;gt; 0 and xpinn_diagnostics is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1510,\\\\\\\"content\\\\\\\":\\\\\\\"-                             'total': float(np.mean(subdomain_losses)) if subdomain_losses else np.nan,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1514,\\\\\\\"content\\\\\\\":\\\\\\\"-                         geomtime_col=subdomain_collocs[0]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1520,\\\\\\\"content\\\\\\\":\\\\\\\"-                 avg_loss = sum(subdomain_losses) / len(subdomain_losses)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1521,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Average component losses across subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1527,\\\\\\\"content\\\\\\\":\\\\\\\"-                 print(f\\\\\\\\\\\\\\\"XPINN Training Loss at {i} (Adam, per-subdomain) = {avg_loss:.2e}\\\\\\\\\\\\\\\", flush=True)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1532,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Alternate between subdomains (not yet implemented - would need separate optimizers)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1539,\\\\\\\"content\\\\\\\":\\\\\\\"-             if i % 50 == 0 and len(nets) &amp;gt; 0 and len(subdomain_collocs) &amp;gt; 0 and xpinn_diagnostics is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1549,\\\\\\\"content\\\\\\\":\\\\\\\"-                         geomtime_col=subdomain_collocs[0]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1562,\\\\\\\"content\\\\\\\":\\\\\\\"-     # L-BFGS training - per-subdomain optimization\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1563,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Each subdomain network is optimized separately while others are frozen\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1566,\\\\\\\"content\\\\\\\":\\\\\\\"-         print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nStarting per-subdomain L-BFGS training...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1568,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Optimize each subdomain network separately\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1569,\\\\\\\"content\\\\\\\":\\\\\\\"-         for subdomain_idx in range(len(nets)):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1570,\\\\\\\"content\\\\\\\":\\\\\\\"-             print(f\\\\\\\\\\\\\\\"  Optimizing subdomain {subdomain_idx}...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1572,\\\\\\\"content\\\\\\\":\\\\\\\"-             net = nets[subdomain_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1573,\\\\\\\"content\\\\\\\":\\\\\\\"-             net_device = subdomain_devices[subdomain_idx] if subdomain_devices else device\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1575,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Create optimizer for this subdomain only\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1579,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Create closure for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1580,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Computes loss for this subdomain + its interface losses\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1581,\\\\\\\"content\\\\\\\":\\\\\\\"-             def make_subdomain_lbfgs_closure(sub_idx, current_net):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1582,\\\\\\\"content\\\\\\\":\\\\\\\"-                 def subdomain_closure():\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1585,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Compute PDE and IC loss for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1586,\\\\\\\"content\\\\\\\":\\\\\\\"-                     colloc = subdomain_collocs[sub_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1587,\\\\\\\"content\\\\\\\":\\\\\\\"-                     colloc_ic = subdomain_ic_collocs[sub_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1595,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Add interface losses where this subdomain is involved\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1597,\\\\\\\"content\\\\\\\":\\\\\\\"-                         subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1598,\\\\\\\"content\\\\\\\":\\\\\\\"-                         interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1600,\\\\\\\"content\\\\\\\":\\\\\\\"-                         # Only compute interface losses where this subdomain participates\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1601,\\\\\\\"content\\\\\\\":\\\\\\\"-                         if sub_idx == subdomain_i or sub_idx == subdomain_j:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1604,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 net1 = nets[subdomain_i]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1605,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 net2 = nets[subdomain_j]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1625,\\\\\\\"content\\\\\\\":\\\\\\\"-                 return subdomain_closure\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1627,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Helper to compute and print a detailed loss breakdown for this subdomain (no grad)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1628,\\\\\\\"content\\\\\\\":\\\\\\\"-             def _lbfgs_subdomain_breakdown(sub_idx, current_net):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1630,\\\\\\\"content\\\\\\\":\\\\\\\"-                     colloc = subdomain_collocs[sub_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1631,\\\\\\\"content\\\\\\\":\\\\\\\"-                     colloc_ic = subdomain_ic_collocs[sub_idx]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1642,\\\\\\\"content\\\\\\\":\\\\\\\"-                         subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1643,\\\\\\\"content\\\\\\\":\\\\\\\"-                         interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1644,\\\\\\\"content\\\\\\\":\\\\\\\"-                         if sub_idx == subdomain_i or sub_idx == subdomain_j:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1647,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 net1 = nets[subdomain_i]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1648,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 net2 = nets[subdomain_j]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1657,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Run L-BFGS for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1659,\\\\\\\"content\\\\\\\":\\\\\\\"-                 loss = optimizer_sub.step(make_subdomain_lbfgs_closure(subdomain_idx, net))\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1662,\\\\\\\"content\\\\\\\":\\\\\\\"-                     total_v, pde_v, ic_v, if_sol_v, if_res_v = _lbfgs_subdomain_breakdown(subdomain_idx, net)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1664,\\\\\\\"content\\\\\\\":\\\\\\\"-                         f\\\\\\\\\\\\\\\"    Subdomain {subdomain_idx} L-BFGS step {i}: \\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1670,\\\\\\\"content\\\\\\\":\\\\\\\"-         print(\\\\\\\\\\\\\\\"Per-subdomain L-BFGS training completed.\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1740,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L495 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1741,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L532 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1941,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L463 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1942,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L500 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2013,\\\\\\\"content\\\\\\\":\\\\\\\"- def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2014,\\\\\\\"content\\\\\\\":\\\\\\\"-                    subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2015,\\\\\\\"content\\\\\\\":\\\\\\\"-                    optimizer, subdomain_devices=None, cached_ic_values=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2022,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_collocs: List of subdomain collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2024,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_ic_collocs: List of IC collocation points per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2029,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices: List of devices per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2039,\\\\\\\"content\\\\\\\":\\\\\\\"-         nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2040,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_ic_collocs, ic_functions, interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2050,\\\\\\\"content\\\\\\\":\\\\\\\"- def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2051,\\\\\\\"content\\\\\\\":\\\\\\\"-                            subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2052,\\\\\\\"content\\\\\\\":\\\\\\\"-                            optimizer, batch_size, num_batches, subdomain_devices=None, cached_ic_values=None):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2060,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_collocs: List of subdomain collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2062,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_ic_collocs: List of IC collocation points per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2069,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices: List of devices per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2075,\\\\\\\"content\\\\\\\":\\\\\\\"-     if subdomain_devices is None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2076,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices = [subdomain_collocs[0][0].device] * len(nets)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2085,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Get device from first subdomain's collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2086,\\\\\\\"content\\\\\\\":\\\\\\\"-     device = subdomain_collocs[0][0].device if len(subdomain_collocs) &amp;gt; 0 else 'cuda'\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2089,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched subdomain collocation points (on correct devices)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2090,\\\\\\\"content\\\\\\\":\\\\\\\"-         batched_subdomain_collocs = []\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2091,\\\\\\\"content\\\\\\\":\\\\\\\"-         for i, subdomain_colloc in enumerate(subdomain_collocs):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2092,\\\\\\\"content\\\\\\\":\\\\\\\"-             dom_n = subdomain_colloc[0].size(0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2093,\\\\\\\"content\\\\\\\":\\\\\\\"-             sub_device = subdomain_devices[i]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2095,\\\\\\\"content\\\\\\\":\\\\\\\"-             batch_dom = _make_batch_tensors(subdomain_colloc, dom_idx)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2096,\\\\\\\"content\\\\\\\":\\\\\\\"-             batched_subdomain_collocs.append(batch_dom)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2098,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched subdomain IC points and batched cached IC values\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2099,\\\\\\\"content\\\\\\\":\\\\\\\"-         batched_subdomain_ic_collocs = []\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2101,\\\\\\\"content\\\\\\\":\\\\\\\"-         for i, subdomain_ic_colloc in enumerate(subdomain_ic_collocs):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2102,\\\\\\\"content\\\\\\\":\\\\\\\"-             ic_n = subdomain_ic_colloc[0].size(0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2103,\\\\\\\"content\\\\\\\":\\\\\\\"-             sub_device = subdomain_devices[i]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2105,\\\\\\\"content\\\\\\\":\\\\\\\"-             batch_ic = _make_batch_tensors(subdomain_ic_colloc, ic_idx)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2106,\\\\\\\"content\\\\\\\":\\\\\\\"-             batched_subdomain_ic_collocs.append(batch_ic)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2117,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched interface collocation points (use device of first subdomain in pair)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2121,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Use device of first subdomain in the interface pair\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2122,\\\\\\\"content\\\\\\\":\\\\\\\"-             sub_device = subdomain_devices[interface_key[0]]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2132,\\\\\\\"content\\\\\\\":\\\\\\\"-             nets, batched_subdomain_collocs, batched_interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2133,\\\\\\\"content\\\\\\\":\\\\\\\"-             batched_subdomain_ic_collocs, ic_functions, interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2198,\\\\\\\"content\\\\\\\":\\\\\\\"-     XPINN Loss computation for domain decomposition.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2201,\\\\\\\"content\\\\\\\":\\\\\\\"-     - PDE residual loss per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2202,\\\\\\\"content\\\\\\\":\\\\\\\"-     - Initial condition loss per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2232,\\\\\\\"content\\\\\\\":\\\\\\\"-         Compute PDE residual loss for a subdomain.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2236,\\\\\\\"content\\\\\\\":\\\\\\\"-             net: Neural network for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2249,\\\\\\\"content\\\\\\\":\\\\\\\"-         Compute initial condition loss for a subdomain.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2253,\\\\\\\"content\\\\\\\":\\\\\\\"-             net: Neural network for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2295,\\\\\\\"content\\\\\\\":\\\\\\\"-             net1, net2: Neural networks for adjacent subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2359,\\\\\\\"content\\\\\\\":\\\\\\\"-             net1, net2: Neural networks for adjacent subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2400,\\\\\\\"content\\\\\\\":\\\\\\\"-     def compute_total_loss(self, nets, subdomain_collocs, interface_collocs, \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2401,\\\\\\\"content\\\\\\\":\\\\\\\"-                           subdomain_ic_collocs, ic_functions, interfaces, \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2407,\\\\\\\"content\\\\\\\":\\\\\\\"-             nets: List of neural networks (one per subdomain)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2408,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_collocs: List of subdomain collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2410,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_ic_collocs: List of IC collocation points per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2412,\\\\\\\"content\\\\\\\":\\\\\\\"-             interfaces: List of interface tuples (subdomain_i, subdomain_j, type, pos)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2413,\\\\\\\"content\\\\\\\":\\\\\\\"-             exterior_boundaries: Dict mapping subdomain_idx to boundary info\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2414,\\\\\\\"content\\\\\\\":\\\\\\\"-             cached_ic_values: Precomputed IC values (list of dicts per subdomain, optional)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2431,\\\\\\\"content\\\\\\\":\\\\\\\"-         # PDE and IC losses for each subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2432,\\\\\\\"content\\\\\\\":\\\\\\\"-         for i, (net, colloc, colloc_ic) in enumerate(zip(nets, subdomain_collocs, subdomain_ic_collocs)):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2447,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2448,\\\\\\\"content\\\\\\\":\\\\\\\"-             interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2452,\\\\\\\"content\\\\\\\":\\\\\\\"-                 net1 = nets[subdomain_i]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2453,\\\\\\\"content\\\\\\\":\\\\\\\"-                 net2 = nets[subdomain_j]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2550,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"predict_xpinn|add_interface_lines|NUM_SUBDOMAINS|SHOW_INTERFACE|INTERFACE_AVERAGING\\\\\\\\\\\\\\\" in \\\\\\\\\\\\\\\"visualization/Plotting.py\\\\\\\\\\\\\\\" â€¢ 26 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2557,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY&#96; | L168 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2559,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;i, xmin, xmax, ymin, ymax, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y&#96; | L380 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2562,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;i, xmin, xmax, ymin, ymax, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y&#96; | L421 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2564,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;if not SHOW_INTERFACE_LINES or NUM_SUBDOMAINS_X == 1 and NUM_SUBDOMAINS_Y == 1:&#96; | L444 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2565,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;dx = (xmax - xmin) / NUM_SUBDOMAINS_X&#96; | L448 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2566,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;dy = (ymax - ymin) / NUM_SUBDOMAINS_Y&#96; | L449 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2567,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;for i in range(1, NUM_SUBDOMAINS_X):&#96; | L452 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2568,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;for j in range(1, NUM_SUBDOMAINS_Y):&#96; | L457 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2569,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;if NUM_SUBDOMAINS_X &gt; 1 or NUM_SUBDOMAINS_Y &gt; 1:&#96; | L462 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2605,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2637,\\\\\\\"content\\\\\\\":\\\\\\\"-     Automatically determines which subdomain(s) each point belongs to and evaluates accordingly.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2643,\\\\\\\"content\\\\\\\":\\\\\\\"-         nets: List of neural networks (one per subdomain)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2650,\\\\\\\"content\\\\\\\":\\\\\\\"-         Combined predictions from all subdomains [N, 4] (rho, vx, vy, phi)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2661,\\\\\\\"content\\\\\\\":\\\\\\\"-     # If single subdomain, just evaluate directly\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2665,\\\\\\\"content\\\\\\\":\\\\\\\"-     # For each point, determine which subdomain(s) it belongs to\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2667,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_bounds = xpinn_utils.get_subdomain_bounds(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2668,\\\\\\\"content\\\\\\\":\\\\\\\"-             i, xmin, xmax, ymin, ymax, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2670,\\\\\\\"content\\\\\\\":\\\\\\\"-         x_min, x_max, y_min, y_max = subdomain_bounds\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2672,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Find points in this subdomain (with small tolerance for boundaries)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2678,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Evaluate network for points in this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2696,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Add prediction (will average later if point is in multiple subdomains)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2699,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # For other strategies, just use first subdomain's prediction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2702,\\\\\\\"content\\\\\\\":\\\\\\\"-     # For mean averaging, divide by number of subdomains that covered each point\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2705,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Count how many subdomains covered each point\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2708,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_bounds = xpinn_utils.get_subdomain_bounds(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2709,\\\\\\\"content\\\\\\\":\\\\\\\"-                 i, xmin, xmax, ymin, ymax, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2711,\\\\\\\"content\\\\\\\":\\\\\\\"-             x_min, x_max, y_min, y_max = subdomain_bounds\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2733,\\\\\\\"content\\\\\\\":\\\\\\\"-     Add interface lines to plot showing subdomain boundaries.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2740,\\\\\\\"content\\\\\\\":\\\\\\\"-     if not SHOW_INTERFACE_LINES or NUM_SUBDOMAINS_X == 1 and NUM_SUBDOMAINS_Y == 1:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2743,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Calculate subdomain boundaries\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2744,\\\\\\\"content\\\\\\\":\\\\\\\"-     dx = (xmax - xmin) / NUM_SUBDOMAINS_X\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2745,\\\\\\\"content\\\\\\\":\\\\\\\"-     dy = (ymax - ymin) / NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2748,\\\\\\\"content\\\\\\\":\\\\\\\"-     for i in range(1, NUM_SUBDOMAINS_X):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2753,\\\\\\\"content\\\\\\\":\\\\\\\"-     for j in range(1, NUM_SUBDOMAINS_Y):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2758,\\\\\\\"content\\\\\\\":\\\\\\\"-     if NUM_SUBDOMAINS_X &amp;gt; 1 or NUM_SUBDOMAINS_Y &amp;gt; 1:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2808,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import N_r_PER_SUBDOMAIN, N_0_PER_SUBDOMAIN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2830,\\\\\\\"content\\\\\\\":\\\\\\\"- # - xpinn_decomposition: Domain decomposition (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2865,\\\\\\\"content\\\\\\\":\\\\\\\"- ## XPINN Domain Decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2867,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;NUM_SUBDOMAINS_X&amp;#96;: Number of subdomain splits in x-direction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2868,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;NUM_SUBDOMAINS_Y&amp;#96;: Number of subdomain splits in y-direction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2870,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_r_PER_SUBDOMAIN&amp;#96;: Residual points per subdomain (None = auto-distribute)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2871,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_0_PER_SUBDOMAIN&amp;#96;: IC points per subdomain (None = auto-distribute)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2878,\\\\\\\"content\\\\\\\":\\\\\\\"- ## Per-Subdomain Network Architecture\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2879,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;: List of dicts configuring each subdomain's network architecture (list or None)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2880,\\\\\\\"content\\\\\\\":\\\\\\\"-   - Format: &amp;#96;[{config_0}, {config_1}, ..., {config_N-1}]&amp;#96; where N = NUM_SUBDOMAINS_X Ã— NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2883,\\\\\\\"content\\\\\\\":\\\\\\\"-   - Set to &amp;#96;None&amp;#96; to use global defaults for all subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2884,\\\\\\\"content\\\\\\\":\\\\\\\"-   - Subdomain ordering (for 2Ã—2 grid): bottom-left [0], bottom-right [2], top-left [1], top-right [3]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2885,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;DEFAULT_ACTIVATION&amp;#96;: Default activation function used when not specified in SUBDOMAIN_CONFIGS\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2889,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;XPINN_ALTERNATING_TRAINING&amp;#96;: Whether to alternate subdomain training\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2891,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;USE_MULTI_GPU&amp;#96;: Whether to distribute subdomains across available GPUs\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2892,\\\\\\\"content\\\\\\\":\\\\\\\"-   - If &amp;#96;True&amp;#96;: Automatically detects available GPUs and assigns subdomains round-robin\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2893,\\\\\\\"content\\\\\\\":\\\\\\\"-   - Networks stay on assigned devices during Adam; L-BFGS optimizes per-subdomain on its device\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2898,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;SHOW_INTERFACE_LINES&amp;#96;: Whether to draw subdomain boundaries in plots\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2899,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;INTERFACE_AVERAGING&amp;#96;: Method to combine overlapping predictions at interfaces ('mean', 'weighted', 'subdomain1', 'subdomain2')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2977,\\\\\\\"content\\\\\\\":\\\\\\\"I have successfully removed all causal training and XPINN domain decomposition code from your codebase. Here's what was done:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2981,\\\\\\\"content\\\\\\\":\\\\\\\"2. **&#96;methods/xpinn_decomposition.py&#96;** - Complete XPINN domain decomposition module (470 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2987,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed all &#96;XPINN_*&#96;, &#96;USE_XPINN&#96;, &#96;NUM_SUBDOMAINS_*&#96;, &#96;INTERFACE_*&#96;, &#96;SUBDOMAIN_CONFIGS&#96; parameters (31 lines, lines 113-143)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3019,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed imports of &#96;N_r_PER_SUBDOMAIN&#96;, &#96;N_0_PER_SUBDOMAIN&#96;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3035,\\\\\\\"content\\\\\\\":\\\\\\\"The codebase is now streamlined to focus exclusively on standard Physics-Informed Neural Networks without the complexity of domain decomposition or causal training features.\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-08_17-39Z-icml-paper-latex-formatting.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":1394,\\\\\\\"content\\\\\\\":\\\\\\\"2. XPINN domain decomposition for scalability\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1411,\\\\\\\"content\\\\\\\":\\\\\\\"Simulating the evolution of cosmological density perturbations governed by self-gravitating fluid dynamics remains computationally expensive, particularly for long-time integration with complex initial conditions. We introduce GRINN (Gravitational Residual-Informed Neural Networks), a physics-informed neural network framework that learns to solve the coupled Euler-Poisson system for density, velocity, and gravitational potential fields without requiring numerical grid-based solvers. Our approach integrates several key innovations: extended PINN (XPINN) domain decomposition for spatial scalability, causal training strategies with temporal curriculum learning for accurate long-time evolution, and a pure neural method for enforcing the Poisson equation at initial conditions. We demonstrate that GRINN achieves competitive accuracy compared to traditional finite-difference methods while naturally handling complex power spectrum initial conditions and avoiding the stability constraints of ex [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":194,\\\\\\\"content\\\\\\\":\\\\\\\"    def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":196,\\\\\\\"content\\\\\\\":\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":200,\\\\\\\"content\\\\\\\":\\\\\\\"            subdomain_bounds: Tuple (x_min, x_max, y_min, y_max) for 2D\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":205,\\\\\\\"content\\\\\\\":\\\\\\\"            Collocation points list constrained to subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":209,\\\\\\\"content\\\\\\\":\\\\\\\"            x_min, x_max, y_min, y_max = subdomain_bounds\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":232,\\\\\\\"content\\\\\\\":\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":259,\\\\\\\"content\\\\\\\":\\\\\\\"            raise NotImplementedError(f\\\\\\\\\\\\\\\"Subdomain collocation not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":261,\\\\\\\"content\\\\\\\":\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":263,\\\\\\\"content\\\\\\\":\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":267,\\\\\\\"content\\\\\\\":\\\\\\\"            subdomain_idx: Linear subdomain index\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":268,\\\\\\\"content\\\\\\\":\\\\\\\"            nx_sub: Number of subdomain splits in x-direction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":269,\\\\\\\"content\\\\\\\":\\\\\\\"            ny_sub: Number of subdomain splits in y-direction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":283,\\\\\\\"content\\\\\\\":\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":349,\\\\\\\"content\\\\\\\":\\\\\\\"def distribute_collocation_points(n_total, num_subdomains):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":351,\\\\\\\"content\\\\\\\":\\\\\\\"    Distribute collocation points across subdomains for XPINN.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":355,\\\\\\\"content\\\\\\\":\\\\\\\"        num_subdomains: Number of subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":358,\\\\\\\"content\\\\\\\":\\\\\\\"        List of point counts per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":361,\\\\\\\"content\\\\\\\":\\\\\\\"    # If per-subdomain count is specified, use it\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":362,\\\\\\\"content\\\\\\\":\\\\\\\"    if n_total == N_r_PER_SUBDOMAIN and N_r_PER_SUBDOMAIN is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":363,\\\\\\\"content\\\\\\\":\\\\\\\"        return [N_r_PER_SUBDOMAIN] * num_subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":364,\\\\\\\"content\\\\\\\":\\\\\\\"    elif n_total == N_0_PER_SUBDOMAIN and N_0_PER_SUBDOMAIN is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":365,\\\\\\\"content\\\\\\\":\\\\\\\"        return [N_0_PER_SUBDOMAIN] * num_subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":368,\\\\\\\"content\\\\\\\":\\\\\\\"    base_count = n_total // num_subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":369,\\\\\\\"content\\\\\\\":\\\\\\\"    remainder = n_total % num_subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":371,\\\\\\\"content\\\\\\\":\\\\\\\"    counts = [base_count] * num_subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":372,\\\\\\\"content\\\\\\\":\\\\\\\"    # Distribute remainder to first few subdomains\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\DIAGNOSTICS_GUIDE.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"- Late-time failures â†’ Try causal training, time-marching, or domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":196,\\\\\\\"content\\\\\\\":\\\\\\\"- **Solution**: Causal training, time-marching, domain decomposition in time\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":353,\\\\\\\"totalMatchedLines\\\\\\\":353}}}}}\\\"},\\\"capabilityType\\\":15}\",\"3ce7a236-1fc7-4f5c-a1b0-8bd1605cc663\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"933924e8-c094-4404-bbdf-6f9181264713\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.718Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_f1ef7b88-a235-4d65-b204-935ec873d15\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_f1ef7b88-a235-4d65-b204-935ec873d15\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"interface|boundary.stitch|stitch|decomposition\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_f1ef7b88-a235-4d65-b204-935ec873d15\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"interface|boundary.stitch|stitch|decomposition\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"interface|boundary.stitch|stitch|decomposition\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_18-49Z-xpinn-domain-decomposition-for-pinn.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"# XPINN domain decomposition for PINN (2026-02-08 18:49Z)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":9,\\\\\\\"content\\\\\\\":\\\\\\\"The current codebase has a methods folder, which is currently empty. This was made for future additions to improve PINN performance. One idea proposed to me was using XPINN style domain decomposition. I tried it eariler with a half ready script, but due to various issues, the implementation was not good, preventing proper experimentation. I do want to properly implement XPINN style domain decomposition though, and test it thoroughly. But before making up any codes or scripts, have a look at the codebase, and give a high level description of how would someone go about implementing that. No codes necessary, just a qualitative discussion to plan well for future\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-13Z-pinn-and-lax-solver-comparison.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_01Ge7Gp3bAyP6gPHvnm5Xage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2181a25a-ff2a-4ce1-a9d1-d46ecaab11f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c3b0e4e0-e73f-4892-8e4d-03cc82eb0ea8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"34bfe595-59cb-4523-bff5-3f4300330ed0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"33540af8-647a-4e47-82a4-9cdb1e12ed91\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a711058d-5b60-4bd9-aadb-bbcdf5a05997\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f2453eb5-db26-4a76-a33d-fd8c048e33e7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"80d06c8b-c1a8-43d0-a429-96e1a89e3d9b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ca1c992e-415f-4d0f-8865-aa6db3640726\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"9abf266b-2593-4837-8938-c423f6d17585\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"29295441-351f-480f-9a9b-386f8377b75b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"99fb6f39-d980-49ff-8f5c-57e29b5c79f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ebaedb63-e0c4-4546-a7f6-c32f773c06d6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a907e52a-dd [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-17Z-explore-project-structure-and-physics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":852,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"exposes a common interface for sinusoidal versus power-spectrum cases, which allows the training\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1287,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"This is a **conservative finite-difference scheme** â€” it's written in flux form where fluxes cancel at shared cell interfaces. Combined with the exact periodicity from &amp;#96;roll&amp;#96;, the fluxes that leave the right boundary re-enter the left. There is no net gain or loss. Total mass (the sum of &amp;#96;rho&amp;#96; over all grid cells times cell volume) should be conserved to floating-point precision.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2100,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Taking this further, I could frame this as an end-to-end research automation platform where a user poses a physics problem and the system explores solution spaces, runs experiments, analyzes outcomes, and produces documented findings. What distinguishes this from a conversational interface is that it actually executes code to obtain real results, embeds physics constraints directly into its reasoning, interprets failures scientifically rather than speculatively, and generates verifiable outputs instead of just explanatory text. Essentially, it automates the research workflow a graduate student would follow.&amp;lt;/details&amp;gt;&amp;lt;/think&amp;gt;\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2104,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2204,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2220,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2304,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2320,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2536,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"**What it is**: Calling Claude/GPT programmatically instead of through a chat interface.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2686,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2694,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3053,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3057,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3420,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3428,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        rho_0 =  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3452,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3456,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3496,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3500,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3560,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3568,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3584,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3588,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3592,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3596,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3600,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3604,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3652,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3656,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3660,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3668,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with torch.no_grad(): [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4562,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4618,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1. **Implement temporal domain decomposition**: Create a &amp;#96;methods/temporal_decomposition.py&amp;#96; that trains 3 networks on overlapping time windows\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5170,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Ideally I want to push for longer timescales. Even though I have shown that PINNs work for complex power spectrum ICs and not just sinusoidal case of GRINN, being the first paper in application of PINNs to molecular cloud collapse, GRINN had two major strong points to show - one being PINN can learn gravitational collapse, and second that the training time of PINN doesn't scale on dimensions. A major limitation the authors mentioned though was the issue of longer timescale evolution learning, so unless I can do some sort of breakthrough in that, just showing PINNs work for more complex ICs isn't a lot. I have tried a few approaches before only for the PINN to fail miserably, but that's partly my fault since I saw some papers that this technique helps in better learning better performance etc, but none of those were tested on systems having gravitational collapse. So before trying any approach (like domain decomposition, causal training etc etc) I want to k [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5638,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove all causal training and XPINN domain decomposition code from the codebase, simplifying to a single standard PINN implementation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5787,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Simulating the evolution of cosmological density perturbations governed by self-gravitating fluid dynamics remains computationally expensive, particularly for long-time integration with complex initial conditions. We introduce GRINN (Gravitational Residual-Informed Neural Networks), a physics-informed neural network framework that learns to solve the coupled Euler-Poisson system for density, velocity, and gravitational potential fields without requiring numerical grid-based solvers. Our approach integrates several key innovations: extended PINN (XPINN) domain decomposition for spatial scalability, causal training strategies with temporal curriculum learning for accurate long-time evolution, and a pure neural method for enforcing the Poisson equation at initial conditions. We demonstrate that GRINN achieves competitive accuracy compared to traditional finite-difference methods while naturally handling complex power spectrum initial conditions and avoiding t [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-31_18-55Z-power-spectrum-initial-conditions-for-molecular-clouds.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":446,\\\\\\\"content\\\\\\\":\\\\\\\"exposes a common interface for sinusoidal versus power-spectrum cases, which allows the training\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2774,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2803,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4522,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4551,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4688,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"- Late-time failures â†’ Try causal training, time-marching, or domain decomposition\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":8890,\\\\\\\"content\\\\\\\":\\\\\\\"This is a **conservative finite-difference scheme** â€” it's written in flux form where fluxes cancel at shared cell interfaces. Combined with the exact periodicity from &#96;roll&#96;, the fluxes that leave the right boundary re-enter the left. There is no net gain or loss. Total mass (the sum of &#96;rho&#96; over all grid cells times cell volume) should be conserved to floating-point precision.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14684,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_interface_lines(ax, xmin, xmax, ymin, ymax):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14968,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14978,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15234,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15244,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15258,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15268,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16265,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        # Add interface lines for XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16275,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            add_interface_lines(ax_pinn, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17079,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_interface_lines(ax, xmin, xmax, ymin, ymax):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17363,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17373,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17629,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17639,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17653,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17663,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18660,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        # Add interface lines for XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18670,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            add_interface_lines(ax_pinn, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":31077,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_019aNmsGakgw5VbE2Soqf7P3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b530dce-d1e9-4fc1-a61b-33f822115c6a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a89bb8c4-b830-4dca-a69b-74bdc6bbb79e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"49c90654-5f1c-487e-8e5d-01d0e7d99f87\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b8e7ad8-4676-4a3a-bf19-c48fae4dbbb7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f6a38903-c908-4c54-b5a4-801a38b9c87a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"90a27c62-d770-447d-be4d-1cd0669127f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"4ac40ee8-f125-44bc-bc87-3352c7db6894\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"02473f18-b861-43a0-95c0-b4271492196e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2}],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conversationMap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"approximateLintErrors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"lints\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"codebaseContextChunks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pullRequests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"atta [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-31_19-29Z-agentic-ai-concepts-for-research-project.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":265,\\\\\\\"content\\\\\\\":\\\\\\\"â”‚                      TOOL INTERFACE                         â”‚\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":419,\\\\\\\"content\\\\\\\":\\\\\\\"- Chat interface where researchers can ask questions about their simulations\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":438,\\\\\\\"content\\\\\\\":\\\\\\\"Taking this further, I could frame this as an end-to-end research automation platform where a user poses a physics problem and the system explores solution spaces, runs experiments, analyzes outcomes, and produces documented findings. What distinguishes this from a conversational interface is that it actually executes code to obtain real results, embeds physics constraints directly into its reasoning, interprets failures scientifically rather than speculatively, and generates verifiable outputs instead of just explanatory text. Essentially, it automates the research workflow a graduate student would follow.&lt;/details&gt;&lt;/think&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":442,\\\\\\\"content\\\\\\\":\\\\\\\"You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":565,\\\\\\\"content\\\\\\\":\\\\\\\"5. **Conversational Interface**\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":786,\\\\\\\"content\\\\\\\":\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":817,\\\\\\\"content\\\\\\\":\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":979,\\\\\\\"content\\\\\\\":\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1010,\\\\\\\"content\\\\\\\":\\\\\\\"AI: You're absolutely right to push for more ambition. Just hyperparameter optimization is a \\\\\\\\\\\\\\\"tool with a nice interface\\\\\\\\\\\\\\\" - not a truly agentic system. Let me think bigger.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1113,\\\\\\\"content\\\\\\\":\\\\\\\"â”‚                         USER INTERFACE                                  â”‚\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1433,\\\\\\\"content\\\\\\\":\\\\\\\"- With natural language interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1481,\\\\\\\"content\\\\\\\":\\\\\\\"â”‚                              USER INTERFACE                                  â”‚\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1483,\\\\\\\"content\\\\\\\":\\\\\\\"â”‚  â”‚  Chat Interface (Gradio/Streamlit)                                   â”‚   â”‚\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1607,\\\\\\\"content\\\\\\\":\\\\\\\"| **Product Sense** | User-facing interface, documentation, demo |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1632,\\\\\\\"content\\\\\\\":\\\\\\\"&gt; - Deployed with Gradio interface; generates production-ready surrogate models 100x faster than traditional numerical methods\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1777,\\\\\\\"content\\\\\\\":\\\\\\\"### Strategy: Hierarchical Decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1831,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;step&#96; | H(x - xâ‚€) | Sharp interfaces |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1985,\\\\\\\"content\\\\\\\":\\\\\\\"**What it is**: Calling Claude/GPT programmatically instead of through a chat interface.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2369,\\\\\\\"content\\\\\\\":\\\\\\\"### Week 21: User Interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2373,\\\\\\\"content\\\\\\\":\\\\\\\"- Chat interface for conversation with agent\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-26_13-05Z-multi-stage-training-code-removal.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":504,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam,  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":528,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_ [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-58Z-pinn-batch-processing-logic.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2053,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam,  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2086,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, closure_batched_cached, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_ [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-05Z-3d-power-spectrum-comparison-plot-verification.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":543,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":576,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":623,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":648,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":697,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":722,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1237,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1279,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1321,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1363,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1405,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1430,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-23_13-45Z-multi-stage-training-for-physics-informed-neural-networks.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":710,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        vx_0 = fun_vx_0(lam, jeans, v_1, collocatio [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":734,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        vx_0 = fun_vx_0(lam, jeans, v_1, co [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":961,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":986,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1244,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1269,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2262,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2312,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2547,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2597,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2645,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2669,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2717,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2749,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3485,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3528,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3619,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\n        [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3710,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTraining loop management for PINN and XPINN.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis module handles the optimization loops (Adam and L-BFGS) for both\\\\\\\\\\\\\\\\nsingle PINN and XPINN decomposition training.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nfrom training.training_diagnostics import TrainingDiagnostics\\\\\\\\\\\\\\\\nfrom config import BATCH_SIZE, NUM_BATCHES, ENABLE_TRAINING_DIAGNOSTICS\\\\\\\\\\\\\\\\nfrom training.physics import closure_batched, _random_batch_indices, _make_batch_tensors\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef _compute_ic_component_losses(net, collocation_IC, rho_1, lam, jeans, v_1, dimension, mse_cost_function):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Compute individual IC component losses for 3D power spectrum diagnostics.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dict with component-wise losses: {'rho', 'vx', 'vy', 'vz', 'phi'}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    from core.initial_conditions import fun_rho_0, fun_vx_0, fun_vy_0, fun_vz_0\\\\\\\\\\\\\\\\n    from config import rho_o\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    with torch.no_grad():\\\\\\\\\\\\\\\\n        # Get true ICs\\\\\\\\\\\\\\\\n        rho_0 = fun_rho_0(rho_1, lam, collocation_IC)\\\\\\\\\\\\\\\\ [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-22_15-06Z-pinn-long-term-learning-diagnostics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2570,\\\\\\\"content\\\\\\\":\\\\\\\"3. They mention domain decomposition and evolutionary deep neural networks as potential solutions\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2780,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Proposed Solutions (Domain Decomposition)**: They correctly identified that standard PINNs struggle with long temporal domains, but didn't realize the **root cause was Poisson equation failure**, not just temporal extent.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2805,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Suggested Future Work**: Mentioned advanced techniques (domain decomposition, evolutionary networks)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2840,\\\\\\\"content\\\\\\\":\\\\\\\"4. âœ… The solution is **not** domain decomposition or better hyperparameters\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3194,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Decomposition approaches**:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3214,\\\\\\\"content\\\\\\\":\\\\\\\"3. **Auxiliary variable decomposition** - introduce Ïˆ = âˆ‡Ï† to reduce derivative order\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-22_13-11Z-pinn-performance-diagnostics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":245,\\\\\\\"content\\\\\\\":\\\\\\\"6. **Decomposition**: Separate networks for hydrodynamics and potential\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-50Z-transformer-architecture-for-pinn.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":250,\\\\\\\"content\\\\\\\":\\\\\\\"4. **Temporal decomposition** - like XPINN but in time\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":384,\\\\\\\"content\\\\\\\":\\\\\\\"- Can learn appropriate frequency decomposition\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-45Z-grinn-paper-limitations-and-future-scope.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":23,\\\\\\\"content\\\\\\\":\\\\\\\"3. Domain decomposition and evolutionary deep neural networks could help\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":85,\\\\\\\"content\\\\\\\":\\\\\\\"3. **Potential solutions**: domain decomposition, evolutionary neural networks\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":125,\\\\\\\"content\\\\\\\":\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":127,\\\\\\\"content\\\\\\\":\\\\\\\"- **Temporal decomposition**: Break &#96;[0, tmax]&#96; into overlapping windows &#96;[0, 3]&#96;, &#96;[2.5, 5.5]&#96;, &#96;[5, 8]&#96;, etc.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":128,\\\\\\\"content\\\\\\\":\\\\\\\"- **Spatial decomposition**: For &#96;num_of_waves &gt; 1&#96;, split domain into subregions with interface matching conditions\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":211,\\\\\\\"content\\\\\\\":\\\\\\\"1. **Implement temporal domain decomposition**: Create a &#96;methods/temporal_decomposition.py&#96; that trains 3 networks on overlapping time windows\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_19-13Z-pinn-long-timescale-performance-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":245,\\\\\\\"content\\\\\\\":\\\\\\\"Ideally I want to push for longer timescales. Even though I have shown that PINNs work for complex power spectrum ICs and not just sinusoidal case of GRINN, being the first paper in application of PINNs to molecular cloud collapse, GRINN had two major strong points to show - one being PINN can learn gravitational collapse, and second that the training time of PINN doesn't scale on dimensions. A major limitation the authors mentioned though was the issue of longer timescale evolution learning, so unless I can do some sort of breakthrough in that, just showing PINNs work for more complex ICs isn't a lot. I have tried a few approaches before only for the PINN to fail miserably, but that's partly my fault since I saw some papers that this technique helps in better learning better performance etc, but none of those were tested on systems having gravitational collapse. So before trying any approach (like domain decomposition, causal training etc etc) I want to know exactly what's preventing  [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":286,\\\\\\\"content\\\\\\\":\\\\\\\"If this is the culprit: Temporal decomposition or causal training If this is NOT the culprit: Don't waste time on domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":316,\\\\\\\"content\\\\\\\":\\\\\\\"Case C: Solution good until t~4-5, then sudden collapse â†’ Root cause: Temporal accumulation at phase transition â†’ Solution: Temporal decomposition with window boundaries at collapse onset\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1036,\\\\\\\"content\\\\\\\":\\\\\\\"2. Temporal decomposition or progressive training strategies\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":270,\\\\\\\"content\\\\\\\":\\\\\\\"3. Temporal decomposition methods\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":283,\\\\\\\"content\\\\\\\":\\\\\\\"            &lt;summary&gt;Tool use: **web_search** â€¢ Searched web &#96;PINN long time integration causality temporal decomposition 2024 2025 2026&#96; â€¢ **1** results&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":300,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several well-vetted ideas from recent research that could help mitigate the failure modes you observed when \\\\\\\\\\\\\\\\(t_\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\max\\\\\\\\\\\\\\\\}\\\\\\\\\\\\\\\\) is highâ€”especially over-smoothing, momentum drift, and loss of dynamic richness. You asked for no code; I focus on high-level strategies and references.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Diagnostics â†’ What to Aim For&lt;br/&gt;&lt;br/&gt;Based on your failure â€” perturbations collapsing toward a near-uniform state, severe drift in conserved quantities, spectral power loss â€” the strategies below target:&lt;br/&gt;&lt;br/&gt;- restoring sensitivity to **high frequencies / growing modes**  &lt;br/&gt;- improving conservation of **mass, momentum, etc.**  &lt;br/&gt;- ensuring **temporal causality** so that errors donâ€™t accumulate disproportionately at later times  &lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Mitigation Strategies&lt;br/&gt;&lt;br/&gt;Below are methods, grouped by theme, with pros/cons, as seen in recent literature.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;### 1. Enforcing Conservation Laws Hard&lt;br/&gt;&lt;br/&gt;Since mo [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":437,\\\\\\\"content\\\\\\\":\\\\\\\"6. **Multi-network time decomposition (CEENs style)** - Separate networks for different time windows\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_10-18Z-mlp-pinn-high-tmax-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":141,\\\\\\\"content\\\\\\\":\\\\\\\"- **Error decomposition by region**: Where in space does PINN fail?\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":165,\\\\\\\"content\\\\\\\":\\\\\\\"- **Causality issues** â†’ Try time-marching/domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1618,\\\\\\\"content\\\\\\\":\\\\\\\"+ - Late-time failures â†’ Try causal training, time-marching, or domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1761,\\\\\\\"content\\\\\\\":\\\\\\\"+ - **Solution**: Causal training, time-marching, domain decomposition in time\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":9,\\\\\\\"content\\\\\\\":\\\\\\\"In @config.py you will see many options for causal training configuration and xpinn domain decomposition configuration. I dont need these options, or more specifically, any code related to causal training and xpinn. I want to clean up the scripts and remove codes related to these\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16,\\\\\\\"content\\\\\\\":\\\\\\\"The user wants to clean up their codebase by removing all code related to causal training and XPINN domain decomposition. Looking at the config.py, I can see there are many configuration options for both:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":19,\\\\\\\"content\\\\\\\":\\\\\\\"2. XPINN Domain Decomposition Configuration (lines 113-143)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":55,\\\\\\\"content\\\\\\\":\\\\\\\"                &lt;summary&gt;Tool use: **codebase_search** â€¢ Searched codebase \\\\\\\\\\\\\\\"Where is XPINN domain decomposition implemented and used?\\\\\\\\\\\\\\\" â€¢ **12** results&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":61,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L305-409 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":62,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L308-439 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":63,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L284-369 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":65,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L41 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":70,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L372-468 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":116,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;.\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\xpinn_decomposition.py&#96; |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":146,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;details&gt;&lt;summary&gt;Tool use: **read_file** â€¢ Read file: methods/xpinn_decomposition.py&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":175,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"from methods\\\\\\\\\\\\\\\\.causal_training|from methods\\\\\\\\\\\\\\\\.xpinn_decomposition\\\\\\\\\\\\\\\" â€¢ 3 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":258,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete causal_training.py and xpinn_decomposition.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":298,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Remove all causal training and XPINN domain decomposition code from the codebase, simplifying to a single standard PINN implementation.\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":322,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete causal_training.py and xpinn_decomposition.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":395,\\\\\\\"content\\\\\\\":\\\\\\\"1. Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":415,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":443,\\\\\\\"content\\\\\\\":\\\\\\\"Explanation: Deleting the entire XPINN domain decomposition module as it's no longer needed\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":458,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":515,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== XPINN Domain Decomposition Configuration ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":520,\\\\\\\"content\\\\\\\":\\\\\\\"- N_INTERFACE = 50  # Interface collocation points per interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":524,\\\\\\\"content\\\\\\\":\\\\\\\"- INTERFACE_SOLUTION_WEIGHT = 0.1  # Solution continuity weight\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":525,\\\\\\\"content\\\\\\\":\\\\\\\"- INTERFACE_RESIDUAL_WEIGHT = 0.1  # Residual continuity weight\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":526,\\\\\\\"content\\\\\\\":\\\\\\\"- INTERFACE_SOLUTION_COMPONENTS = ['rho', 'vx', 'vy', 'phi']  # Which components to enforce\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":544,\\\\\\\"content\\\\\\\":\\\\\\\"- SHOW_INTERFACE_LINES = True  # Draw subdomain boundaries in plots\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":545,\\\\\\\"content\\\\\\\":\\\\\\\"- INTERFACE_AVERAGING = 'mean'  # Combine overlapping predictions: 'mean', 'weighted', 'subdomain1', 'subdomain2'\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":561,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":593,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import N_INTERFACE, XPINN_OPTIMIZER_STRATEGY, USE_MULTI_GPU, CACHE_IC_VALUES, STARTUP_DT\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":615,\\\\\\\"content\\\\\\\":\\\\\\\"- import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":616,\\\\\\\"content\\\\\\\":\\\\\\\"- from methods.xpinn_decomposition import (setup_xpinn_devices, setup_xpinn_networks,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":617,\\\\\\\"content\\\\\\\":\\\\\\\"-                                          setup_xpinn_collocation, setup_xpinn_interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":881,\\\\\\\"content\\\\\\\":\\\\\\\"-     print(\\\\\\\\\\\\\\\"Running in XPINN mode (domain decomposition)...\\\\\\\\\\\\\\\")\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":901,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Setup interfaces\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":902,\\\\\\\"content\\\\\\\":\\\\\\\"-     interfaces, interface_collocs = setup_xpinn_interfaces(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":903,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_devices, xmin, xmax, ymin, ymax, tmin, tmax, N_INTERFACE,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":983,\\\\\\\"content\\\\\\\":\\\\\\\"-         interface_collocs=interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":986,\\\\\\\"content\\\\\\\":\\\\\\\"-         interfaces=interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1091,\\\\\\\"content\\\\\\\":\\\\\\\"-                 'interface_collocs': interface_collocs if 'interface_collocs' in locals() else None\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1223,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1343,\\\\\\\"content\\\\\\\":\\\\\\\"- def train_xpinn(nets, subdomain_collocs, interface_collocs, subdomain_ic_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1344,\\\\\\\"content\\\\\\\":\\\\\\\"-                 ic_functions, interfaces, exterior_boundaries, xpinn_loss_model,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1350,\\\\\\\"content\\\\\\\":\\\\\\\"-     Manages Adam and L-BFGS optimization for domain decomposition, with support\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1356,\\\\\\\"content\\\\\\\":\\\\\\\"-         interface_collocs: Dict of interface collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1359,\\\\\\\"content\\\\\\\":\\\\\\\"-         interfaces: List of interface tuples\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1402,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1403,\\\\\\\"content\\\\\\\":\\\\\\\"-                     subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1409,\\\\\\\"content\\\\\\\":\\\\\\\"-                     xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1410,\\\\\\\"content\\\\\\\":\\\\\\\"-                     subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1425,\\\\\\\"content\\\\\\\":\\\\\\\"-             total_interface_sol_loss = 0.0\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1426,\\\\\\\"content\\\\\\\":\\\\\\\"-             total_interface_res_loss = 0.0\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1456,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Accumulate all interface losses for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1457,\\\\\\\"content\\\\\\\":\\\\\\\"-                     interface_sol_loss_sum = 0.0\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1458,\\\\\\\"content\\\\\\\":\\\\\\\"-                     interface_res_loss_sum = 0.0\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1459,\\\\\\\"content\\\\\\\":\\\\\\\"-                     for interface in interfaces:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1460,\\\\\\\"content\\\\\\\":\\\\\\\"-                         subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1461,\\\\\\\"content\\\\\\\":\\\\\\\"-                         interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1463,\\\\\\\"content\\\\\\\":\\\\\\\"-                         # Only compute interface losses where this subdomain participates\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1465,\\\\\\\"content\\\\\\\":\\\\\\\"-                             if interface_key in interface_collocs:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1466,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 # Create fresh copies of interface collocation points to avoid graph sharing\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1467,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 colloc_interface = interface_collocs[interface_key]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1468,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 colloc_interface_fresh = [t.clone().detach().requires_grad_(False) for t in colloc_interface]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1475,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     sol_loss = xpinn_loss_model.compute_interface_solution_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1476,\\\\\\\"content\\\\\\\":\\\\\\\"-                                         colloc_interface_fresh, net1, net2, grad_to='net1')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1477,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     res_loss = xpinn_loss_model.compute_interface_residual_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1478,\\\\\\\"content\\\\\\\":\\\\\\\"-                                         colloc_interface_fresh, net1, net2, grad_to='net1')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1480,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     sol_loss = xpinn_loss_model.compute_interface_solution_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1481,\\\\\\\"content\\\\\\\":\\\\\\\"-                                         colloc_interface_fresh, net1, net2, grad_to='net2')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1482,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     res_loss = xpinn_loss_model.compute_interface_residual_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1483,\\\\\\\"content\\\\\\\":\\\\\\\"-                                         colloc_interface_fresh, net1, net2, grad_to='net2')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1485,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 interface_sol_loss_sum += sol_loss.item()\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1486,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 interface_res_loss_sum += res_loss.item()\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1490,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Track interface losses\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1491,\\\\\\\"content\\\\\\\":\\\\\\\"-                     total_interface_sol_loss += interface_sol_loss_sum\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1492,\\\\\\\"content\\\\\\\":\\\\\\\"-                     total_interface_res_loss += interface_res_loss_sum\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1524,\\\\\\\"content\\\\\\\":\\\\\\\"-                 avg_if_sol = total_interface_sol_loss / len(nets)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1525,\\\\\\\"content\\\\\\\":\\\\\\\"-                 avg_if_res = total_interface_res_loss / len(nets)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1580,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Computes loss for this subdomain + its interface losses\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1595,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Add interface losses where this subdomain is involved\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1596,\\\\\\\"content\\\\\\\":\\\\\\\"-                     for interface in interfaces:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1597,\\\\\\\"content\\\\\\\":\\\\\\\"-                         subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1598,\\\\\\\"content\\\\\\\":\\\\\\\"-                         interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1600,\\\\\\\"content\\\\\\\":\\\\\\\"-                         # Only compute interface losses where this subdomain participates\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1602,\\\\\\\"content\\\\\\\":\\\\\\\"-                             if interface_key in interface_collocs:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1603,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 colloc_interface = interface_collocs[interface_key]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1607,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 # Compute interface losses (gradients only flow to this net)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1608,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 sol_loss = xpinn_loss_model.compute_interface_solution_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1609,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1610,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 res_loss = xpinn_loss_model.compute_interface_residual_loss(\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1611,\\\\\\\"content\\\\\\\":\\\\\\\"-                                     colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1613,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 # Move interface losses to current net's device before adding\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1641,\\\\\\\"content\\\\\\\":\\\\\\\"-                     for interface in interfaces:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1642,\\\\\\\"content\\\\\\\":\\\\\\\"-                         subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1643,\\\\\\\"content\\\\\\\":\\\\\\\"-                         interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1645,\\\\\\\"content\\\\\\\":\\\\\\\"-                             if interface_key in interface_collocs:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1646,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 colloc_interface = interface_collocs[interface_key]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1649,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 sol_loss = xpinn_loss_model.compute_interface_solution_loss(colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1650,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 res_loss = xpinn_loss_model.compute_interface_residual_loss(colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1698,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1740,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L495 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1741,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L532 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1941,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L463 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1942,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;training/physics.py&#96; | &#96;def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,&#96; | L500 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2013,\\\\\\\"content\\\\\\\":\\\\\\\"- def closure_xpinn(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2014,\\\\\\\"content\\\\\\\":\\\\\\\"-                    subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2023,\\\\\\\"content\\\\\\\":\\\\\\\"-         interface_collocs: Dict of interface collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2026,\\\\\\\"content\\\\\\\":\\\\\\\"-         interfaces: List of interface tuples\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2039,\\\\\\\"content\\\\\\\":\\\\\\\"-         nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2040,\\\\\\\"content\\\\\\\":\\\\\\\"-         subdomain_ic_collocs, ic_functions, interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2050,\\\\\\\"content\\\\\\\":\\\\\\\"- def closure_xpinn_batched(xpinn_loss_model, nets, subdomain_collocs, interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2051,\\\\\\\"content\\\\\\\":\\\\\\\"-                            subdomain_ic_collocs, ic_functions, interfaces, exterior_boundaries,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2061,\\\\\\\"content\\\\\\\":\\\\\\\"-         interface_collocs: Dict of interface collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2064,\\\\\\\"content\\\\\\\":\\\\\\\"-         interfaces: List of interface tuples\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2117,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched interface collocation points (use device of first subdomain in pair)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2118,\\\\\\\"content\\\\\\\":\\\\\\\"-         batched_interface_collocs = {}\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2119,\\\\\\\"content\\\\\\\":\\\\\\\"-         for interface_key, interface_colloc in interface_collocs.items():\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2120,\\\\\\\"content\\\\\\\":\\\\\\\"-             if_n = interface_colloc[0].size(0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2121,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Use device of first subdomain in the interface pair\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2122,\\\\\\\"content\\\\\\\":\\\\\\\"-             sub_device = subdomain_devices[interface_key[0]]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2125,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Move interface collocation points to the correct device before indexing\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2126,\\\\\\\"content\\\\\\\":\\\\\\\"-             interface_colloc_on_device = [t.to(sub_device) for t in interface_colloc]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2127,\\\\\\\"content\\\\\\\":\\\\\\\"-             batch_if = _make_batch_tensors(interface_colloc_on_device, if_idx)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2128,\\\\\\\"content\\\\\\\":\\\\\\\"-             batched_interface_collocs[interface_key] = batch_if\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2132,\\\\\\\"content\\\\\\\":\\\\\\\"-             nets, batched_subdomain_collocs, batched_interface_collocs,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2133,\\\\\\\"content\\\\\\\":\\\\\\\"-             batched_subdomain_ic_collocs, ic_functions, interfaces,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2169,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2198,\\\\\\\"content\\\\\\\":\\\\\\\"-     XPINN Loss computation for domain decomposition.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2204,\\\\\\\"content\\\\\\\":\\\\\\\"-     - Interface continuity losses (solution + residual)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2221,\\\\\\\"content\\\\\\\":\\\\\\\"-         from config import (INTERFACE_SOLUTION_WEIGHT, INTERFACE_RESIDUAL_WEIGHT,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2222,\\\\\\\"content\\\\\\\":\\\\\\\"-                            INTERFACE_SOLUTION_COMPONENTS)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2223,\\\\\\\"content\\\\\\\":\\\\\\\"-         self.interface_solution_weight = INTERFACE_SOLUTION_WEIGHT\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2224,\\\\\\\"content\\\\\\\":\\\\\\\"-         self.interface_residual_weight = INTERFACE_RESIDUAL_WEIGHT\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2225,\\\\\\\"content\\\\\\\":\\\\\\\"-         self.interface_components = INTERFACE_SOLUTION_COMPONENTS\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2286,\\\\\\\"content\\\\\\\":\\\\\\\"-     def compute_interface_solution_loss(self, colloc_interface, net1, net2, grad_to='both'):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2288,\\\\\\\"content\\\\\\\":\\\\\\\"-         Compute solution continuity loss at interface.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2294,\\\\\\\"content\\\\\\\":\\\\\\\"-             colloc_interface: Interface collocation points [x, y, t]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2301,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Move interface points to each network's device\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2305,\\\\\\\"content\\\\\\\":\\\\\\\"-         colloc_interface_1 = [t.to(device1) for t in colloc_interface]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2306,\\\\\\\"content\\\\\\\":\\\\\\\"-         colloc_interface_2 = [t.to(device2) for t in colloc_interface]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2308,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Get predictions from both networks at interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2309,\\\\\\\"content\\\\\\\":\\\\\\\"-         u1 = net1(colloc_interface_1)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2310,\\\\\\\"content\\\\\\\":\\\\\\\"-         u2 = net2(colloc_interface_2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2325,\\\\\\\"content\\\\\\\":\\\\\\\"-             for comp_name in self.interface_components:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2338,\\\\\\\"content\\\\\\\":\\\\\\\"-             for comp_name in self.interface_components:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2349,\\\\\\\"content\\\\\\\":\\\\\\\"-         return self.interface_solution_weight * loss\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2351,\\\\\\\"content\\\\\\\":\\\\\\\"-     def compute_interface_residual_loss(self, colloc_interface, net1, net2, grad_to='both'):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2353,\\\\\\\"content\\\\\\\":\\\\\\\"-         Compute residual continuity loss at interface.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2355,\\\\\\\"content\\\\\\\":\\\\\\\"-         Enforces: R1(interface) = R2(interface)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2358,\\\\\\\"content\\\\\\\":\\\\\\\"-             colloc_interface: Interface collocation points [x, y, t]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2365,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Move interface points to each network's device\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2369,\\\\\\\"content\\\\\\\":\\\\\\\"-         colloc_interface_1 = [t.to(device1) for t in colloc_interface]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2370,\\\\\\\"content\\\\\\\":\\\\\\\"-         colloc_interface_2 = [t.to(device2) for t in colloc_interface]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2372,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Compute PDE residuals from both networks at interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2373,\\\\\\\"content\\\\\\\":\\\\\\\"-         residuals1 = pde_residue(colloc_interface_1, net1, dimension=self.dimension)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2374,\\\\\\\"content\\\\\\\":\\\\\\\"-         residuals2 = pde_residue(colloc_interface_2, net2, dimension=self.dimension)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2394,\\\\\\\"content\\\\\\\":\\\\\\\"-         return self.interface_residual_weight * loss\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2400,\\\\\\\"content\\\\\\\":\\\\\\\"-     def compute_total_loss(self, nets, subdomain_collocs, interface_collocs, \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2401,\\\\\\\"content\\\\\\\":\\\\\\\"-                           subdomain_ic_collocs, ic_functions, interfaces, \\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2409,\\\\\\\"content\\\\\\\":\\\\\\\"-             interface_collocs: Dict mapping interface tuple to collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2412,\\\\\\\"content\\\\\\\":\\\\\\\"-             interfaces: List of interface tuples (subdomain_i, subdomain_j, type, pos)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2427,\\\\\\\"content\\\\\\\":\\\\\\\"-             'interface_solution': torch.tensor(0.0, device=device),\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2428,\\\\\\\"content\\\\\\\":\\\\\\\"-             'interface_residual': torch.tensor(0.0, device=device)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2445,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Interface losses\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2446,\\\\\\\"content\\\\\\\":\\\\\\\"-         for interface in interfaces:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2447,\\\\\\\"content\\\\\\\":\\\\\\\"-             subdomain_i, subdomain_j, _, _ = interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2448,\\\\\\\"content\\\\\\\":\\\\\\\"-             interface_key = (subdomain_i, subdomain_j)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2450,\\\\\\\"content\\\\\\\":\\\\\\\"-             if interface_key in interface_collocs:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2451,\\\\\\\"content\\\\\\\":\\\\\\\"-                 colloc_interface = interface_collocs[interface_key]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2455,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Compute interface losses\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2456,\\\\\\\"content\\\\\\\":\\\\\\\"-                 sol_loss = self.compute_interface_solution_loss(colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2457,\\\\\\\"content\\\\\\\":\\\\\\\"-                 res_loss = self.compute_interface_residual_loss(colloc_interface, net1, net2)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2464,\\\\\\\"content\\\\\\\":\\\\\\\"-                 loss_dict['interface_solution'] += sol_loss\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2465,\\\\\\\"content\\\\\\\":\\\\\\\"-                 loss_dict['interface_residual'] += res_loss\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2489,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2532,\\\\\\\"content\\\\\\\":\\\\\\\"Let me find where this function ends and also check for the add_interface_lines function:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2544,\\\\\\\"content\\\\\\\":\\\\\\\"Let me check if there are other XPINN or interface-related references:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2550,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"predict_xpinn|add_interface_lines|NUM_SUBDOMAINS|SHOW_INTERFACE|INTERFACE_AVERAGING\\\\\\\\\\\\\\\" in \\\\\\\\\\\\\\\"visualization/Plotting.py\\\\\\\\\\\\\\\" â€¢ 26 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2557,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY&#96; | L168 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2560,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;if INTERFACE_AVERAGING == 'mean':&#96; | L407 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2561,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;if INTERFACE_AVERAGING == 'mean' and len(nets) &gt; 1:&#96; | L416 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2563,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;def add_interface_lines(ax, xmin, xmax, ymin, ymax):&#96; | L436 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2564,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;if not SHOW_INTERFACE_LINES or NUM_SUBDOMAINS_X == 1 and NUM_SUBDOMAINS_Y == 1:&#96; | L444 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2572,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;add_interface_lines(ax, xmin, xmax, ymin, ymax)&#96; | L713 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2577,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;add_interface_lines(ax, xmin, xmax, ymin, ymax)&#96; | L929 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2578,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;add_interface_lines(ax, xmin, xmax, ymin, ymax)&#96; | L937 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2582,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;add_interface_lines(ax_pinn, xmin, xmax, ymin, ymax)&#96; | L2606 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2590,\\\\\\\"content\\\\\\\":\\\\\\\"I see there are many calls to predict_xpinn and add_interface_lines. Since the file is very large and we're removing XPINN entirely, let me update the imports first, then remove the functions, then replace all calls with standard single network prediction. Let me start:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2605,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2638,\\\\\\\"content\\\\\\\":\\\\\\\"-     For points at interfaces, combines predictions using configured averaging method.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2653,\\\\\\\"content\\\\\\\":\\\\\\\"-     import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2695,\\\\\\\"content\\\\\\\":\\\\\\\"-             if INTERFACE_AVERAGING == 'mean':\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2703,\\\\\\\"content\\\\\\\":\\\\\\\"-     # This automatically handles interface points by averaging\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2704,\\\\\\\"content\\\\\\\":\\\\\\\"-     if INTERFACE_AVERAGING == 'mean' and len(nets) &amp;gt; 1:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2731,\\\\\\\"content\\\\\\\":\\\\\\\"  def add_interface_lines(ax, xmin, xmax, ymin, ymax):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2733,\\\\\\\"content\\\\\\\":\\\\\\\"-     Add interface lines to plot showing subdomain boundaries.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2740,\\\\\\\"content\\\\\\\":\\\\\\\"-     if not SHOW_INTERFACE_LINES or NUM_SUBDOMAINS_X == 1 and NUM_SUBDOMAINS_Y == 1:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2749,\\\\\\\"content\\\\\\\":\\\\\\\"-         x_interface = xmin + i * dx\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2750,\\\\\\\"content\\\\\\\":\\\\\\\"-         ax.axvline(x=x_interface, color='white', linestyle='--', linewidth=1.5, alpha=0.7, label='Interface' if i == 1 else '')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2754,\\\\\\\"content\\\\\\\":\\\\\\\"-         y_interface = ymin + j * dy\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2755,\\\\\\\"content\\\\\\\":\\\\\\\"-         ax.axhline(y=y_interface, color='white', linestyle='--', linewidth=1.5, alpha=0.7)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2760,\\\\\\\"content\\\\\\\":\\\\\\\"-         if 'Interface' in labels:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2766,\\\\\\\"content\\\\\\\":\\\\\\\"              # Only show interface label once\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2783,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2830,\\\\\\\"content\\\\\\\":\\\\\\\"- # - xpinn_decomposition: Domain decomposition (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2865,\\\\\\\"content\\\\\\\":\\\\\\\"- ## XPINN Domain Decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2869,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_INTERFACE&amp;#96;: Number of interface collocation points per interface\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2873,\\\\\\\"content\\\\\\\":\\\\\\\"- ## Interface Loss Weights\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2874,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;INTERFACE_SOLUTION_WEIGHT&amp;#96;: Weight for solution continuity at interfaces\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2875,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;INTERFACE_RESIDUAL_WEIGHT&amp;#96;: Weight for residual continuity at interfaces\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2876,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;INTERFACE_SOLUTION_COMPONENTS&amp;#96;: Which solution components to enforce continuity for\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2898,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;SHOW_INTERFACE_LINES&amp;#96;: Whether to draw subdomain boundaries in plots\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2899,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;INTERFACE_AVERAGING&amp;#96;: Method to combine overlapping predictions at interfaces ('mean', 'weighted', 'subdomain1', 'subdomain2')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2938,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2977,\\\\\\\"content\\\\\\\":\\\\\\\"I have successfully removed all causal training and XPINN domain decomposition code from your codebase. Here's what was done:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2981,\\\\\\\"content\\\\\\\":\\\\\\\"2. **&#96;methods/xpinn_decomposition.py&#96;** - Complete XPINN domain decomposition module (470 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2987,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed all &#96;XPINN_*&#96;, &#96;USE_XPINN&#96;, &#96;NUM_SUBDOMAINS_*&#96;, &#96;INTERFACE_*&#96;, &#96;SUBDOMAIN_CONFIGS&#96; parameters (31 lines, lines 113-143)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3015,\\\\\\\"content\\\\\\\":\\\\\\\"   - Replaced &#96;add_interface_lines&#96; function with no-op for compatibility\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3022,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed comments about causal_training and xpinn_decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3035,\\\\\\\"content\\\\\\\":\\\\\\\"The codebase is now streamlined to focus exclusively on standard Physics-Informed Neural Networks without the complexity of domain decomposition or causal training features.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3168,\\\\\\\"content\\\\\\\":\\\\\\\"I see the problem - when I replaced the &#96;add_interface_lines&#96; function, I didn't remove all the old code. There's leftover code after the &#96;pass&#96; statement. Let me fix it:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3183,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Only show interface label once\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3233,\\\\\\\"content\\\\\\\":\\\\\\\"-     (\\\\\\\\\\\\\\\"methods/xpinn_decomposition.py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"methods.xpinn_decomposition\\\\\\\\\\\\\\\"),\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3246,\\\\\\\"content\\\\\\\":\\\\\\\"- &#96;(\\\\\\\\\\\\\\\"methods/xpinn_decomposition.py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"methods.xpinn_decomposition\\\\\\\\\\\\\\\")&#96;\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-08_17-39Z-icml-paper-latex-formatting.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":1394,\\\\\\\"content\\\\\\\":\\\\\\\"2. XPINN domain decomposition for scalability\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1411,\\\\\\\"content\\\\\\\":\\\\\\\"Simulating the evolution of cosmological density perturbations governed by self-gravitating fluid dynamics remains computationally expensive, particularly for long-time integration with complex initial conditions. We introduce GRINN (Gravitational Residual-Informed Neural Networks), a physics-informed neural network framework that learns to solve the coupled Euler-Poisson system for density, velocity, and gravitational potential fields without requiring numerical grid-based solvers. Our approach integrates several key innovations: extended PINN (XPINN) domain decomposition for spatial scalability, causal training strategies with temporal curriculum learning for accurate long-time evolution, and a pure neural method for enforcing the Poisson equation at initial conditions. We demonstrate that GRINN achieves competitive accuracy compared to traditional finite-difference methods while naturally handling complex power spectrum initial conditions and avoiding the stability constraints of ex [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":379,\\\\\\\"content\\\\\\\":\\\\\\\"def add_interface_lines(ax, xmin, xmax, ymin, ymax):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":634,\\\\\\\"content\\\\\\\":\\\\\\\"    # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":636,\\\\\\\"content\\\\\\\":\\\\\\\"        add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":850,\\\\\\\"content\\\\\\\":\\\\\\\"            # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":852,\\\\\\\"content\\\\\\\":\\\\\\\"                add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":858,\\\\\\\"content\\\\\\\":\\\\\\\"            # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":860,\\\\\\\"content\\\\\\\":\\\\\\\"                add_interface_lines(ax, xmin, xmax, ymin, ymax)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2571,\\\\\\\"content\\\\\\\":\\\\\\\"        # Add interface lines for XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2573,\\\\\\\"content\\\\\\\":\\\\\\\"            add_interface_lines(ax_pinn, xmin, xmax, ymin, ymax)\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"single PINN and XPINN decomposition training.\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":264,\\\\\\\"content\\\\\\\":\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":274,\\\\\\\"content\\\\\\\":\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\DIAGNOSTICS_GUIDE.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"- Late-time failures â†’ Try causal training, time-marching, or domain decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":196,\\\\\\\"content\\\\\\\":\\\\\\\"- **Solution**: Causal training, time-marching, domain decomposition in time\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":385,\\\\\\\"totalMatchedLines\\\\\\\":385}}}}}\\\"},\\\"capabilityType\\\":15}\",\"260acfff-29a5-4a29-833d-5e109987abeb\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"01ee9fd8-a9d9-4f15-a628-b0a17755e9c5\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_847dd19e-6f2c-48ac-a565-dd5fd866607\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_847dd19e-6f2c-48ac-a565-dd5fd866607\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"methods\\\\\\\\\\\\\\\\.xpinn|xpinn_decomposition\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_847dd19e-6f2c-48ac-a565-dd5fd866607\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"methods\\\\\\\\\\\\\\\\.xpinn|xpinn_decomposition\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"methods\\\\\\\\\\\\\\\\.xpinn|xpinn_decomposition\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2774,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2803,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4522,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4551,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":61,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L305-409 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":62,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L308-439 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":63,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L284-369 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":65,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L41 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":70,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;methods/xpinn_decomposition.py&#96; | L372-468 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":116,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;.\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\xpinn_decomposition.py&#96; |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":146,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;details&gt;&lt;summary&gt;Tool use: **read_file** â€¢ Read file: methods/xpinn_decomposition.py&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":175,\\\\\\\"content\\\\\\\":\\\\\\\"&lt;summary&gt;Tool use: **grep** â€¢ Grep for \\\\\\\\\\\\\\\"from methods\\\\\\\\\\\\\\\\.causal_training|from methods\\\\\\\\\\\\\\\\.xpinn_decomposition\\\\\\\\\\\\\\\" â€¢ 3 matches&lt;/summary&gt;\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":258,\\\\\\\"content\\\\\\\":\\\\\\\"      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete causal_training.py and xpinn_decomposition.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":322,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete causal_training.py and xpinn_decomposition.py\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":395,\\\\\\\"content\\\\\\\":\\\\\\\"1. Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":415,\\\\\\\"content\\\\\\\":\\\\\\\"- [-] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":458,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":561,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":615,\\\\\\\"content\\\\\\\":\\\\\\\"- import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":616,\\\\\\\"content\\\\\\\":\\\\\\\"- from methods.xpinn_decomposition import (setup_xpinn_devices, setup_xpinn_networks,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1223,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1698,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2169,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2489,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2653,\\\\\\\"content\\\\\\\":\\\\\\\"-     import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2783,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2830,\\\\\\\"content\\\\\\\":\\\\\\\"- # - xpinn_decomposition: Domain decomposition (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2938,\\\\\\\"content\\\\\\\":\\\\\\\"- [x] Delete causal_training.py and xpinn_decomposition.py\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2981,\\\\\\\"content\\\\\\\":\\\\\\\"2. **&#96;methods/xpinn_decomposition.py&#96;** - Complete XPINN domain decomposition module (470 lines)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3022,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed comments about causal_training and xpinn_decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3233,\\\\\\\"content\\\\\\\":\\\\\\\"-     (\\\\\\\\\\\\\\\"methods/xpinn_decomposition.py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"methods.xpinn_decomposition\\\\\\\\\\\\\\\"),\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3246,\\\\\\\"content\\\\\\\":\\\\\\\"- &#96;(\\\\\\\\\\\\\\\"methods/xpinn_decomposition.py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"methods.xpinn_decomposition\\\\\\\\\\\\\\\")&#96;\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":264,\\\\\\\"content\\\\\\\":\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":274,\\\\\\\"content\\\\\\\":\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":35,\\\\\\\"totalMatchedLines\\\\\\\":35}}}}}\\\"},\\\"capabilityType\\\":15}\",\"d469619f-9a4b-478c-936d-10ed3be3c82d\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"8df3f61d-9549-4182-a9c2-22c5dea30afd\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_017bafaa-708f-4cf0-aa09-535b72461ea\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_017bafaa-708f-4cf0-aa09-535b72461ea\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\\\\\\\\\\__init__.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"# Enhancement methods for PINN training\\\\\\\\n\\\\\\\\n\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":3}\\\"},\\\"capabilityType\\\":15}\",\"ddfe2c9e-bb47-425a-b3fb-c7854ef9012f\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"863892b5-5bc7-465a-bc37-b9395f79d5c3\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_00ece492-42ae-41a6-aefe-0c0b1ac8ec9\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_00ece492-42ae-41a6-aefe-0c0b1ac8ec9\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":422}\\\"},\\\"capabilityType\\\":15}\",\"42ac6f28-3deb-431b-8014-c5debaa44083\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"ea7c0de5-214d-4bca-bc10-4e735ece99f3\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_0cc5e5eb-cdf6-455e-8cba-4b816f4f7a5\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_0cc5e5eb-cdf6-455e-8cba-4b816f4f7a5\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"from core.data_generator import col_gen\\\\\\\\nfrom core.data_generator import diff\\\\\\\\n\\\\\\\\nimport numpy as np\\\\\\\\n\\\\\\\\nimport torch\\\\\\\\nimport torch.nn as nn\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\nfrom config import cs, const, G, rho_o\\\\\\\\n\\\\\\\\nclass ASTPN(col_gen):\\\\\\\\n    \\\\\\\\n    def __init__(self, rmin=[0,0,0,0], rmax=[1,1,1,1], N_0 = 1000, N_b=1000, N_r=3000, dimension=1):\\\\\\\\n        super().__init__(rmin,rmax, N_0,0,N_r, dimension)  # N_b set to 0 due to hard constraints\\\\\\\\n        \\\\\\\\n       \\\\\\\\n        self.coord_Lx, self.coord_Rx = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=1)\\\\\\\\n        \\\\\\\\n        if dimension == 2:\\\\\\\\n            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\\n\\\\\\\\n        if dimension == 3:\\\\\\\\n            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\\n            self.coord_Lz, self.coord_Rz = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=3)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef pde_residue(colloc, net, dimension = 1):\\\\\\\\n    \\\\\\\\n    '''\\\\\\\\n    This is the main function that returns all the PDE residue\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        colloc: Collocation points\\\\\\\\n        net: Neural network\\\\\\\\n        dimension: Spatial dimension (1, 2, or 3)\\\\\\\\n    '''\\\\\\\\n    \\\\\\\\n    return pde_residue_standard(colloc, net, dimension)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef pde_residue_standard(colloc, net, dimension = 1):\\\\\\\\n    \\\\\\\\n    '''\\\\\\\\n    Standard PDE residues (network predicts rho directly)\\\\\\\\n    '''\\\\\\\\n    net_outputs = net(colloc)\\\\\\\\n    \\\\\\\\n    x = colloc[0]\\\\\\\\n    \\\\\\\\n    if dimension == 1:\\\\\\\\n        t = colloc[1]\\\\\\\\n\\\\\\\\n    elif dimension == 2:\\\\\\\\n        y = colloc[1]\\\\\\\\n        t = colloc[2]\\\\\\\\n\\\\\\\\n    elif dimension == 3:\\\\\\\\n        y = colloc[1]\\\\\\\\n        z = colloc[2]\\\\\\\\n        t = colloc[3]\\\\\\\\n    \\\\\\\\n    rho, vx = net_outputs[:,0:1], net_outputs[:,1:2]\\\\\\\\n\\\\\\\\n    if dimension == 1:\\\\\\\\n\\\\\\\\n        phi = net_outputs[:,2:3]\\\\\\\\n\\\\\\\\n        rho_t = diff(rho,t,order=1)  \\\\\\\\n        rho_x = diff(rho,x,order=1)\\\\\\\\n\\\\\\\\n        vx_t = diff(vx, t,order=1)\\\\\\\\n        vx_x = diff(vx, x,order=1)\\\\\\\\n        \\\\\\\\n        phi_x = diff(phi,x,order=1)\\\\\\\\n        phi_x_x = diff(phi,x,order=2)\\\\\\\\n\\\\\\\\n    elif dimension == 2:\\\\\\\\n\\\\\\\\n        vy = net_outputs[:,2:3]\\\\\\\\n        phi = net_outputs[:,3:4]\\\\\\\\n\\\\\\\\n        rho_t = diff(rho,t,order=1)  \\\\\\\\n        rho_x = diff(rho,x,order=1)\\\\\\\\n        rho_y = diff(rho,y,order=1)\\\\\\\\n\\\\\\\\n        vx_t = diff(vx, t,order=1)\\\\\\\\n        vy_t = diff(vy, t,order=1)\\\\\\\\n\\\\\\\\n        vx_x = diff(vx, x,order=1)\\\\\\\\n        vx_y = diff(vx, y,order=1)\\\\\\\\n        vy_x = diff(vy, x,order=1)\\\\\\\\n        vy_y = diff(vy, y,order=1)\\\\\\\\n        \\\\\\\\n        phi_x = diff(phi,x,order=1)\\\\\\\\n        phi_x_x = diff(phi,x,order=2)\\\\\\\\n\\\\\\\\n        phi_y = diff(phi,y,order=1)\\\\\\\\n        phi_y_y = diff(phi,y,order=2)\\\\\\\\n\\\\\\\\n    elif dimension == 3:\\\\\\\\n        vy = net_outputs[:,2:3]\\\\\\\\n        vz = net_outputs[:,3:4]\\\\\\\\n        phi = net_outputs[:,4:5]\\\\\\\\n\\\\\\\\n        rho_t = diff(rho,t,order=1)  \\\\\\\\n        rho_x = diff(rho,x,order=1)\\\\\\\\n        rho_y = diff(rho,y,order=1)\\\\\\\\n        rho_z = diff(rho,z,order=1)\\\\\\\\n\\\\\\\\n        vx_t = diff(vx, t,order=1)\\\\\\\\n        vy_t = diff(vy, t,order=1)\\\\\\\\n        vz_t = diff(vz, t,order=1)\\\\\\\\n\\\\\\\\n        vx_x = diff(vx, x,order=1)\\\\\\\\n        vy_x = diff(vy, x,order=1)\\\\\\\\n        vz_x = diff(vz, x,order=1)\\\\\\\\n\\\\\\\\n        vx_y = diff(vx, y,order=1)\\\\\\\\n        vy_y = diff(vy, y,order=1)\\\\\\\\n        vz_y = diff(vz, y,order=1)\\\\\\\\n        \\\\\\\\n        vx_z = diff(vx, z,order=1)\\\\\\\\n        vy_z = diff(vy, z,order=1)\\\\\\\\n        vz_z = diff(vz, z,order=1)\\\\\\\\n        \\\\\\\\n        phi_x = diff(phi,x,order=1)\\\\\\\\n        phi_x_x = diff(phi,x,order=2)\\\\\\\\n\\\\\\\\n        phi_y = diff(phi,y,order=1)\\\\\\\\n        phi_y_y = diff(phi,y,order=2)\\\\\\\\n    \\\\\\\\n        phi_z = diff(phi,z,order=1)\\\\\\\\n        phi_z_z = diff(phi,z,order=2)\\\\\\\\n\\\\\\\\n    \\\\\\\\n    ## The residues from the equations\\\\\\\\n\\\\\\\\n    if dimension == 1:\\\\\\\\n        rho_r = rho_t + vx * rho_x + rho * vx_x\\\\\\\\n        vx_r = rho*vx_t + rho*(vx*vx_x) + cs*cs*rho_x +rho*phi_x\\\\\\\\n        phi_r = phi_x_x - const*(rho - rho_o)\\\\\\\\n\\\\\\\\n        return rho_r, vx_r, phi_r\\\\\\\\n\\\\\\\\n    elif dimension == 2:\\\\\\\\n        rho_r = rho_t + vx * rho_x + vy * rho_y + rho * vx_x + rho * vy_y\\\\\\\\n        vx_r = rho*vx_t + rho*(vx*vx_x + vy*vx_y) + cs*cs*rho_x + rho*phi_x\\\\\\\\n        vy_r = rho*vy_t + rho*(vy*vy_y + vx*vy_x) + cs*cs*rho_y + rho*phi_y\\\\\\\\n        phi_r = phi_x_x + phi_y_y - const*(rho - rho_o)\\\\\\\\n\\\\\\\\n        return rho_r, vx_r, vy_r, phi_r\\\\\\\\n    \\\\\\\\n    elif dimension == 3:\\\\\\\\n        rho_r = rho_t + vx * rho_x + rho * vx_x + vy *rho_y + rho * vy_y + vz *rho_z +rho * vz_z\\\\\\\\n        vx_r = rho*vx_t + rho*(vx*vx_x + vy*vx_y+vz*vx_z) + cs*cs*rho_x + rho*phi_x\\\\\\\\n        vy_r = rho*vy_t + rho*(vy*vy_y + vx*vy_x+vz*vy_z) + cs*cs*rho_y + rho*phi_y\\\\\\\\n        vz_r = rho*vz_t + rho*(vz*vz_z + vx*vz_x+vy*vz_y) + cs*cs*rho_z + rho*phi_z\\\\\\\\n        phi_r = phi_x_x + phi_y_y +phi_z_z - const*(rho - rho_o)\\\\\\\\n        \\\\\\\\n        return rho_r,vx_r,vy_r,vz_r,phi_r\\\\\\\\n\\\\\\\\n\\\\\\\\ndef poisson_residue_only(colloc, net, dimension=1):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Compute only the Poisson equation residual: âˆ‡Â²Ï† - const*(Ï - Ïâ‚€)\\\\\\\\n    \\\\\\\\n    This is used for extra enforcement at t=0 (Option 3: Pure ML approach).\\\\\\\\n    By evaluating Poisson residual on many t=0 points, we ensure Ï† is \\\\\\\\n    correctly initialized without using numerical solvers.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        colloc: Collocation points [x, (y), (z), t]\\\\\\\\n        net: Neural network\\\\\\\\n        dimension: Spatial dimension (1, 2, or 3)\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        phi_r: Poisson residual tensor\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    net_outputs = net(colloc)\\\\\\\\n    \\\\\\\\n    x = colloc[0]\\\\\\\\n    \\\\\\\\n    if dimension == 1:\\\\\\\\n        t = colloc[1]\\\\\\\\n        phi = net_outputs[:, 2:3]\\\\\\\\n        phi_x_x = diff(phi, x, order=2)\\\\\\\\n        \\\\\\\\n    elif dimension == 2:\\\\\\\\n        y = colloc[1]\\\\\\\\n        t = colloc[2]\\\\\\\\n        phi = net_outputs[:, 3:4]\\\\\\\\n        phi_x_x = diff(phi, x, order=2)\\\\\\\\n        phi_y_y = diff(phi, y, order=2)\\\\\\\\n        \\\\\\\\n    elif dimension == 3:\\\\\\\\n        y = colloc[1]\\\\\\\\n        z = colloc[2]\\\\\\\\n        t = colloc[3]\\\\\\\\n        phi = net_outputs[:, 4:5]\\\\\\\\n        phi_x_x = diff(phi, x, order=2)\\\\\\\\n        phi_y_y = diff(phi, y, order=2)\\\\\\\\n        phi_z_z = diff(phi, z, order=2)\\\\\\\\n    \\\\\\\\n    # Get density\\\\\\\\n    rho = net_outputs[:, 0:1]\\\\\\\\n    \\\\\\\\n    # Compute Poisson residual\\\\\\\\n    if dimension == 1:\\\\\\\\n        phi_r = phi_x_x - const*(rho - rho_o)\\\\\\\\n    elif dimension == 2:\\\\\\\\n        phi_r = phi_x_x + phi_y_y - const*(rho - rho_o)\\\\\\\\n    elif dimension == 3:\\\\\\\\n        phi_r = phi_x_x + phi_y_y + phi_z_z - const*(rho - rho_o)\\\\\\\\n    \\\\\\\\n    return phi_r\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":215}\\\"},\\\"capabilityType\\\":15}\",\"80762fd5-91e2-480d-b9cc-8b63fd09fcc0\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"85ca09e6-dbb6-42a6-9975-24c828436235\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_aa6491d9-eee7-4e68-95da-2c56bfd4f13\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_aa6491d9-eee7-4e68-95da-2c56bfd4f13\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":443}\\\"},\\\"capabilityType\\\":15}\",\"6b6dfe1a-fb86-4d25-9428-cd70f1f30dfa\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"4e8292c3-c650-4e0c-9222-040bb16c3d78\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_0fcf2a56-f235-462e-9b9b-6ca99824103\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_0fcf2a56-f235-462e-9b9b-6ca99824103\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\physics.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":701}\\\"},\\\"capabilityType\\\":15}\",\"ba3d4c12-b704-42f0-8a22-8c49169685cf\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"9cdedc9d-1ae8-4dcc-8438-173f507b8f72\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nChecking for commented-out XPINN code and exploring the methods directory:\\\\n\\\"}\",\"7796a49f-d997-402c-a4e7-a034c17aa499\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"6d8e1c30-cf0b-4e44-9358-7845fca04252\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_05d4aec9-7635-4311-b051-a2c075e719b\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_05d4aec9-7635-4311-b051-a2c075e719b\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"list_dir_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\",\\\\\\\"ignore\\\\\\\":[],\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_05d4aec9-7635-4311-b051-a2c075e719b\\\\\\\"}\\\",\\\"tool\\\":39,\\\"params\\\":\\\"{\\\\\\\"targetDirectory\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"directoryTreeRoot\\\\\\\":{\\\\\\\"absPath\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\methods\\\\\\\",\\\\\\\"childrenFiles\\\\\\\":[{\\\\\\\"name\\\\\\\":\\\\\\\"__init__.py\\\\\\\"}],\\\\\\\"childrenWereProcessed\\\\\\\":true}}\\\"},\\\"capabilityType\\\":15}\",\"3ee58c4e-2c65-47e8-b7b9-36d3b67feba6\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"55928361-5406-453b-a69e-26ba900f3c86\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.719Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_bb82dbb2-ddcf-40d7-9141-6c6ad5d3b1d\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_bb82dbb2-ddcf-40d7-9141-6c6ad5d3b1d\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"#.*XPINN|#.*xpinn|#.*subdomain|#.*domain.*decomp\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_bb82dbb2-ddcf-40d7-9141-6c6ad5d3b1d\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"#.*XPINN|#.*xpinn|#.*subdomain|#.*domain.*decomp\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"#.*XPINN|#.*xpinn|#.*subdomain|#.*domain.*decomp\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_18-49Z-xpinn-domain-decomposition-for-pinn.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"# XPINN domain decomposition for PINN (2026-02-08 18:49Z)\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-13Z-pinn-and-lax-solver-comparison.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_01Ge7Gp3bAyP6gPHvnm5Xage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2181a25a-ff2a-4ce1-a9d1-d46ecaab11f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c3b0e4e0-e73f-4892-8e4d-03cc82eb0ea8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"34bfe595-59cb-4523-bff5-3f4300330ed0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"33540af8-647a-4e47-82a4-9cdb1e12ed91\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a711058d-5b60-4bd9-aadb-bbcdf5a05997\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f2453eb5-db26-4a76-a33d-fd8c048e33e7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"80d06c8b-c1a8-43d0-a429-96e1a89e3d9b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ca1c992e-415f-4d0f-8865-aa6db3640726\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"9abf266b-2593-4837-8938-c423f6d17585\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"29295441-351f-480f-9a9b-386f8377b75b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"99fb6f39-d980-49ff-8f5c-57e29b5c79f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ebaedb63-e0c4-4546-a7f6-c32f773c06d6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a907e52a-dd [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-17Z-explore-project-structure-and-physics.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":1451,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1467,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4562,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5654,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"-             # Helper to compute and print a detailed loss breakdown for this subdomain (no grad)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5686,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"+     # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5702,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"      # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":5816,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\"\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2629,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4377,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6299,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6754,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14717,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":14968,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15234,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15258,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":15734,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Handle both single network and list of networks (XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":16265,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        # Add interface lines for XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17112,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17363,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17629,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":17653,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"            # Add interface lines if using XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18129,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    # Handle both single network and list of networks (XPINN)\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18660,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        # Add interface lines for XPINN\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":31077,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_019aNmsGakgw5VbE2Soqf7P3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b530dce-d1e9-4fc1-a61b-33f822115c6a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a89bb8c4-b830-4dca-a69b-74bdc6bbb79e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"49c90654-5f1c-487e-8e5d-01d0e7d99f87\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b8e7ad8-4676-4a3a-bf19-c48fae4dbbb7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f6a38903-c908-4c54-b5a4-801a38b9c87a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"90a27c62-d770-447d-be4d-1cd0669127f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"4ac40ee8-f125-44bc-bc87-3352c7db6894\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"02473f18-b861-43a0-95c0-b4271492196e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2}],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conversationMap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"approximateLintErrors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"lints\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"codebaseContextChunks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pullRequests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"atta [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-05Z-3d-power-spectrum-comparison-plot-verification.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":543,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":576,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":623,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":635,\\\\\\\"content\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"diffString\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"          pt_x = Variable(torch.from_numpy(X).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n          pt_y = Variable(torch.from_numpy(Y).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n-         pt_z = Variable(torch.from_numpy(Z).float(), requires_grad=True).to(device) if Z is not None else None\\\\\\\\\\\\\\\\n+         # For 3D power spectrum, align PINN z-slice with cached FD z\\\\\\\\\\\\\\\\n+         if Z is not None and fd_cache is not None and t in fd_cache and DIMENSION == 3:\\\\\\\\\\\\\\\\n+             z_val_use = fd_cache[t].get('z_val', SLICE_Z)\\\\\\\\\\\\\\\\n+             Z_use = z_val_use * np.ones_like(X)\\\\\\\\\\\\\\\\n+             pt_z = Variable(torch.from_numpy(Z_use).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n+         else:\\\\\\\\\\\\\\\\n+             pt_z = Variable(torch.from_numpy(Z).float(), requires_grad=True).to(device) if Z is not None else None\\\\\\\\\\\\\\\\n          pt_t = Variable(torch.from_numpy(t_arr).float(), requires_grad=True).to(device)\\\\\\\\\\\\\\\\n          if use_xpinn:\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":648,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":697,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":722,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1237,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1279,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1321,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1363,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1405,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1430,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-21_18-45Z-grinn-paper-limitations-and-future-scope.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":125,\\\\\\\"content\\\\\\\":\\\\\\\"### a) **Domain Decomposition (XPINN-style)**\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-18_16-33Z-high-tmax-pinn-performance-issues.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":287,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several ideas and strategies (drawn from recent papers) you can try to mitigate the strong degradation of PINN performance as \\\\\\\\\\\\\\\\( t_\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\max\\\\\\\\\\\\\\\\} \\\\\\\\\\\\\\\\) increases. These suggestions address issues surfaced in your diagnostics (overâ€smoothing, lossâ€ofâ€spectral power, conservation violations, momentum drift), and are mostly conceptualâ€”so you can evaluate which to try without implementing all of them.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Key Strategies from Recent Literature&lt;br/&gt;&lt;br/&gt;### 1. Enforce Temporal Causality via Sequential or Timeâ€Segmented Training&lt;br/&gt;&lt;br/&gt;**What they do**: instead of training a single network over the whole time domain at once, divide the time interval into subintervals, train sequentially, or have separate networks over subâ€intervals, sometimes with transfer learning or continuity constraints between them. ([sciencedirect.com](https://www.sciencedirect.com/science/article/abs/pii/S0045782524002925?utm_source=openai))&lt;br/&gt;&lt;br/&gt;**Why it helps**: fo [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":300,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several well-vetted ideas from recent research that could help mitigate the failure modes you observed when \\\\\\\\\\\\\\\\(t_\\\\\\\\\\\\\\\\{\\\\\\\\\\\\\\\\max\\\\\\\\\\\\\\\\}\\\\\\\\\\\\\\\\) is highâ€”especially over-smoothing, momentum drift, and loss of dynamic richness. You asked for no code; I focus on high-level strategies and references.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Diagnostics â†’ What to Aim For&lt;br/&gt;&lt;br/&gt;Based on your failure â€” perturbations collapsing toward a near-uniform state, severe drift in conserved quantities, spectral power loss â€” the strategies below target:&lt;br/&gt;&lt;br/&gt;- restoring sensitivity to **high frequencies / growing modes**  &lt;br/&gt;- improving conservation of **mass, momentum, etc.**  &lt;br/&gt;- ensuring **temporal causality** so that errors donâ€™t accumulate disproportionately at later times  &lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## Mitigation Strategies&lt;br/&gt;&lt;br/&gt;Below are methods, grouped by theme, with pros/cons, as seen in recent literature.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;### 1. Enforcing Conservation Laws Hard&lt;br/&gt;&lt;br/&gt;Since mo [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":313,\\\\\\\"content\\\\\\\":\\\\\\\"| Web Search Results |  | Here are several broad strategies drawn from recent work that could help mitigate the failure modes you observed when extending tmax. I include **what** they change (loss, sampling, architecture, etc.), **why** they might help, and **trade-offs or caveats**. No codeâ€”just concepts and design levers so you can prioritize which seem promising.&lt;br/&gt;&lt;br/&gt;---&lt;br/&gt;&lt;br/&gt;## What seems to go wrong when tmax increases&lt;br/&gt;&lt;br/&gt;From your diagnostics:  &lt;br/&gt;- The solution over time collapses toward smooth, nearly uniform states (â€œdamping outâ€ perturbations).  &lt;br/&gt;- Conservation laws (especially momentum) degrade significantly even when lower tmax works.  &lt;br/&gt;- The laterâ€time PDE residuals dominate, but earlier times are not learned well (loss imbalance).  &lt;br/&gt;&lt;br/&gt;So you want methods that **(i)** preserve perturbation growth or dynamics over time, **(ii)** enforce conservation laws more strictly, and **(iii)** distribute learning effort across time (making later times n [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":5,\\\\\\\"content\\\\\\\":\\\\\\\"# Causal training and XPinn configuration cleanup (2026-01-14 06:30Z)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":515,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== XPINN Domain Decomposition Configuration ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":516,\\\\\\\"content\\\\\\\":\\\\\\\"- USE_XPINN = False  # Toggle XPINN on/off (False = original single PINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":517,\\\\\\\"content\\\\\\\":\\\\\\\"- NUM_SUBDOMAINS_X = 2  # Subdomain splits in x-direction (1 = no split)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":518,\\\\\\\"content\\\\\\\":\\\\\\\"- NUM_SUBDOMAINS_Y = 2  # Subdomain splits in y-direction (1 = no split)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":521,\\\\\\\"content\\\\\\\":\\\\\\\"- N_r_PER_SUBDOMAIN = None  # Residual points per subdomain (None = auto-distribute N_r)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":522,\\\\\\\"content\\\\\\\":\\\\\\\"- N_0_PER_SUBDOMAIN = None  # IC points per subdomain (None = auto-distribute N_0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":534,\\\\\\\"content\\\\\\\":\\\\\\\"- # Set to None to use global defaults for all subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":536,\\\\\\\"content\\\\\\\":\\\\\\\"- DEFAULT_ACTIVATION = 'sin'  # Default activation (if not specified in SUBDOMAIN_CONFIGS)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":538,\\\\\\\"content\\\\\\\":\\\\\\\"- XPINN_OPTIMIZER_STRATEGY = 'unified'  # 'unified' = single optimizer, 'separate' = one per subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":539,\\\\\\\"content\\\\\\\":\\\\\\\"- XPINN_ALTERNATING_TRAINING = False  # True = alternate subdomains, False = simultaneous\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":540,\\\\\\\"content\\\\\\\":\\\\\\\"- USE_XPINN_BATCHING = False  # True = use mini-batch processing for XPINN (reduces GPU memory)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":541,\\\\\\\"content\\\\\\\":\\\\\\\"- USE_MULTI_GPU = True  # True = distribute subdomains across available GPUs\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":544,\\\\\\\"content\\\\\\\":\\\\\\\"- SHOW_INTERFACE_LINES = True  # Draw subdomain boundaries in plots\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":545,\\\\\\\"content\\\\\\\":\\\\\\\"- INTERFACE_AVERAGING = 'mean'  # Combine overlapping predictions: 'mean', 'weighted', 'subdomain1', 'subdomain2'\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":689,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== MODE SWITCHING: ORIGINAL PINN vs XPINN ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":880,\\\\\\\"content\\\\\\\":\\\\\\\"-     # ==================== XPINN MULTI-NETWORK MODE ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":883,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Calculate total number of subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":907,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Create XPINN loss model\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":953,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Cache IC values for each subdomain to avoid recomputation\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":963,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Multi-GPU: use per-subdomain optimizers to avoid cross-device gradient issues\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":965,\\\\\\\"content\\\\\\\":\\\\\\\"-         optimizer = None  # Will use per-subdomain optimizers in train_xpinn\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":978,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Train XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1073,\\\\\\\"content\\\\\\\":\\\\\\\"-             # For XPINN, optimizers might be None or per-subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1184,\\\\\\\"content\\\\\\\":\\\\\\\"-     # XPINN multi-network visualization\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1193,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Sinusoidal cross-section plot for XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1197,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Density growth plot for XPINN as well\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1382,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Determine if we need per-subdomain optimizers (multi-GPU case)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1386,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Multi-GPU: create separate Adam optimizer for each subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1398,\\\\\\\"content\\\\\\\":\\\\\\\"-             bs = max(1, bs_global // max(1, num_sub))  # per-subdomain batch size\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1418,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Per-subdomain Adam training (multi-GPU)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1419,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Process each subdomain completely independently to avoid graph sharing issues\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1422,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Track component losses across all subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1432,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Compute PDE and IC loss for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1456,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Accumulate all interface losses for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1463,\\\\\\\"content\\\\\\\":\\\\\\\"-                         # Only compute interface losses where this subdomain participates\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1473,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 # Backprop only to current subdomain's network\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1479,\\\\\\\"content\\\\\\\":\\\\\\\"-                                 else:  # sub_idx == subdomain_j\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1494,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Single backward pass for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1503,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Diagnostics for XPINN (aggregate) every 50 iterations\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1521,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Average component losses across subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1532,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Alternate between subdomains (not yet implemented - would need separate optimizers)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1538,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Diagnostics for XPINN unified every 50 iterations\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1562,\\\\\\\"content\\\\\\\":\\\\\\\"-     # L-BFGS training - per-subdomain optimization\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1563,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Each subdomain network is optimized separately while others are frozen\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1568,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Optimize each subdomain network separately\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1575,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Create optimizer for this subdomain only\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1579,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Create closure for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1580,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Computes loss for this subdomain + its interface losses\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1585,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Compute PDE and IC loss for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1595,\\\\\\\"content\\\\\\\":\\\\\\\"-                     # Add interface losses where this subdomain is involved\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1600,\\\\\\\"content\\\\\\\":\\\\\\\"-                         # Only compute interface losses where this subdomain participates\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1627,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Helper to compute and print a detailed loss breakdown for this subdomain (no grad)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1657,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Run L-BFGS for this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1672,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Generate diagnostic plots at the end of XPINN training\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2011,\\\\\\\"content\\\\\\\":\\\\\\\"- # ==================== XPINN Physics Calculations ====================\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2037,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Compute total XPINN loss (passing cached IC if available)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2085,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Get device from first subdomain's collocation points\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2089,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched subdomain collocation points (on correct devices)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2098,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched subdomain IC points and batched cached IC values\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2117,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Create batched interface collocation points (use device of first subdomain in pair)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2121,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Use device of first subdomain in the interface pair\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2148,\\\\\\\"content\\\\\\\":\\\\\\\"-     # For batched XPINN, we need to compute breakdown from the last batch\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2431,\\\\\\\"content\\\\\\\":\\\\\\\"-         # PDE and IC losses for each subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2661,\\\\\\\"content\\\\\\\":\\\\\\\"-     # If single subdomain, just evaluate directly\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2665,\\\\\\\"content\\\\\\\":\\\\\\\"-     # For each point, determine which subdomain(s) it belongs to\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2672,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Find points in this subdomain (with small tolerance for boundaries)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2678,\\\\\\\"content\\\\\\\":\\\\\\\"-             # Evaluate network for points in this subdomain\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2696,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # Add prediction (will average later if point is in multiple subdomains)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2699,\\\\\\\"content\\\\\\\":\\\\\\\"-                 # For other strategies, just use first subdomain's prediction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2702,\\\\\\\"content\\\\\\\":\\\\\\\"-     # For mean averaging, divide by number of subdomains that covered each point\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2705,\\\\\\\"content\\\\\\\":\\\\\\\"-         # Count how many subdomains covered each point\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2743,\\\\\\\"content\\\\\\\":\\\\\\\"-     # Calculate subdomain boundaries\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2764,\\\\\\\"content\\\\\\\":\\\\\\\"+     # XPINN removed - this function is now a no-op for compatibility\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2830,\\\\\\\"content\\\\\\\":\\\\\\\"- # - xpinn_decomposition: Domain decomposition (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2865,\\\\\\\"content\\\\\\\":\\\\\\\"- ## XPINN Domain Decomposition\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2866,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;USE_XPINN&amp;#96;: Toggle XPINN on/off (False = original single PINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2867,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;NUM_SUBDOMAINS_X&amp;#96;: Number of subdomain splits in x-direction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2868,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;NUM_SUBDOMAINS_Y&amp;#96;: Number of subdomain splits in y-direction\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2870,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_r_PER_SUBDOMAIN&amp;#96;: Residual points per subdomain (None = auto-distribute)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2871,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_0_PER_SUBDOMAIN&amp;#96;: IC points per subdomain (None = auto-distribute)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2878,\\\\\\\"content\\\\\\\":\\\\\\\"- ## Per-Subdomain Network Architecture\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2879,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;: List of dicts configuring each subdomain's network architecture (list or None)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2880,\\\\\\\"content\\\\\\\":\\\\\\\"-   - Format: &amp;#96;[{config_0}, {config_1}, ..., {config_N-1}]&amp;#96; where N = NUM_SUBDOMAINS_X Ã— NUM_SUBDOMAINS_Y\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2883,\\\\\\\"content\\\\\\\":\\\\\\\"-   - Set to &amp;#96;None&amp;#96; to use global defaults for all subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2885,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;DEFAULT_ACTIVATION&amp;#96;: Default activation function used when not specified in SUBDOMAIN_CONFIGS\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2888,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;XPINN_OPTIMIZER_STRATEGY&amp;#96;: Optimizer strategy ('unified' or 'separate')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2889,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;XPINN_ALTERNATING_TRAINING&amp;#96;: Whether to alternate subdomain training\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2890,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;USE_XPINN_BATCHING&amp;#96;: Whether to use mini-batch processing for XPINN (reduces GPU memory)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2891,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;USE_MULTI_GPU&amp;#96;: Whether to distribute subdomains across available GPUs\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2892,\\\\\\\"content\\\\\\\":\\\\\\\"-   - If &amp;#96;True&amp;#96;: Automatically detects available GPUs and assigns subdomains round-robin\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2898,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;SHOW_INTERFACE_LINES&amp;#96;: Whether to draw subdomain boundaries in plots\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2899,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;INTERFACE_AVERAGING&amp;#96;: Method to combine overlapping predictions at interfaces ('mean', 'weighted', 'subdomain1', 'subdomain2')\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3181,\\\\\\\"content\\\\\\\":\\\\\\\"      # XPINN removed - this function is now a no-op for compatibility\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":387,\\\\\\\"content\\\\\\\":\\\\\\\"    # XPINN removed - this function is now a no-op for compatibility\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":634,\\\\\\\"content\\\\\\\":\\\\\\\"    # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":850,\\\\\\\"content\\\\\\\":\\\\\\\"            # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":858,\\\\\\\"content\\\\\\\":\\\\\\\"            # Add interface lines if using XPINN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1569,\\\\\\\"content\\\\\\\":\\\\\\\"    # Handle both single network and list of networks (XPINN)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2571,\\\\\\\"content\\\\\\\":\\\\\\\"        # Add interface lines for XPINN\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":232,\\\\\\\"content\\\\\\\":\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":361,\\\\\\\"content\\\\\\\":\\\\\\\"    # If per-subdomain count is specified, use it\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":372,\\\\\\\"content\\\\\\\":\\\\\\\"    # Distribute remainder to first few subdomains\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":147,\\\\\\\"totalMatchedLines\\\\\\\":147}}}}}\\\"},\\\"capabilityType\\\":15}\",\"339dd4c8-ab45-4637-befd-9a96767b069b\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"08e30b25-450e-4d78-a409-db0f71343b7f\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.720Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_55ec0eeb-c6c7-49fb-b058-da560c348fa\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_55ec0eeb-c6c7-49fb-b058-da560c348fa\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"semantic_search_full\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"query\\\\\\\":\\\\\\\"Where are subdomain collocation points generated or used for domain decomposition?\\\\\\\",\\\\\\\"targetDirectories\\\\\\\":[],\\\\\\\"explanation\\\\\\\":\\\\\\\"\\\\\\\"}\\\",\\\"tool\\\":9,\\\"params\\\":\\\"{\\\\\\\"query\\\\\\\":\\\\\\\"Where are subdomain collocation points generated or used for domain decomposition?\\\\\\\",\\\\\\\"topK\\\\\\\":10,\\\\\\\"explanation\\\\\\\":\\\\\\\"\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"codeResults\\\\\\\":[{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\n\\\\\\\\n    \\\\\\\\n    def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Generate collocation points within a subdomain.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            option: \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\", or \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\"\\\\\\\\n            subdomain_bounds: Tuple (x_min, x_max, y_min, y_max) for 2D\\\\\\\\n            device: PyTorch device\\\\\\\\n            coordinate: For BC generation (1=x, 2=y)\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Collocation points list constrained to subdomain\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # For 2D (current focus)\\\\\\\\n        if self.dimension == 2:\\\\\\\\n            x_min, x_max, y_min, y_max = subdomain_bounds\\\\\\\\n            \\\\\\\\n            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\\n                coor = []\\\\\\\\n                x_dom = torch.empty(self.N_r, 1, device=device, dtype=torch.float32).uniform_(x_min, x_max).requires_grad_()\\\\\\\\n                y_dom = torch.empty(self.N_r, 1, device=device, dtype=torch.float32).uniform_(y_min, y_max).requires_grad_()\\\\\\\\n                t_dom = torch.empty(self.N_r, 1, device=device, dtype=torch.float32).uniform_(max(self.rmin[2], STARTUP_DT), self.rmax[2]).requires_grad_()\\\\\\\\n                coor.append(x_dom)\\\\\\\\n                coor.append(y_dom)\\\\\\\\n                coor.append(t_dom)\\\\\\\\n                return coor\\\\\\\\n            \\\\\\\\n            elif option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\\n                coor = []\\\\\\\\n                x_ic = torch.empty(self.N_0, 1, device=device, dtype=torch.float32).uniform_(x_min, x_max).requires_grad_()\\\\\\\\n                y_ic = torch.empty(self.N_0, 1, device=device, dtype=torch.float32).uniform_(y_min, y_max).requires_grad_()\\\\\\\\n                t_ic = torch.empty(self.N_0, 1, device=device, dtype=torch.float32).fill_(0).requires_grad_()\\\\\\\\n                coor.append(x_ic)\\\\\\\\n                coor.append(y_ic)\\\\\\\\n                coor.append(t_ic)\\\\\\\\n                return coor\\\\\\\\n            \\\\\\\\n            elif option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":28,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":29,\\\\\\\"column\\\\\\\":5}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":192},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":193},{\\\\\\\"text\\\\\\\":\\\\\\\"    def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":194},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":195},{\\\\\\\"text\\\\\\\":\\\\\\\"        Generate collocation points within a subdomain.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":196},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":197},{\\\\\\\"text\\\\\\\":\\\\\\\"        Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":198},{\\\\\\\"text\\\\\\\":\\\\\\\"            option: \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\", or \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":199},{\\\\\\\"text\\\\\\\":\\\\\\\"            subdomain_bounds: Tuple (x_min, x_max, y_min, y_max) for 2D\\\\\\\",\\\\\\\"lineNumber\\\\\\\":200},{\\\\\\\"text\\\\\\\":\\\\\\\"            device: PyTorch device\\\\\\\",\\\\\\\"lineNumber\\\\\\\":201},{\\\\\\\"text\\\\\\\":\\\\\\\"            coordinate: For BC generation (1=x, 2=y)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":202},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":203},{\\\\\\\"text\\\\\\\":\\\\\\\"        Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":204},{\\\\\\\"text\\\\\\\":\\\\\\\"            Collocation points list constrained to subdomain\\\\\\\",\\\\\\\"lineNumber\\\\\\\":205},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":206},{\\\\\\\"text\\\\\\\":\\\\\\\"        # For 2D (current focus)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":207},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":208},{\\\\\\\"text\\\\\\\":\\\\\\\"            x_min, x_max, y_min, y_max = subdomain_bounds\\\\\\\",\\\\\\\"lineNumber\\\\\\\":209},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":210},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":211},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":212},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_dom = torch.empty(self.N_r, 1, device=device, dtype=torch.float32).uniform_(x_min, x_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":213},{\\\\\\\"text\\\\\\\":\\\\\\\"                y_dom = torch.empty(self.N_r, 1, device=device, dtype=torch.float32).uniform_(y_min, y_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":214},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_dom = torch.empty(self.N_r, 1, device=device, dtype=torch.float32).uniform_(max(self.rmin[2], STARTUP_DT), self.rmax[2]).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":215},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor.append(x_dom)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":216},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor.append(y_dom)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":217},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor.append(t_dom)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":218},{\\\\\\\"text\\\\\\\":\\\\\\\"                return coor\\\\\\\",\\\\\\\"lineNumber\\\\\\\":219},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":220},{\\\\\\\"text\\\\\\\":\\\\\\\"            elif option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":221},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":222},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_ic = torch.empty(self.N_0, 1, device=device, dtype=torch.float32).uniform_(x_min, x_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":223},{\\\\\\\"text\\\\\\\":\\\\\\\"                y_ic = torch.empty(self.N_0, 1, device=device, dtype=torch.float32).uniform_(y_min, y_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":224},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_ic = torch.empty(self.N_0, 1, device=device, dtype=torch.float32).fill_(0).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":225},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor.append(x_ic)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":226},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor.append(y_ic)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":227},{\\\\\\\"text\\\\\\\":\\\\\\\"                coor.append(t_ic)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":228},{\\\\\\\"text\\\\\\\":\\\\\\\"                return coor\\\\\\\",\\\\\\\"lineNumber\\\\\\\":229},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":230},{\\\\\\\"text\\\\\\\":\\\\\\\"            elif option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":231}]},\\\\\\\"score\\\\\\\":0.4997791647911072},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":345,\\\\\\\"column\\\\\\\":23},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":421}},\\\\\\\"contents\\\\\\\":\\\\\\\"def distribute_collocation_points(n_total, num_subdomains):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Distribute collocation points across subdomains for XPINN.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        n_total: Total number of collocation points\\\\\\\\n        num_subdomains: Number of subdomains\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        List of point counts per subdomain\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    # If per-subdomain count is specified, use it\\\\\\\\n    if n_total == N_r_PER_SUBDOMAIN and N_r_PER_SUBDOMAIN is not None:\\\\\\\\n        return [N_r_PER_SUBDOMAIN] * num_subdomains\\\\\\\\n    elif n_total == N_0_PER_SUBDOMAIN and N_0_PER_SUBDOMAIN is not None:\\\\\\\\n        return [N_0_PER_SUBDOMAIN] * num_subdomains\\\\\\\\n    \\\\\\\\n    # Otherwise, auto-distribute evenly\\\\\\\\n    base_count = n_total // num_subdomains\\\\\\\\n    remainder = n_total % num_subdomains\\\\\\\\n    \\\\\\\\n    counts = [base_count] * num_subdomains\\\\\\\\n    # Distribute remainder to first few subdomains\\\\\\\\n    for i in range(remainder):\\\\\\\\n        counts[i] += 1\\\\\\\\n    \\\\\\\\n    return counts\\\\\\\\n\\\\\\\\n\\\\\\\\ndef generate_poisson_ic_points(rmin, rmax, n_points, dimension=2, device='cuda'):\\\\\\\\n    \\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def distribute_collocation_points(n_total, num_subdomains):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":349,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":350},{\\\\\\\"text\\\\\\\":\\\\\\\"    Distribute collocation points across subdomains for XPINN.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":351},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":352},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":353},{\\\\\\\"text\\\\\\\":\\\\\\\"        n_total: Total number of collocation points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":354},{\\\\\\\"text\\\\\\\":\\\\\\\"        num_subdomains: Number of subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":355},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":356},{\\\\\\\"text\\\\\\\":\\\\\\\"    Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":357},{\\\\\\\"text\\\\\\\":\\\\\\\"        List of point counts per subdomain\\\\\\\",\\\\\\\"lineNumber\\\\\\\":358},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":359},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":360},{\\\\\\\"text\\\\\\\":\\\\\\\"    # If per-subdomain count is specified, use it\\\\\\\",\\\\\\\"lineNumber\\\\\\\":361},{\\\\\\\"text\\\\\\\":\\\\\\\"    if n_total == N_r_PER_SUBDOMAIN and N_r_PER_SUBDOMAIN is not None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":362},{\\\\\\\"text\\\\\\\":\\\\\\\"        return [N_r_PER_SUBDOMAIN] * num_subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":363},{\\\\\\\"text\\\\\\\":\\\\\\\"    elif n_total == N_0_PER_SUBDOMAIN and N_0_PER_SUBDOMAIN is not None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":364},{\\\\\\\"text\\\\\\\":\\\\\\\"        return [N_0_PER_SUBDOMAIN] * num_subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":365},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":366},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Otherwise, auto-distribute evenly\\\\\\\",\\\\\\\"lineNumber\\\\\\\":367},{\\\\\\\"text\\\\\\\":\\\\\\\"    base_count = n_total // num_subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":368},{\\\\\\\"text\\\\\\\":\\\\\\\"    remainder = n_total % num_subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":369},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":370},{\\\\\\\"text\\\\\\\":\\\\\\\"    counts = [base_count] * num_subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":371},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Distribute remainder to first few subdomains\\\\\\\",\\\\\\\"lineNumber\\\\\\\":372},{\\\\\\\"text\\\\\\\":\\\\\\\"    for i in range(remainder):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":373},{\\\\\\\"text\\\\\\\":\\\\\\\"        counts[i] += 1\\\\\\\",\\\\\\\"lineNumber\\\\\\\":374},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":375},{\\\\\\\"text\\\\\\\":\\\\\\\"    return counts\\\\\\\",\\\\\\\"lineNumber\\\\\\\":376,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":377},{\\\\\\\"lineNumber\\\\\\\":378},{\\\\\\\"text\\\\\\\":\\\\\\\"def generate_poisson_ic_points(rmin, rmax, n_points, dimension=2, device='cuda'):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":379,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":380}]},\\\\\\\"score\\\\\\\":0.4779011011123657},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":24,\\\\\\\"column\\\\\\\":14},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Collocation point generator for PINNs.\\\\\\\\n    \\\\\\\\n    Generates collocation points for:\\\\\\\\n    - Domain (PDE enforcement)\\\\\\\\n    - Initial conditions (IC)\\\\\\\\n    - Boundary conditions (BC)\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        rmin: List of minimum values [xmin, ymin, zmin, tmin] (depending on dimension)\\\\\\\\n        rmax: List of maximum values [xmax, ymax, zmax, tmax] (depending on dimension)\\\\\\\\n        N_0: Number of initial condition collocation points\\\\\\\\n        N_b: Number of boundary condition points (per boundary)\\\\\\\\n        N_r: Number of residual/domain collocation points\\\\\\\\n        dimension: Spatial dimension (1, 2, or 3)\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, rmin = [0, 0, 0, 0], rmax = [1, 1, 1, 1], N_0 = 1000, N_b = 1000, N_r = 3000, dimension = 1):\\\\\\\\n        self.rmin = rmin\\\\\\\\n        self.rmax = rmax\\\\\\\\n        self.N_0 = N_0\\\\\\\\n        self.N_b = N_b\\\\\\\\n        self.N_r = N_r\\\\\\\\n        self.dimension = dimension\\\\\\\\n    \\\\\\\\n    def _generate_uniform_tensor(self, n_points, lower, upper, device = 'cuda', requires_grad = True):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Helper function to generate uniformly distributed tensor.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            n_points: Number of points to generate\\\\\\\\n            lower: Lower bound\\\\\\\\n            upper: Upper bound\\\\\\\\n            device: PyTorch device\\\\\\\\n            requires_grad: Whether tensor requires gradients\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Tensor of shape [n_points, 1]\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        tensor = torch.empty(n_points, 1, device = device, dtype = torch.float32).uniform_(lower, upper)\\\\\\\\n        if requires_grad:\\\\\\\\n            tensor = tensor.requires_grad_()\\\\\\\\n        return tensor\\\\\\\\n    \\\\\\\\n    def _generate_constant_tensor(self, n_points, value, device='cuda', requires_grad=True):\\\\\\\\n        \\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":29},{\\\\\\\"text\\\\\\\":\\\\\\\"    Collocation point generator for PINNs.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":30},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":31},{\\\\\\\"text\\\\\\\":\\\\\\\"    Generates collocation points for:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":32},{\\\\\\\"text\\\\\\\":\\\\\\\"    - Domain (PDE enforcement)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":33},{\\\\\\\"text\\\\\\\":\\\\\\\"    - Initial conditions (IC)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":34},{\\\\\\\"text\\\\\\\":\\\\\\\"    - Boundary conditions (BC)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":35},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":36},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":37},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmin: List of minimum values [xmin, ymin, zmin, tmin] (depending on dimension)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":38},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmax: List of maximum values [xmax, ymax, zmax, tmax] (depending on dimension)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":39},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_0: Number of initial condition collocation points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":40},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_b: Number of boundary condition points (per boundary)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":41},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_r: Number of residual/domain collocation points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":42},{\\\\\\\"text\\\\\\\":\\\\\\\"        dimension: Spatial dimension (1, 2, or 3)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":43},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":44},{\\\\\\\"lineNumber\\\\\\\":45},{\\\\\\\"text\\\\\\\":\\\\\\\"    def __init__(self, rmin = [0, 0, 0, 0], rmax = [1, 1, 1, 1], N_0 = 1000, N_b = 1000, N_r = 3000, dimension = 1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":46},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.rmin = rmin\\\\\\\",\\\\\\\"lineNumber\\\\\\\":47},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.rmax = rmax\\\\\\\",\\\\\\\"lineNumber\\\\\\\":48},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.N_0 = N_0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":49},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.N_b = N_b\\\\\\\",\\\\\\\"lineNumber\\\\\\\":50},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.N_r = N_r\\\\\\\",\\\\\\\"lineNumber\\\\\\\":51},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.dimension = dimension\\\\\\\",\\\\\\\"lineNumber\\\\\\\":52},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":53},{\\\\\\\"text\\\\\\\":\\\\\\\"    def _generate_uniform_tensor(self, n_points, lower, upper, device = 'cuda', requires_grad = True):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":54},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":55},{\\\\\\\"text\\\\\\\":\\\\\\\"        Helper function to generate uniformly distributed tensor.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":56},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":57},{\\\\\\\"text\\\\\\\":\\\\\\\"        Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":58},{\\\\\\\"text\\\\\\\":\\\\\\\"            n_points: Number of points to generate\\\\\\\",\\\\\\\"lineNumber\\\\\\\":59},{\\\\\\\"text\\\\\\\":\\\\\\\"            lower: Lower bound\\\\\\\",\\\\\\\"lineNumber\\\\\\\":60},{\\\\\\\"text\\\\\\\":\\\\\\\"            upper: Upper bound\\\\\\\",\\\\\\\"lineNumber\\\\\\\":61},{\\\\\\\"text\\\\\\\":\\\\\\\"            device: PyTorch device\\\\\\\",\\\\\\\"lineNumber\\\\\\\":62},{\\\\\\\"text\\\\\\\":\\\\\\\"            requires_grad: Whether tensor requires gradients\\\\\\\",\\\\\\\"lineNumber\\\\\\\":63},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":64},{\\\\\\\"text\\\\\\\":\\\\\\\"        Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":65},{\\\\\\\"text\\\\\\\":\\\\\\\"            Tensor of shape [n_points, 1]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":66},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":67},{\\\\\\\"text\\\\\\\":\\\\\\\"        tensor = torch.empty(n_points, 1, device = device, dtype = torch.float32).uniform_(lower, upper)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":68},{\\\\\\\"text\\\\\\\":\\\\\\\"        if requires_grad:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":69},{\\\\\\\"text\\\\\\\":\\\\\\\"            tensor = tensor.requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":70},{\\\\\\\"text\\\\\\\":\\\\\\\"        return tensor\\\\\\\",\\\\\\\"lineNumber\\\\\\\":71},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":72},{\\\\\\\"text\\\\\\\":\\\\\\\"    def _generate_constant_tensor(self, n_points, value, device='cuda', requires_grad=True):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":73},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":74}]},\\\\\\\"score\\\\\\\":0.412757009267807},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\train.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":281,\\\\\\\"column\\\\\\\":58},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":338,\\\\\\\"column\\\\\\\":28}},\\\\\\\"contents\\\\\\\":\\\\\\\"net = PINN(n_harmonics=harmonics)\\\\\\\\nnet = net.to(device)\\\\\\\\nmse_cost_function = torch.nn.MSELoss()\\\\\\\\noptimizer = torch.optim.Adam(net.parameters(), lr=0.001)\\\\\\\\noptimizerL = torch.optim.LBFGS(net.parameters(), line_search_fn='strong_wolfe')\\\\\\\\n\\\\\\\\nif DIMENSION == 1:\\\\\\\\n    astpn_rmin = [xmin, tmin]\\\\\\\\n    astpn_rmax = [xmax, tmax]\\\\\\\\nelif DIMENSION == 2:\\\\\\\\n    astpn_rmin = [xmin, ymin, tmin]\\\\\\\\n    astpn_rmax = [xmax, ymax, tmax]\\\\\\\\nelif DIMENSION == 3:\\\\\\\\n    astpn_rmin = [xmin, ymin, zmin, tmin]\\\\\\\\n    astpn_rmax = [xmax, ymax, zmax, tmax]\\\\\\\\nelse:\\\\\\\\n    raise ValueError(f\\\\\\\\\\\\\\\"Unsupported DIMENSION={DIMENSION}\\\\\\\\\\\\\\\")\\\\\\\\ncollocation_model = ASTPN(rmin=astpn_rmin, rmax=astpn_rmax, N_0=N_0, N_b=0, N_r=N_r, dimension=DIMENSION)\\\\\\\\n\\\\\\\\n# Set domain on the network so periodic embeddings enforce hard BCs\\\\\\\\nspatial_rmin = [xmin]\\\\\\\\nspatial_rmax = [xmax]\\\\\\\\nif DIMENSION &gt;= 2:\\\\\\\\n    spatial_rmin.append(ymin)\\\\\\\\n    spatial_rmax.append(ymax)\\\\\\\\nif DIMENSION &gt;= 3:\\\\\\\\n    spatial_rmin.append(zmin)\\\\\\\\n    spatial_rmax.append(zmax)\\\\\\\\nnet.set_domain(rmin=spatial_rmin, rmax=spatial_rmax, dimension=DIMENSION)\\\\\\\\n\\\\\\\\n# IC collocation stays at t=0 throughout\\\\\\\\ncollocation_IC = collocation_model.geo_time_coord(option=\\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\n# Generate extra collocation points at t=0 for Poisson enforcement (Option 3)\\\\\\\\nfrom core.data_generator import generate_poisson_ic_points\\\\\\\\nfrom config import N_POISSON_IC\\\\\\\\ncollocation_poisson_ic = generate_poisson_ic_points(\\\\\\\\n    rmin=collocation_model.rmin,\\\\\\\\n    rmax=collocation_model.rmax,\\\\\\\\n    n_points=N_POISSON_IC,\\\\\\\\n    dimension=DIMENSION,\\\\\\\\n    device=device\\\\\\\\n)\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Generated {N_POISSON_IC} extra collocation points at t=0 for Poisson enforcement\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\nstart_time = time.time()\\\\\\\\n\\\\\\\\n# Standard training\\\\\\\\ncollocation_domain = collocation_model.geo_time_coord(option=\\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nprint(\\\\\\\\\\\\\\\"Using standard training...\\\\\\\\\\\\\\\")\\\\\\\\ntraining_diagnostics = train(\\\\\\\\n    net=net,\\\\\\\\n    model=collocation_model,\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"net = PINN(n_harmonics=harmonics)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":284},{\\\\\\\"text\\\\\\\":\\\\\\\"net = net.to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":285},{\\\\\\\"text\\\\\\\":\\\\\\\"mse_cost_function = torch.nn.MSELoss()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":286},{\\\\\\\"text\\\\\\\":\\\\\\\"optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":287},{\\\\\\\"text\\\\\\\":\\\\\\\"optimizerL = torch.optim.LBFGS(net.parameters(), line_search_fn='strong_wolfe')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":288},{\\\\\\\"lineNumber\\\\\\\":289},{\\\\\\\"text\\\\\\\":\\\\\\\"if DIMENSION == 1:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":290},{\\\\\\\"text\\\\\\\":\\\\\\\"    astpn_rmin = [xmin, tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":291},{\\\\\\\"text\\\\\\\":\\\\\\\"    astpn_rmax = [xmax, tmax]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":292},{\\\\\\\"text\\\\\\\":\\\\\\\"elif DIMENSION == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":293},{\\\\\\\"text\\\\\\\":\\\\\\\"    astpn_rmin = [xmin, ymin, tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":294},{\\\\\\\"text\\\\\\\":\\\\\\\"    astpn_rmax = [xmax, ymax, tmax]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":295},{\\\\\\\"text\\\\\\\":\\\\\\\"elif DIMENSION == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":296},{\\\\\\\"text\\\\\\\":\\\\\\\"    astpn_rmin = [xmin, ymin, zmin, tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":297},{\\\\\\\"text\\\\\\\":\\\\\\\"    astpn_rmax = [xmax, ymax, zmax, tmax]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":298},{\\\\\\\"text\\\\\\\":\\\\\\\"else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":299},{\\\\\\\"text\\\\\\\":\\\\\\\"    raise ValueError(f\\\\\\\\\\\\\\\"Unsupported DIMENSION={DIMENSION}\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":300},{\\\\\\\"text\\\\\\\":\\\\\\\"collocation_model = ASTPN(rmin=astpn_rmin, rmax=astpn_rmax, N_0=N_0, N_b=0, N_r=N_r, dimension=DIMENSION)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":301},{\\\\\\\"lineNumber\\\\\\\":302},{\\\\\\\"text\\\\\\\":\\\\\\\"# Set domain on the network so periodic embeddings enforce hard BCs\\\\\\\",\\\\\\\"lineNumber\\\\\\\":303},{\\\\\\\"text\\\\\\\":\\\\\\\"spatial_rmin = [xmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":304},{\\\\\\\"text\\\\\\\":\\\\\\\"spatial_rmax = [xmax]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":305},{\\\\\\\"text\\\\\\\":\\\\\\\"if DIMENSION &gt;= 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":306},{\\\\\\\"text\\\\\\\":\\\\\\\"    spatial_rmin.append(ymin)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":307},{\\\\\\\"text\\\\\\\":\\\\\\\"    spatial_rmax.append(ymax)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":308},{\\\\\\\"text\\\\\\\":\\\\\\\"if DIMENSION &gt;= 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":309},{\\\\\\\"text\\\\\\\":\\\\\\\"    spatial_rmin.append(zmin)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":310},{\\\\\\\"text\\\\\\\":\\\\\\\"    spatial_rmax.append(zmax)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":311},{\\\\\\\"text\\\\\\\":\\\\\\\"net.set_domain(rmin=spatial_rmin, rmax=spatial_rmax, dimension=DIMENSION)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":312},{\\\\\\\"lineNumber\\\\\\\":313},{\\\\\\\"text\\\\\\\":\\\\\\\"# IC collocation stays at t=0 throughout\\\\\\\",\\\\\\\"lineNumber\\\\\\\":314},{\\\\\\\"text\\\\\\\":\\\\\\\"collocation_IC = collocation_model.geo_time_coord(option=\\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":315},{\\\\\\\"lineNumber\\\\\\\":316},{\\\\\\\"lineNumber\\\\\\\":317},{\\\\\\\"text\\\\\\\":\\\\\\\"# Generate extra collocation points at t=0 for Poisson enforcement (Option 3)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":318},{\\\\\\\"text\\\\\\\":\\\\\\\"from core.data_generator import generate_poisson_ic_points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":319},{\\\\\\\"text\\\\\\\":\\\\\\\"from config import N_POISSON_IC\\\\\\\",\\\\\\\"lineNumber\\\\\\\":320},{\\\\\\\"text\\\\\\\":\\\\\\\"collocation_poisson_ic = generate_poisson_ic_points(\\\\\\\",\\\\\\\"lineNumber\\\\\\\":321},{\\\\\\\"text\\\\\\\":\\\\\\\"    rmin=collocation_model.rmin,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":322},{\\\\\\\"text\\\\\\\":\\\\\\\"    rmax=collocation_model.rmax,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":323},{\\\\\\\"text\\\\\\\":\\\\\\\"    n_points=N_POISSON_IC,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":324},{\\\\\\\"text\\\\\\\":\\\\\\\"    dimension=DIMENSION,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":325},{\\\\\\\"text\\\\\\\":\\\\\\\"    device=device\\\\\\\",\\\\\\\"lineNumber\\\\\\\":326},{\\\\\\\"text\\\\\\\":\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":327},{\\\\\\\"text\\\\\\\":\\\\\\\"print(f\\\\\\\\\\\\\\\"Generated {N_POISSON_IC} extra collocation points at t=0 for Poisson enforcement\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":328},{\\\\\\\"lineNumber\\\\\\\":329},{\\\\\\\"lineNumber\\\\\\\":330},{\\\\\\\"text\\\\\\\":\\\\\\\"start_time = time.time()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":331},{\\\\\\\"lineNumber\\\\\\\":332},{\\\\\\\"text\\\\\\\":\\\\\\\"# Standard training\\\\\\\",\\\\\\\"lineNumber\\\\\\\":333},{\\\\\\\"text\\\\\\\":\\\\\\\"collocation_domain = collocation_model.geo_time_coord(option=\\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":334},{\\\\\\\"lineNumber\\\\\\\":335},{\\\\\\\"text\\\\\\\":\\\\\\\"print(\\\\\\\\\\\\\\\"Using standard training...\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":336},{\\\\\\\"text\\\\\\\":\\\\\\\"training_diagnostics = train(\\\\\\\",\\\\\\\"lineNumber\\\\\\\":337},{\\\\\\\"text\\\\\\\":\\\\\\\"    net=net,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":338},{\\\\\\\"text\\\\\\\":\\\\\\\"    model=collocation_model,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":339}]},\\\\\\\"score\\\\\\\":0.3898839056491852},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\ndef geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\\n\\\\\\\\n            \\\\\\\\n            elif option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\\n                # Only generate BC if subdomain touches exterior boundary\\\\\\\\n                # This is handled by get_exterior_boundary_info\\\\\\\\n                if self.N_b == 0:\\\\\\\\n                    return [], []\\\\\\\\n                \\\\\\\\n                t_bc = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).uniform_(max(self.rmin[2], STARTUP_DT), self.rmax[2])\\\\\\\\n                t_bc.requires_grad_()\\\\\\\\n                \\\\\\\\n                if coordinate == 1:\\\\\\\\n                    x_bc_l = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(x_min).requires_grad_()\\\\\\\\n                    x_bc_r = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(x_max).requires_grad_()\\\\\\\\n                    y_bc = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).uniform_(y_min, y_max).requires_grad_()\\\\\\\\n                    \\\\\\\\n                    coor_l = [x_bc_l, y_bc, t_bc]\\\\\\\\n                    coor_r = [x_bc_r, y_bc, t_bc]\\\\\\\\n                    return coor_l, coor_r\\\\\\\\n                \\\\\\\\n                elif coordinate == 2:\\\\\\\\n                    y_bc_l = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(y_min).requires_grad_()\\\\\\\\n                    y_bc_r = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(y_max).requires_grad_()\\\\\\\\n                    x_bc = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).uniform_(x_min, x_max).requires_grad_()\\\\\\\\n                    \\\\\\\\n                    coor_l = [x_bc, y_bc_l, t_bc]\\\\\\\\n                    coor_r = [x_bc, y_bc_r, t_bc]\\\\\\\\n                    return coor_l, coor_r\\\\\\\\n        \\\\\\\\n        else:\\\\\\\\n            raise NotImplementedError(f\\\\\\\\\\\\\\\"Subdomain collocation not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\n        \\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":28,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":29,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":194,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":195,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":194},{\\\\\\\"lineNumber\\\\\\\":229},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":230},{\\\\\\\"text\\\\\\\":\\\\\\\"            elif option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":231},{\\\\\\\"text\\\\\\\":\\\\\\\"                # Only generate BC if subdomain touches exterior boundary\\\\\\\",\\\\\\\"lineNumber\\\\\\\":232},{\\\\\\\"text\\\\\\\":\\\\\\\"                # This is handled by get_exterior_boundary_info\\\\\\\",\\\\\\\"lineNumber\\\\\\\":233},{\\\\\\\"text\\\\\\\":\\\\\\\"                if self.N_b == 0:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":234},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return [], []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":235},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":236},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_bc = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).uniform_(max(self.rmin[2], STARTUP_DT), self.rmax[2])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":237},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_bc.requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":238},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":239},{\\\\\\\"text\\\\\\\":\\\\\\\"                if coordinate == 1:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":240},{\\\\\\\"text\\\\\\\":\\\\\\\"                    x_bc_l = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(x_min).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":241},{\\\\\\\"text\\\\\\\":\\\\\\\"                    x_bc_r = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(x_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":242},{\\\\\\\"text\\\\\\\":\\\\\\\"                    y_bc = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).uniform_(y_min, y_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":243},{\\\\\\\"text\\\\\\\":\\\\\\\"                    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":244},{\\\\\\\"text\\\\\\\":\\\\\\\"                    coor_l = [x_bc_l, y_bc, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":245},{\\\\\\\"text\\\\\\\":\\\\\\\"                    coor_r = [x_bc_r, y_bc, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":246},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return coor_l, coor_r\\\\\\\",\\\\\\\"lineNumber\\\\\\\":247},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":248},{\\\\\\\"text\\\\\\\":\\\\\\\"                elif coordinate == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":249},{\\\\\\\"text\\\\\\\":\\\\\\\"                    y_bc_l = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(y_min).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":250},{\\\\\\\"text\\\\\\\":\\\\\\\"                    y_bc_r = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).fill_(y_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":251},{\\\\\\\"text\\\\\\\":\\\\\\\"                    x_bc = torch.empty(self.N_b, 1, device=device, dtype=torch.float32).uniform_(x_min, x_max).requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":252},{\\\\\\\"text\\\\\\\":\\\\\\\"                    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":253},{\\\\\\\"text\\\\\\\":\\\\\\\"                    coor_l = [x_bc, y_bc_l, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":254},{\\\\\\\"text\\\\\\\":\\\\\\\"                    coor_r = [x_bc, y_bc_r, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":255},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return coor_l, coor_r\\\\\\\",\\\\\\\"lineNumber\\\\\\\":256},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":257},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":258},{\\\\\\\"text\\\\\\\":\\\\\\\"            raise NotImplementedError(f\\\\\\\\\\\\\\\"Subdomain collocation not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":259},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":260},{\\\\\\\"text\\\\\\\":\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":261},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":262}]},\\\\\\\"score\\\\\\\":0.37869250774383545},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\compare_models_with_fd.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":144}},\\\\\\\"contents\\\\\\\":\\\\\\\"import argparse\\\\\\\\nimport os\\\\\\\\nfrom typing import Dict, List, Sequence, Tuple\\\\\\\\n\\\\\\\\nimport matplotlib\\\\\\\\n\\\\\\\\nmatplotlib.use(\\\\\\\\\\\\\\\"Agg\\\\\\\\\\\\\\\")\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nimport numpy as np\\\\\\\\nimport torch\\\\\\\\nimport torch.nn as nn\\\\\\\\n\\\\\\\\nfrom config import (DIMENSION,FD_N_2D,FD_N_3D,PERTURBATION_TYPE,SLICE_Z,a,cs,harmonics,\\\\\\\\n    num_of_waves,tmax,tmin,wave,xmin,ymin,zmin,N_0,N_r,rho_o,)\\\\\\\\nfrom core.data_generator import input_taker, req_consts_calc\\\\\\\\nfrom core.initial_conditions import fun_rho_0,fun_vx_0,fun_vy_0,fun_vz_0,initialize_shared_velocity_fields\\\\\\\\nfrom core.losses import ASTPN, pde_residue\\\\\\\\nfrom core.model_architecture import PINN\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_warm_start_torch,lax_solution_torch,lax_solution_3d_sinusoidal_torch\\\\\\\\n\\\\\\\\n\\\\\\\\n# ========================= Collocation / PINN loss =========================\\\\\\\\n\\\\\\\\n\\\\\\\\ndef prepare_collocation_points(\\\\\\\\n    lam: float,\\\\\\\\n    num_waves: float,\\\\\\\\n    tmax_cfg: float,\\\\\\\\n    device: torch.device,\\\\\\\\n) -&gt; Tuple[ASTPN, List[torch.Tensor], List[torch.Tensor]]:\\\\\\\\n    xmax = xmin + lam * num_waves\\\\\\\\n    ymax = ymin + lam * num_waves if DIMENSION &gt;= 2 else ymin\\\\\\\\n\\\\\\\\n    # For 3D, ASTPN expects rmin/rmax including z; we just re-use zmin and zmax=zmin+lam*num_waves\\\\\\\\n    if DIMENSION == 3:\\\\\\\\n        zmax = zmin + lam * num_waves\\\\\\\\n        rmin = [xmin, ymin, zmin, tmin]\\\\\\\\n        rmax = [xmax, ymax, zmax, tmax_cfg]\\\\\\\\n    elif DIMENSION == 2:\\\\\\\\n        rmin = [xmin, ymin, tmin]\\\\\\\\n        rmax = [xmax, ymax, tmax_cfg]\\\\\\\\n    else:\\\\\\\\n        rmin = [xmin, tmin]\\\\\\\\n        rmax = [xmax, tmax_cfg]\\\\\\\\n\\\\\\\\n    model = ASTPN(\\\\\\\\n        rmin=rmin,\\\\\\\\n        rmax=rmax,\\\\\\\\n        N_0=N_0,\\\\\\\\n        N_b=0,\\\\\\\\n        N_r=N_r,\\\\\\\\n        dimension=DIMENSION,\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    collocation_domain = model.geo_time_coord(option=\\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\")\\\\\\\\n    collocation_ic = model.geo_time_coord(option=\\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    collocation_domain = [tensor.to(device) for tensor in collocation_domain]\\\\\\\\n    collocation_ic = [tensor.to(device) for tensor in collocation_ic]\\\\\\\\n    return model, collocation_domain, collocation_ic\\\\\\\\n\\\\\\\\n\\\\\\\\ndef compute_pinn_loss(\\\\\\\\n    model: ASTPN,\\\\\\\\n    net: PINN,\\\\\\\\n    collocation_domain: Sequence[torch.Tensor],\\\\\\\\n    collocation_ic: Sequence[torch.Tensor],\\\\\\\\n    lam: float,\\\\\\\\n    rho_1: float,\\\\\\\\n    jeans: float,\\\\\\\\n    v_1: float,\\\\\\\\n) -&gt; float:\\\\\\\\n    \\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"import argparse\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1},{\\\\\\\"text\\\\\\\":\\\\\\\"import os\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2},{\\\\\\\"text\\\\\\\":\\\\\\\"from typing import Dict, List, Sequence, Tuple\\\\\\\",\\\\\\\"lineNumber\\\\\\\":3},{\\\\\\\"lineNumber\\\\\\\":4},{\\\\\\\"text\\\\\\\":\\\\\\\"import matplotlib\\\\\\\",\\\\\\\"lineNumber\\\\\\\":5},{\\\\\\\"lineNumber\\\\\\\":6},{\\\\\\\"text\\\\\\\":\\\\\\\"matplotlib.use(\\\\\\\\\\\\\\\"Agg\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":7},{\\\\\\\"text\\\\\\\":\\\\\\\"import matplotlib.pyplot as plt\\\\\\\",\\\\\\\"lineNumber\\\\\\\":8},{\\\\\\\"text\\\\\\\":\\\\\\\"import numpy as np\\\\\\\",\\\\\\\"lineNumber\\\\\\\":9},{\\\\\\\"text\\\\\\\":\\\\\\\"import torch\\\\\\\",\\\\\\\"lineNumber\\\\\\\":10},{\\\\\\\"text\\\\\\\":\\\\\\\"import torch.nn as nn\\\\\\\",\\\\\\\"lineNumber\\\\\\\":11},{\\\\\\\"lineNumber\\\\\\\":12},{\\\\\\\"text\\\\\\\":\\\\\\\"from config import (DIMENSION,FD_N_2D,FD_N_3D,PERTURBATION_TYPE,SLICE_Z,a,cs,harmonics,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":13},{\\\\\\\"text\\\\\\\":\\\\\\\"    num_of_waves,tmax,tmin,wave,xmin,ymin,zmin,N_0,N_r,rho_o,)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":14},{\\\\\\\"text\\\\\\\":\\\\\\\"from core.data_generator import input_taker, req_consts_calc\\\\\\\",\\\\\\\"lineNumber\\\\\\\":15},{\\\\\\\"text\\\\\\\":\\\\\\\"from core.initial_conditions import fun_rho_0,fun_vx_0,fun_vy_0,fun_vz_0,initialize_shared_velocity_fields\\\\\\\",\\\\\\\"lineNumber\\\\\\\":16},{\\\\\\\"text\\\\\\\":\\\\\\\"from core.losses import ASTPN, pde_residue\\\\\\\",\\\\\\\"lineNumber\\\\\\\":17},{\\\\\\\"text\\\\\\\":\\\\\\\"from core.model_architecture import PINN\\\\\\\",\\\\\\\"lineNumber\\\\\\\":18},{\\\\\\\"text\\\\\\\":\\\\\\\"from numerical_solvers.LAX_torch import lax_solution_warm_start_torch,lax_solution_torch,lax_solution_3d_sinusoidal_torch\\\\\\\",\\\\\\\"lineNumber\\\\\\\":19},{\\\\\\\"lineNumber\\\\\\\":20},{\\\\\\\"lineNumber\\\\\\\":21},{\\\\\\\"text\\\\\\\":\\\\\\\"# ========================= Collocation / PINN loss =========================\\\\\\\",\\\\\\\"lineNumber\\\\\\\":22},{\\\\\\\"lineNumber\\\\\\\":23},{\\\\\\\"lineNumber\\\\\\\":24},{\\\\\\\"text\\\\\\\":\\\\\\\"def prepare_collocation_points(\\\\\\\",\\\\\\\"lineNumber\\\\\\\":25,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    lam: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":26,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    num_waves: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":27,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    tmax_cfg: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    device: torch.device,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":29,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\") -&gt; Tuple[ASTPN, List[torch.Tensor], List[torch.Tensor]]:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":30,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    xmax = xmin + lam * num_waves\\\\\\\",\\\\\\\"lineNumber\\\\\\\":31},{\\\\\\\"text\\\\\\\":\\\\\\\"    ymax = ymin + lam * num_waves if DIMENSION &gt;= 2 else ymin\\\\\\\",\\\\\\\"lineNumber\\\\\\\":32},{\\\\\\\"lineNumber\\\\\\\":33},{\\\\\\\"text\\\\\\\":\\\\\\\"    # For 3D, ASTPN expects rmin/rmax including z; we just re-use zmin and zmax=zmin+lam*num_waves\\\\\\\",\\\\\\\"lineNumber\\\\\\\":34},{\\\\\\\"text\\\\\\\":\\\\\\\"    if DIMENSION == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":35},{\\\\\\\"text\\\\\\\":\\\\\\\"        zmax = zmin + lam * num_waves\\\\\\\",\\\\\\\"lineNumber\\\\\\\":36},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmin = [xmin, ymin, zmin, tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":37},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmax = [xmax, ymax, zmax, tmax_cfg]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":38},{\\\\\\\"text\\\\\\\":\\\\\\\"    elif DIMENSION == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":39},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmin = [xmin, ymin, tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":40},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmax = [xmax, ymax, tmax_cfg]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":41},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":42},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmin = [xmin, tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":43},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmax = [xmax, tmax_cfg]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":44},{\\\\\\\"lineNumber\\\\\\\":45},{\\\\\\\"text\\\\\\\":\\\\\\\"    model = ASTPN(\\\\\\\",\\\\\\\"lineNumber\\\\\\\":46},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmin=rmin,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":47},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmax=rmax,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":48},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_0=N_0,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":49},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_b=0,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":50},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_r=N_r,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":51},{\\\\\\\"text\\\\\\\":\\\\\\\"        dimension=DIMENSION,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":52},{\\\\\\\"text\\\\\\\":\\\\\\\"    )\\\\\\\",\\\\\\\"lineNumber\\\\\\\":53},{\\\\\\\"lineNumber\\\\\\\":54},{\\\\\\\"text\\\\\\\":\\\\\\\"    collocation_domain = model.geo_time_coord(option=\\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":55},{\\\\\\\"text\\\\\\\":\\\\\\\"    collocation_ic = model.geo_time_coord(option=\\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":56},{\\\\\\\"lineNumber\\\\\\\":57},{\\\\\\\"text\\\\\\\":\\\\\\\"    collocation_domain = [tensor.to(device) for tensor in collocation_domain]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":58},{\\\\\\\"text\\\\\\\":\\\\\\\"    collocation_ic = [tensor.to(device) for tensor in collocation_ic]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":59},{\\\\\\\"text\\\\\\\":\\\\\\\"    return model, collocation_domain, collocation_ic\\\\\\\",\\\\\\\"lineNumber\\\\\\\":60,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":61},{\\\\\\\"lineNumber\\\\\\\":62},{\\\\\\\"text\\\\\\\":\\\\\\\"def compute_pinn_loss(\\\\\\\",\\\\\\\"lineNumber\\\\\\\":63,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    model: ASTPN,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":64,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    net: PINN,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":65,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    collocation_domain: Sequence[torch.Tensor],\\\\\\\",\\\\\\\"lineNumber\\\\\\\":66,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    collocation_ic: Sequence[torch.Tensor],\\\\\\\",\\\\\\\"lineNumber\\\\\\\":67,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    lam: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":68,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    rho_1: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":69,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    jeans: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":70,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    v_1: float,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":71,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\") -&gt; float:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":72,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":73}]},\\\\\\\"score\\\\\\\":0.3732231855392456},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":375,\\\\\\\"column\\\\\\\":17},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":421}},\\\\\\\"contents\\\\\\\":\\\\\\\"def generate_poisson_ic_points(rmin, rmax, n_points, dimension=2, device='cuda'):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Generate extra collocation points at t=0 specifically for enforcing Poisson equation.\\\\\\\\n    \\\\\\\\n    This implements Option 3: Pure ML approach to fix initial phi by sampling many\\\\\\\\n    spatial points at t=0 where Poisson equation âˆ‡Â²Ï† = const*(Ï-Ïâ‚€) must be satisfied.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        rmin: List of minimum values [xmin, ymin, (zmin), tmin]\\\\\\\\n        rmax: List of maximum values [xmax, ymax, (zmax), tmax]\\\\\\\\n        n_points: Number of spatial points to generate at t=0\\\\\\\\n        dimension: Spatial dimension (1, 2, or 3)\\\\\\\\n        device: PyTorch device ('cuda' or 'cpu')\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        List of tensors [x, y, (z), t] where t=0 everywhere, or None if n_points == 0\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    import torch\\\\\\\\n    \\\\\\\\n    # Return None if no points requested (avoids empty tensor issues)\\\\\\\\n    if n_points &lt;= 0:\\\\\\\\n        return None\\\\\\\\n    \\\\\\\\n    coor = []\\\\\\\\n    \\\\\\\\n    if dimension == 1:\\\\\\\\n        x_ic =\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def generate_poisson_ic_points(rmin, rmax, n_points, dimension=2, device='cuda'):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":379,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":380},{\\\\\\\"text\\\\\\\":\\\\\\\"    Generate extra collocation points at t=0 specifically for enforcing Poisson equation.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":381},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":382},{\\\\\\\"text\\\\\\\":\\\\\\\"    This implements Option 3: Pure ML approach to fix initial phi by sampling many\\\\\\\",\\\\\\\"lineNumber\\\\\\\":383},{\\\\\\\"text\\\\\\\":\\\\\\\"    spatial points at t=0 where Poisson equation âˆ‡Â²Ï† = const*(Ï-Ïâ‚€) must be satisfied.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":384},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":385},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":386},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmin: List of minimum values [xmin, ymin, (zmin), tmin]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":387},{\\\\\\\"text\\\\\\\":\\\\\\\"        rmax: List of maximum values [xmax, ymax, (zmax), tmax]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":388},{\\\\\\\"text\\\\\\\":\\\\\\\"        n_points: Number of spatial points to generate at t=0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":389},{\\\\\\\"text\\\\\\\":\\\\\\\"        dimension: Spatial dimension (1, 2, or 3)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":390},{\\\\\\\"text\\\\\\\":\\\\\\\"        device: PyTorch device ('cuda' or 'cpu')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":391},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":392},{\\\\\\\"text\\\\\\\":\\\\\\\"    Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":393},{\\\\\\\"text\\\\\\\":\\\\\\\"        List of tensors [x, y, (z), t] where t=0 everywhere, or None if n_points == 0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":394},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":395},{\\\\\\\"text\\\\\\\":\\\\\\\"    import torch\\\\\\\",\\\\\\\"lineNumber\\\\\\\":396},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":397},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Return None if no points requested (avoids empty tensor issues)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":398},{\\\\\\\"text\\\\\\\":\\\\\\\"    if n_points &lt;= 0:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":399},{\\\\\\\"text\\\\\\\":\\\\\\\"        return None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":400},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":401},{\\\\\\\"text\\\\\\\":\\\\\\\"    coor = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":402},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":403},{\\\\\\\"text\\\\\\\":\\\\\\\"    if dimension == 1:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":404},{\\\\\\\"text\\\\\\\":\\\\\\\"        x_ic =\\\\\\\",\\\\\\\"lineNumber\\\\\\\":405}]},\\\\\\\"score\\\\\\\":0.32721084356307983},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\config.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":72,\\\\\\\"column\\\\\\\":26}},\\\\\\\"contents\\\\\\\":\\\\\\\"import numpy as np\\\\\\\\n\\\\\\\\n# Random seed for reproducibility across all functions\\\\\\\\nRANDOM_SEED = 78\\\\\\\\n\\\\\\\\n# Perturbation selection: \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"sinusoidal\\\\\\\\\\\\\\\"\\\\\\\\nPERTURBATION_TYPE = \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nxmin = 0.0\\\\\\\\nymin = 0.0\\\\\\\\nzmin = 0.0\\\\\\\\ncs = 1.0\\\\\\\\nrho_o = 1.0\\\\\\\\nconst = 1.0\\\\\\\\nG = 1.0\\\\\\\\n\\\\\\\\n# Collocation point parameters\\\\\\\\nN_0 = 25000  # Number of initial condition points\\\\\\\\nN_r = 50000 # Number of residual/collocation points\\\\\\\\nDIMENSION = 2  # Spatial dimension\\\\\\\\n\\\\\\\\nBATCH_SIZE = 75000  # Max collocation points per mini-batch (controls peak GPU memory)\\\\\\\\nNUM_BATCHES = 1  # Mini-batches per optimizer step; gradients accumulate, memory stays constant\\\\\\\\n\\\\\\\\na = 0.1\\\\\\\\n\\\\\\\\ntmin = 0.\\\\\\\\ntmax = 3.0\\\\\\\\n\\\\\\\\nnum_neurons = 64\\\\\\\\nharmonics = 3\\\\\\\\nnum_layers = 5\\\\\\\\nDEFAULT_ACTIVATION = 'sin'  # Default activation function for PINN ('sin', 'tanh', 'relu', etc.)\\\\\\\\n\\\\\\\\nwave = 7.0\\\\\\\\nk = 2 * np.pi / wave\\\\\\\\nnum_of_waves = 2.0\\\\\\\\n\\\\\\\\niteration_adam_2D = 1001\\\\\\\\niteration_lbgfs_2D = 201\\\\\\\\n\\\\\\\\nIC_WEIGHT = 1.0\\\\\\\\n\\\\\\\\n# Extra collocation points at t=0 to strongly enforce Poisson equation\\\\\\\\nN_POISSON_IC = 0  # Number of extra spatial points at t=0 for Poisson\\\\\\\\nPOISSON_IC_WEIGHT = 0.0  # Weight for Poisson residual at t=0\\\\\\\\nPHI_MEAN_CONSTRAINT_WEIGHT = 0.0  # Weight for mean(Ï†)=0 constraint at t=0 (fixes gauge freedom)\\\\\\\\n\\\\\\\\n# Output/snapshot controls\\\\\\\\nSAVE_STATIC_SNAPSHOTS = False\\\\\\\\n\\\\\\\\n# Directory to save snapshots; default keeps Kaggle working dir\\\\\\\\nSNAPSHOT_DIR = \\\\\\\\\\\\\\\"/kaggle/working/\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Training diagnostics\\\\\\\\nENABLE_TRAINING_DIAGNOSTICS = True  # Enable automatic training diagnostics plots and logging\\\\\\\\n\\\\\\\\n# Density growth comparison plot controls\\\\\\\\nPLOT_DENSITY_GROWTH = False\\\\\\\\nGROWTH_PLOT_TMAX = 4.0\\\\\\\\nGROWTH_PLOT_DT = 0.1\\\\\\\\n\\\\\\\\nKX = k\\\\\\\\nKY = 0\\\\\\\\nKZ = 0\\\\\\\\nTIMES_1D = [2.5, 3.0, 3.5] # 1D cross-section times to plot (used for sinusoidal panel plots\\\\\\\\nFD_N_1D = 300  # Grid points for 1D LAX (when used)\\\\\\\\nFD_N_2D = 300  # Grid points per dimension for 2D LAX\\\\\\\\nFD_N_3D = 300  # Grid points per dimension for 3D LAX slices\\\\\\\\nFD_NU_SINUSOIDAL = 0.5  # Courant number for LAX solver\\\\\\\\nSLICE_Y = 0.6  # Default y slice for visualization/cross-sections\\\\\\\\nSLICE_Z = 0.6  # Default z slice for visualization/cross-sections\\\\\\\\nSHOW_LINEAR_THEORY = False\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"import numpy as np\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1},{\\\\\\\"lineNumber\\\\\\\":2},{\\\\\\\"text\\\\\\\":\\\\\\\"# Random seed for reproducibility across all functions\\\\\\\",\\\\\\\"lineNumber\\\\\\\":3},{\\\\\\\"text\\\\\\\":\\\\\\\"RANDOM_SEED = 78\\\\\\\",\\\\\\\"lineNumber\\\\\\\":4},{\\\\\\\"lineNumber\\\\\\\":5},{\\\\\\\"text\\\\\\\":\\\\\\\"# Perturbation selection: \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"sinusoidal\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":6},{\\\\\\\"text\\\\\\\":\\\\\\\"PERTURBATION_TYPE = \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":7},{\\\\\\\"lineNumber\\\\\\\":8},{\\\\\\\"text\\\\\\\":\\\\\\\"xmin = 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":9},{\\\\\\\"text\\\\\\\":\\\\\\\"ymin = 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":10},{\\\\\\\"text\\\\\\\":\\\\\\\"zmin = 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":11},{\\\\\\\"text\\\\\\\":\\\\\\\"cs = 1.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":12},{\\\\\\\"text\\\\\\\":\\\\\\\"rho_o = 1.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":13},{\\\\\\\"text\\\\\\\":\\\\\\\"const = 1.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":14},{\\\\\\\"text\\\\\\\":\\\\\\\"G = 1.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":15},{\\\\\\\"lineNumber\\\\\\\":16},{\\\\\\\"text\\\\\\\":\\\\\\\"# Collocation point parameters\\\\\\\",\\\\\\\"lineNumber\\\\\\\":17},{\\\\\\\"text\\\\\\\":\\\\\\\"N_0 = 25000  # Number of initial condition points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":18},{\\\\\\\"text\\\\\\\":\\\\\\\"N_r = 50000 # Number of residual/collocation points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":19},{\\\\\\\"text\\\\\\\":\\\\\\\"DIMENSION = 2  # Spatial dimension\\\\\\\",\\\\\\\"lineNumber\\\\\\\":20},{\\\\\\\"lineNumber\\\\\\\":21},{\\\\\\\"text\\\\\\\":\\\\\\\"BATCH_SIZE = 75000  # Max collocation points per mini-batch (controls peak GPU memory)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":22},{\\\\\\\"text\\\\\\\":\\\\\\\"NUM_BATCHES = 1  # Mini-batches per optimizer step; gradients accumulate, memory stays constant\\\\\\\",\\\\\\\"lineNumber\\\\\\\":23},{\\\\\\\"lineNumber\\\\\\\":24},{\\\\\\\"text\\\\\\\":\\\\\\\"a = 0.1\\\\\\\",\\\\\\\"lineNumber\\\\\\\":25},{\\\\\\\"lineNumber\\\\\\\":26},{\\\\\\\"text\\\\\\\":\\\\\\\"tmin = 0.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":27},{\\\\\\\"text\\\\\\\":\\\\\\\"tmax = 3.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28},{\\\\\\\"lineNumber\\\\\\\":29},{\\\\\\\"text\\\\\\\":\\\\\\\"num_neurons = 64\\\\\\\",\\\\\\\"lineNumber\\\\\\\":30},{\\\\\\\"text\\\\\\\":\\\\\\\"harmonics = 3\\\\\\\",\\\\\\\"lineNumber\\\\\\\":31},{\\\\\\\"text\\\\\\\":\\\\\\\"num_layers = 5\\\\\\\",\\\\\\\"lineNumber\\\\\\\":32},{\\\\\\\"text\\\\\\\":\\\\\\\"DEFAULT_ACTIVATION = 'sin'  # Default activation function for PINN ('sin', 'tanh', 'relu', etc.)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":33},{\\\\\\\"lineNumber\\\\\\\":34},{\\\\\\\"text\\\\\\\":\\\\\\\"wave = 7.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":35},{\\\\\\\"text\\\\\\\":\\\\\\\"k = 2 * np.pi / wave\\\\\\\",\\\\\\\"lineNumber\\\\\\\":36},{\\\\\\\"text\\\\\\\":\\\\\\\"num_of_waves = 2.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":37},{\\\\\\\"lineNumber\\\\\\\":38},{\\\\\\\"text\\\\\\\":\\\\\\\"iteration_adam_2D = 1001\\\\\\\",\\\\\\\"lineNumber\\\\\\\":39},{\\\\\\\"text\\\\\\\":\\\\\\\"iteration_lbgfs_2D = 201\\\\\\\",\\\\\\\"lineNumber\\\\\\\":40},{\\\\\\\"lineNumber\\\\\\\":41},{\\\\\\\"text\\\\\\\":\\\\\\\"IC_WEIGHT = 1.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":42},{\\\\\\\"lineNumber\\\\\\\":43},{\\\\\\\"text\\\\\\\":\\\\\\\"# Extra collocation points at t=0 to strongly enforce Poisson equation\\\\\\\",\\\\\\\"lineNumber\\\\\\\":44},{\\\\\\\"text\\\\\\\":\\\\\\\"N_POISSON_IC = 0  # Number of extra spatial points at t=0 for Poisson\\\\\\\",\\\\\\\"lineNumber\\\\\\\":45},{\\\\\\\"text\\\\\\\":\\\\\\\"POISSON_IC_WEIGHT = 0.0  # Weight for Poisson residual at t=0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":46},{\\\\\\\"text\\\\\\\":\\\\\\\"PHI_MEAN_CONSTRAINT_WEIGHT = 0.0  # Weight for mean(Ï†)=0 constraint at t=0 (fixes gauge freedom)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":47},{\\\\\\\"lineNumber\\\\\\\":48},{\\\\\\\"text\\\\\\\":\\\\\\\"# Output/snapshot controls\\\\\\\",\\\\\\\"lineNumber\\\\\\\":49},{\\\\\\\"text\\\\\\\":\\\\\\\"SAVE_STATIC_SNAPSHOTS = False\\\\\\\",\\\\\\\"lineNumber\\\\\\\":50},{\\\\\\\"lineNumber\\\\\\\":51},{\\\\\\\"text\\\\\\\":\\\\\\\"# Directory to save snapshots; default keeps Kaggle working dir\\\\\\\",\\\\\\\"lineNumber\\\\\\\":52},{\\\\\\\"text\\\\\\\":\\\\\\\"SNAPSHOT_DIR = \\\\\\\\\\\\\\\"/kaggle/working/\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":53},{\\\\\\\"lineNumber\\\\\\\":54},{\\\\\\\"text\\\\\\\":\\\\\\\"# Training diagnostics\\\\\\\",\\\\\\\"lineNumber\\\\\\\":55},{\\\\\\\"text\\\\\\\":\\\\\\\"ENABLE_TRAINING_DIAGNOSTICS = True  # Enable automatic training diagnostics plots and logging\\\\\\\",\\\\\\\"lineNumber\\\\\\\":56},{\\\\\\\"lineNumber\\\\\\\":57},{\\\\\\\"text\\\\\\\":\\\\\\\"# Density growth comparison plot controls\\\\\\\",\\\\\\\"lineNumber\\\\\\\":58},{\\\\\\\"text\\\\\\\":\\\\\\\"PLOT_DENSITY_GROWTH = False\\\\\\\",\\\\\\\"lineNumber\\\\\\\":59},{\\\\\\\"text\\\\\\\":\\\\\\\"GROWTH_PLOT_TMAX = 4.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":60},{\\\\\\\"text\\\\\\\":\\\\\\\"GROWTH_PLOT_DT = 0.1\\\\\\\",\\\\\\\"lineNumber\\\\\\\":61},{\\\\\\\"lineNumber\\\\\\\":62},{\\\\\\\"text\\\\\\\":\\\\\\\"KX = k\\\\\\\",\\\\\\\"lineNumber\\\\\\\":63},{\\\\\\\"text\\\\\\\":\\\\\\\"KY = 0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":64},{\\\\\\\"text\\\\\\\":\\\\\\\"KZ = 0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":65},{\\\\\\\"text\\\\\\\":\\\\\\\"TIMES_1D = [2.5, 3.0, 3.5] # 1D cross-section times to plot (used for sinusoidal panel plots\\\\\\\",\\\\\\\"lineNumber\\\\\\\":66},{\\\\\\\"text\\\\\\\":\\\\\\\"FD_N_1D = 300  # Grid points for 1D LAX (when used)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":67},{\\\\\\\"text\\\\\\\":\\\\\\\"FD_N_2D = 300  # Grid points per dimension for 2D LAX\\\\\\\",\\\\\\\"lineNumber\\\\\\\":68},{\\\\\\\"text\\\\\\\":\\\\\\\"FD_N_3D = 300  # Grid points per dimension for 3D LAX slices\\\\\\\",\\\\\\\"lineNumber\\\\\\\":69},{\\\\\\\"text\\\\\\\":\\\\\\\"FD_NU_SINUSOIDAL = 0.5  # Courant number for LAX solver\\\\\\\",\\\\\\\"lineNumber\\\\\\\":70},{\\\\\\\"text\\\\\\\":\\\\\\\"SLICE_Y = 0.6  # Default y slice for visualization/cross-sections\\\\\\\",\\\\\\\"lineNumber\\\\\\\":71},{\\\\\\\"text\\\\\\\":\\\\\\\"SLICE_Z = 0.6  # Default z slice for visualization/cross-sections\\\\\\\",\\\\\\\"lineNumber\\\\\\\":72},{\\\\\\\"text\\\\\\\":\\\\\\\"SHOW_LINEAR_THEORY = False\\\\\\\",\\\\\\\"lineNumber\\\\\\\":73}]},\\\\\\\"score\\\\\\\":0.3216795027256012},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":310}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\ndef geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\\n{self.dimension}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\n        Uses xpinn_decomposition utilities.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            subdomain_idx: Linear subdomain index\\\\\\\\n            nx_sub: Number of subdomain splits in x-direction\\\\\\\\n            ny_sub: Number of subdomain splits in y-direction\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Dict with keys 'left', 'right', 'bottom', 'top' indicating if boundary is exterior\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\n        \\\\\\\\n        # Extract global domain bounds from self.rmin, self.rmax\\\\\\\\n        if self.dimension == 2:\\\\\\\\n            xmin, ymin = self.rmin[0], self.rmin[1]\\\\\\\\n            xmax, ymax = self.rmax[0], self.rmax[1]\\\\\\\\n        else:\\\\\\\\n            raise NotImplementedError(f\\\\\\\\\\\\\\\"Exterior boundary info not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\n\\\\\\\\n\\\\\\\\n# ==================== Utility Functions ====================\\\\\\\\n\\\\\\\\ndef input_taker(lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":28,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":29,\\\\\\\"column\\\\\\\":5}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def geo_time_coord_subdomain(self, option, subdomain_bounds, device='cuda', coordinate=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":194},{\\\\\\\"text\\\\\\\":\\\\\\\"{self.dimension}\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":259},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":260},{\\\\\\\"text\\\\\\\":\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":261},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":262},{\\\\\\\"text\\\\\\\":\\\\\\\"        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":263},{\\\\\\\"text\\\\\\\":\\\\\\\"        Uses xpinn_decomposition utilities.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":264},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":265},{\\\\\\\"text\\\\\\\":\\\\\\\"        Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":266},{\\\\\\\"text\\\\\\\":\\\\\\\"            subdomain_idx: Linear subdomain index\\\\\\\",\\\\\\\"lineNumber\\\\\\\":267},{\\\\\\\"text\\\\\\\":\\\\\\\"            nx_sub: Number of subdomain splits in x-direction\\\\\\\",\\\\\\\"lineNumber\\\\\\\":268},{\\\\\\\"text\\\\\\\":\\\\\\\"            ny_sub: Number of subdomain splits in y-direction\\\\\\\",\\\\\\\"lineNumber\\\\\\\":269},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":270},{\\\\\\\"text\\\\\\\":\\\\\\\"        Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":271},{\\\\\\\"text\\\\\\\":\\\\\\\"            Dict with keys 'left', 'right', 'bottom', 'top' indicating if boundary is exterior\\\\\\\",\\\\\\\"lineNumber\\\\\\\":272},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":273},{\\\\\\\"text\\\\\\\":\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\",\\\\\\\"lineNumber\\\\\\\":274},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":275},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Extract global domain bounds from self.rmin, self.rmax\\\\\\\",\\\\\\\"lineNumber\\\\\\\":276},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":277},{\\\\\\\"text\\\\\\\":\\\\\\\"            xmin, ymin = self.rmin[0], self.rmin[1]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":278},{\\\\\\\"text\\\\\\\":\\\\\\\"            xmax, ymax = self.rmax[0], self.rmax[1]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":279},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":280},{\\\\\\\"text\\\\\\\":\\\\\\\"            raise NotImplementedError(f\\\\\\\\\\\\\\\"Exterior boundary info not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":281},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":282},{\\\\\\\"text\\\\\\\":\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":283,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":284},{\\\\\\\"lineNumber\\\\\\\":285},{\\\\\\\"text\\\\\\\":\\\\\\\"# ==================== Utility Functions ====================\\\\\\\",\\\\\\\"lineNumber\\\\\\\":286},{\\\\\\\"lineNumber\\\\\\\":287},{\\\\\\\"text\\\\\\\":\\\\\\\"def input_taker(lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":288,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":289}]},\\\\\\\"score\\\\\\\":0.31199389696121216},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\ndef geo_time_coord(self,option,coordinate=1):\\\\\\\\n\\\\\\\\n            \\\\\\\\n        if self.dimension == 2:\\\\\\\\n            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\\n                x_dom = self._generate_uniform_tensor(self.N_r, self.rmin[0], self.rmax[0])\\\\\\\\n                y_dom = self._generate_uniform_tensor(self.N_r, self.rmin[1], self.rmax[1])\\\\\\\\n                t_dom = self._generate_uniform_tensor(self.N_r, max(self.rmin[2], STARTUP_DT), self.rmax[2])\\\\\\\\n                return [x_dom, y_dom, t_dom]\\\\\\\\n            \\\\\\\\n            if option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\\n                x_0 = self._generate_uniform_tensor(self.N_0, self.rmin[0], self.rmax[0])\\\\\\\\n                y_0 = self._generate_uniform_tensor(self.N_0, self.rmin[1], self.rmax[1])\\\\\\\\n                t_0 = self._generate_constant_tensor(self.N_0, 0.0)\\\\\\\\n                return [x_0, y_0, t_0]\\\\\\\\n            \\\\\\\\n            if option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\\n                if self.N_b == 0:\\\\\\\\n                    return [], []\\\\\\\\n                \\\\\\\\n                t_bc = self._generate_uniform_tensor(self.N_b, max(self.rmin[self.dimension], STARTUP_DT), self.rmax[self.dimension])\\\\\\\\n                \\\\\\\\n                if coordinate == 1:\\\\\\\\n                    x_bc_l = self._generate_constant_tensor(self.N_b, self.rmin[0])\\\\\\\\n                    x_bc_r = self._generate_constant_tensor(self.N_b, self.rmax[0])\\\\\\\\n                    y_bc = self._generate_uniform_tensor(self.N_b, self.rmin[1], self.rmax[1])\\\\\\\\n                    return [x_bc_l, y_bc, t_bc], [x_bc_r, y_bc, t_bc]\\\\\\\\n                \\\\\\\\n                if coordinate == 2:\\\\\\\\n                    y_bc_l = self._generate_constant_tensor(self.N_b, self.rmin[1])\\\\\\\\n                    y_bc_r = self._generate_constant_tensor(self.N_b, self.rmax[1])\\\\\\\\n                    x_bc = self._generate_uniform_tensor(self.N_b, self.rmin[0], self.rmax[0])\\\\\\\\n                    return [x_bc, y_bc_l, t_bc], [x_bc, y_bc_r, t_bc]\\\\\\\\n    \\\\\\\\n            \\\\\\\\n        if self.dimension == 3:\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":28,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":29,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":92,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":93,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def geo_time_coord(self,option,coordinate=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":92},{\\\\\\\"lineNumber\\\\\\\":117},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":118},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":119},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":120},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_dom = self._generate_uniform_tensor(self.N_r, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":121},{\\\\\\\"text\\\\\\\":\\\\\\\"                y_dom = self._generate_uniform_tensor(self.N_r, self.rmin[1], self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":122},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_dom = self._generate_uniform_tensor(self.N_r, max(self.rmin[2], STARTUP_DT), self.rmax[2])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":123},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_dom, y_dom, t_dom]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":124},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":125},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":126},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_0 = self._generate_uniform_tensor(self.N_0, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":127},{\\\\\\\"text\\\\\\\":\\\\\\\"                y_0 = self._generate_uniform_tensor(self.N_0, self.rmin[1], self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":128},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_0 = self._generate_constant_tensor(self.N_0, 0.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":129},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_0, y_0, t_0]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":130},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":131},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":132},{\\\\\\\"text\\\\\\\":\\\\\\\"                if self.N_b == 0:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":133},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return [], []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":134},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":135},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_bc = self._generate_uniform_tensor(self.N_b, max(self.rmin[self.dimension], STARTUP_DT), self.rmax[self.dimension])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":136},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":137},{\\\\\\\"text\\\\\\\":\\\\\\\"                if coordinate == 1:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":138},{\\\\\\\"text\\\\\\\":\\\\\\\"                    x_bc_l = self._generate_constant_tensor(self.N_b, self.rmin[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":139},{\\\\\\\"text\\\\\\\":\\\\\\\"                    x_bc_r = self._generate_constant_tensor(self.N_b, self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":140},{\\\\\\\"text\\\\\\\":\\\\\\\"                    y_bc = self._generate_uniform_tensor(self.N_b, self.rmin[1], self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":141},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return [x_bc_l, y_bc, t_bc], [x_bc_r, y_bc, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":142},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":143},{\\\\\\\"text\\\\\\\":\\\\\\\"                if coordinate == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":144},{\\\\\\\"text\\\\\\\":\\\\\\\"                    y_bc_l = self._generate_constant_tensor(self.N_b, self.rmin[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":145},{\\\\\\\"text\\\\\\\":\\\\\\\"                    y_bc_r = self._generate_constant_tensor(self.N_b, self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":146},{\\\\\\\"text\\\\\\\":\\\\\\\"                    x_bc = self._generate_uniform_tensor(self.N_b, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":147},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return [x_bc, y_bc_l, t_bc], [x_bc, y_bc_r, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":148},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":149},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":150},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":151}]},\\\\\\\"score\\\\\\\":0.29904550313949585},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\utilities\\\\\\\\\\\\\\\\compare_model.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":324},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":606}},\\\\\\\"contents\\\\\\\":\\\\\\\"def create_comparison_plots(net, initial_params, time_points, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", N=None, nu=0.5,\\\\\\\\n                            save_plots=True, fd_backend=\\\\\\\\\\\\\\\"cpu\\\\\\\\\\\\\\\", show_plot=True, fd_cache=None):\\\\\\\\n\\\\\\\\n    \\\\\\\\n    num_times = len(time_points)\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Creating {num_times}x3 comparison table for {which}...\\\\\\\\\\\\\\\")\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Time points: {time_points}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Create subplot grid\\\\\\\\n    fig, axes = plt.subplots(num_times, 3, figsize=(15, 4*num_times), constrained_layout=True)\\\\\\\\n    if num_times == 1:\\\\\\\\n        axes = axes.reshape(1, -1)\\\\\\\\n    \\\\\\\\n    # Store data\\\\\\\\n    pinn_data = []\\\\\\\\n    fd_data = []\\\\\\\\n    pinn_velocity_data = []\\\\\\\\n    fd_velocity_data = []\\\\\\\\n    \\\\\\\\n    # First pass: collect data\\\\\\\\n    for i, t in enumerate(time_points):\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Collecting data for t = {t:.4f}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Get PINN data - use N_GRID for consistency with FD solver\\\\\\\\n        Q = N_GRID\\\\\\\\n        xs = np.linspace(xmin, xmax, Q, endpoint=False)\\\\\\\\n        ys = np.linspace(ymin, ymax, Q, endpoint=False)\\\\\\\\n        tau, phi = np.meshgrid(xs, ys)\\\\\\\\n        Xgrid = np.vstack([tau.flatten(), phi.flatten()]).T\\\\\\\\n        t_00 = t * np.ones(Q**2).reshape(Q**2, 1)\\\\\\\\n        \\\\\\\\n        pt_x_collocation = Variable(torch.from_numpy(Xgrid[:, 0:1]).float(), requires_grad=True).to(device)\\\\\\\\n        pt_y_collocation = Variable(torch.from_numpy(Xgrid[:, 1:2]).float(), requires_grad=True).to(device)\\\\\\\\n        pt_t_collocation = Variable(torch.from_numpy(t_00).float(), requires_grad=True).to(device)\\\\\\\\n        if DIMENSION &gt;= 3:\\\\\\\\n            z_values = np.full((Q**2, 1), z_slice, dtype=np.float32)\\\\\\\\n            pt_z_collocation = Variable(torch.from_numpy(z_values).float(), requires_grad=True).to(device)\\\\\\\\n        else:\\\\\\\\n            pt_z_collocation = None\\\\\\\\n        \\\\\\\\n        net_inputs = [pt_x_collocation]\\\\\\\\n        if DIMENSION &gt;= 2:\\\\\\\\n            net_inputs.append(pt_y_collocation)\\\\\\\\n        if DIMENSION &gt;= 3 and pt_z_collocation is not None:\\\\\\\\n            net_inputs.append(pt_z_collocation)\\\\\\\\n        net_inputs.append(pt_t_collocation)\\\\\\\\n        \\\\\\\\n        output_00 = net(net_inputs)\\\\\\\\n        \\\\\\\\n        # Extract components\\\\\\\\n        rho_pinn = output_00[:, 0].data.cpu().numpy().reshape(Q, Q)\\\\\\\\n        pinn_vx = output_00[:, 1].data.cpu().numpy().reshape(Q, Q)\\\\\\\\n        pinn_vy = output_00[:, 2].data.cpu().numpy().reshape(Q, Q) if DIMENSION &gt;= 2 else None\\\\\\\\n        pinn_vz =\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":325,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":327,\\\\\\\"column\\\\\\\":5}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def create_comparison_plots(net, initial_params, time_points, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", N=None, nu=0.5,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":325,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"                            save_plots=True, fd_backend=\\\\\\\\\\\\\\\"cpu\\\\\\\\\\\\\\\", show_plot=True, fd_cache=None):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":326,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":360},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":361},{\\\\\\\"text\\\\\\\":\\\\\\\"    num_times = len(time_points)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":362},{\\\\\\\"text\\\\\\\":\\\\\\\"    print(f\\\\\\\\\\\\\\\"Creating {num_times}x3 comparison table for {which}...\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":363},{\\\\\\\"text\\\\\\\":\\\\\\\"    print(f\\\\\\\\\\\\\\\"Time points: {time_points}\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":364},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":365},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Create subplot grid\\\\\\\",\\\\\\\"lineNumber\\\\\\\":366},{\\\\\\\"text\\\\\\\":\\\\\\\"    fig, axes = plt.subplots(num_times, 3, figsize=(15, 4*num_times), constrained_layout=True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":367},{\\\\\\\"text\\\\\\\":\\\\\\\"    if num_times == 1:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":368},{\\\\\\\"text\\\\\\\":\\\\\\\"        axes = axes.reshape(1, -1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":369},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":370},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Store data\\\\\\\",\\\\\\\"lineNumber\\\\\\\":371},{\\\\\\\"text\\\\\\\":\\\\\\\"    pinn_data = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":372},{\\\\\\\"text\\\\\\\":\\\\\\\"    fd_data = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":373},{\\\\\\\"text\\\\\\\":\\\\\\\"    pinn_velocity_data = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":374},{\\\\\\\"text\\\\\\\":\\\\\\\"    fd_velocity_data = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":375},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":376},{\\\\\\\"text\\\\\\\":\\\\\\\"    # First pass: collect data\\\\\\\",\\\\\\\"lineNumber\\\\\\\":377},{\\\\\\\"text\\\\\\\":\\\\\\\"    for i, t in enumerate(time_points):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":378},{\\\\\\\"text\\\\\\\":\\\\\\\"        print(f\\\\\\\\\\\\\\\"Collecting data for t = {t:.4f}\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":379},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":380},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Get PINN data - use N_GRID for consistency with FD solver\\\\\\\",\\\\\\\"lineNumber\\\\\\\":381},{\\\\\\\"text\\\\\\\":\\\\\\\"        Q = N_GRID\\\\\\\",\\\\\\\"lineNumber\\\\\\\":382},{\\\\\\\"text\\\\\\\":\\\\\\\"        xs = np.linspace(xmin, xmax, Q, endpoint=False)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":383},{\\\\\\\"text\\\\\\\":\\\\\\\"        ys = np.linspace(ymin, ymax, Q, endpoint=False)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":384},{\\\\\\\"text\\\\\\\":\\\\\\\"        tau, phi = np.meshgrid(xs, ys)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":385},{\\\\\\\"text\\\\\\\":\\\\\\\"        Xgrid = np.vstack([tau.flatten(), phi.flatten()]).T\\\\\\\",\\\\\\\"lineNumber\\\\\\\":386},{\\\\\\\"text\\\\\\\":\\\\\\\"        t_00 = t * np.ones(Q**2).reshape(Q**2, 1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":387},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":388},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_x_collocation = Variable(torch.from_numpy(Xgrid[:, 0:1]).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":389},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_y_collocation = Variable(torch.from_numpy(Xgrid[:, 1:2]).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":390},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_t_collocation = Variable(torch.from_numpy(t_00).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":391},{\\\\\\\"text\\\\\\\":\\\\\\\"        if DIMENSION &gt;= 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":392},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_values = np.full((Q**2, 1), z_slice, dtype=np.float32)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":393},{\\\\\\\"text\\\\\\\":\\\\\\\"            pt_z_collocation = Variable(torch.from_numpy(z_values).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":394},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":395},{\\\\\\\"text\\\\\\\":\\\\\\\"            pt_z_collocation = None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":396},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":397},{\\\\\\\"text\\\\\\\":\\\\\\\"        net_inputs = [pt_x_collocation]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":398},{\\\\\\\"text\\\\\\\":\\\\\\\"        if DIMENSION &gt;= 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":399},{\\\\\\\"text\\\\\\\":\\\\\\\"            net_inputs.append(pt_y_collocation)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":400},{\\\\\\\"text\\\\\\\":\\\\\\\"        if DIMENSION &gt;= 3 and pt_z_collocation is not None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":401},{\\\\\\\"text\\\\\\\":\\\\\\\"            net_inputs.append(pt_z_collocation)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":402},{\\\\\\\"text\\\\\\\":\\\\\\\"        net_inputs.append(pt_t_collocation)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":403},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":404},{\\\\\\\"text\\\\\\\":\\\\\\\"        output_00 = net(net_inputs)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":405},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":406},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Extract components\\\\\\\",\\\\\\\"lineNumber\\\\\\\":407},{\\\\\\\"text\\\\\\\":\\\\\\\"        rho_pinn = output_00[:, 0].data.cpu().numpy().reshape(Q, Q)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":408},{\\\\\\\"text\\\\\\\":\\\\\\\"        pinn_vx = output_00[:, 1].data.cpu().numpy().reshape(Q, Q)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":409},{\\\\\\\"text\\\\\\\":\\\\\\\"        pinn_vy = output_00[:, 2].data.cpu().numpy().reshape(Q, Q) if DIMENSION &gt;= 2 else None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":410},{\\\\\\\"text\\\\\\\":\\\\\\\"        pinn_vz =\\\\\\\",\\\\\\\"lineNumber\\\\\\\":411}]},\\\\\\\"score\\\\\\\":0.297723650932312},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\ndef _generate_uniform_tensor(self, n_points, lower, upper, device = 'cuda', requires_grad = True):\\\\\\\\n\\\\\\\\n        return tensor\\\\\\\\n    \\\\\\\\n    def _generate_constant_tensor(self, n_points, value, device='cuda', requires_grad=True):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Helper function to generate constant-valued tensor.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            n_points: Number of points\\\\\\\\n            value: Constant value\\\\\\\\n            device: PyTorch device\\\\\\\\n            requires_grad: Whether tensor requires gradients\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Tensor of shape [n_points, 1]\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        tensor = torch.empty(n_points, 1, device=device, dtype=torch.float32).fill_(value)\\\\\\\\n        if requires_grad:\\\\\\\\n            tensor = tensor.requires_grad_()\\\\\\\\n        return tensor\\\\\\\\n        \\\\\\\\n        \\\\\\\\n    def geo_time_coord(self,option,coordinate=1):\\\\\\\\n        '''\\\\\\\\n        option: Takes arguments: \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\" for Boundary conditions, \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\" for initial conditions:\\\\\\\\n        \\\\\\\\n        '''\\\\\\\\n        \\\\\\\\n        if self.dimension == 1: \\\\\\\\n            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\\n                x_coor = self._generate_uniform_tensor(self.N_r, self.rmin[0], self.rmax[0])\\\\\\\\n                t_coor = self._generate_uniform_tensor(self.N_r, max(self.rmin[1], STARTUP_DT), self.rmax[1])\\\\\\\\n                return [x_coor, t_coor]\\\\\\\\n\\\\\\\\n            if option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\\n                x_0 = self._generate_uniform_tensor(self.N_0, self.rmin[0], self.rmax[0])\\\\\\\\n                t_0 = self._generate_constant_tensor(self.N_0, 0.0)\\\\\\\\n                return [x_0, t_0]\\\\\\\\n\\\\\\\\n            if option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\\n                if self.N_b == 0:\\\\\\\\n                    return [], []\\\\\\\\n                \\\\\\\\n                x_bc_l = self._generate_constant_tensor(self.N_b, self.rmin[coordinate-1])\\\\\\\\n                x_bc_r = self._generate_constant_tensor(self.N_b, self.rmax[coordinate-1])\\\\\\\\n                t_bc = self._generate_uniform_tensor(self.N_b, self.rmin[self.dimension], self.rmax[self.dimension])\\\\\\\\n                \\\\\\\\n                return [x_bc_l, t_bc], [x_bc_r, t_bc]\\\\\\\\n            \\\\\\\\n        if self.dimension == 2:\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":28,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":29,\\\\\\\"column\\\\\\\":5}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def _generate_uniform_tensor(self, n_points, lower, upper, device = 'cuda', requires_grad = True):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":54},{\\\\\\\"lineNumber\\\\\\\":70},{\\\\\\\"text\\\\\\\":\\\\\\\"        return tensor\\\\\\\",\\\\\\\"lineNumber\\\\\\\":71},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":72},{\\\\\\\"text\\\\\\\":\\\\\\\"    def _generate_constant_tensor(self, n_points, value, device='cuda', requires_grad=True):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":73},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":74},{\\\\\\\"text\\\\\\\":\\\\\\\"        Helper function to generate constant-valued tensor.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":75},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":76},{\\\\\\\"text\\\\\\\":\\\\\\\"        Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":77},{\\\\\\\"text\\\\\\\":\\\\\\\"            n_points: Number of points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":78},{\\\\\\\"text\\\\\\\":\\\\\\\"            value: Constant value\\\\\\\",\\\\\\\"lineNumber\\\\\\\":79},{\\\\\\\"text\\\\\\\":\\\\\\\"            device: PyTorch device\\\\\\\",\\\\\\\"lineNumber\\\\\\\":80},{\\\\\\\"text\\\\\\\":\\\\\\\"            requires_grad: Whether tensor requires gradients\\\\\\\",\\\\\\\"lineNumber\\\\\\\":81},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":82},{\\\\\\\"text\\\\\\\":\\\\\\\"        Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":83},{\\\\\\\"text\\\\\\\":\\\\\\\"            Tensor of shape [n_points, 1]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":84},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":85},{\\\\\\\"text\\\\\\\":\\\\\\\"        tensor = torch.empty(n_points, 1, device=device, dtype=torch.float32).fill_(value)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":86},{\\\\\\\"text\\\\\\\":\\\\\\\"        if requires_grad:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":87},{\\\\\\\"text\\\\\\\":\\\\\\\"            tensor = tensor.requires_grad_()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":88},{\\\\\\\"text\\\\\\\":\\\\\\\"        return tensor\\\\\\\",\\\\\\\"lineNumber\\\\\\\":89},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":90},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":91},{\\\\\\\"text\\\\\\\":\\\\\\\"    def geo_time_coord(self,option,coordinate=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":92},{\\\\\\\"text\\\\\\\":\\\\\\\"        '''\\\\\\\",\\\\\\\"lineNumber\\\\\\\":93},{\\\\\\\"text\\\\\\\":\\\\\\\"        option: Takes arguments: \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\" for Boundary conditions, \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\" for initial conditions:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":94},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":95},{\\\\\\\"text\\\\\\\":\\\\\\\"        '''\\\\\\\",\\\\\\\"lineNumber\\\\\\\":96},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":97},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 1: \\\\\\\",\\\\\\\"lineNumber\\\\\\\":98},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":99},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_coor = self._generate_uniform_tensor(self.N_r, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":100},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_coor = self._generate_uniform_tensor(self.N_r, max(self.rmin[1], STARTUP_DT), self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":101},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_coor, t_coor]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":102},{\\\\\\\"lineNumber\\\\\\\":103},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":104},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_0 = self._generate_uniform_tensor(self.N_0, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":105},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_0 = self._generate_constant_tensor(self.N_0, 0.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":106},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_0, t_0]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":107},{\\\\\\\"lineNumber\\\\\\\":108},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":109},{\\\\\\\"text\\\\\\\":\\\\\\\"                if self.N_b == 0:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":110},{\\\\\\\"text\\\\\\\":\\\\\\\"                    return [], []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":111},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":112},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_bc_l = self._generate_constant_tensor(self.N_b, self.rmin[coordinate-1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":113},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_bc_r = self._generate_constant_tensor(self.N_b, self.rmax[coordinate-1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":114},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_bc = self._generate_uniform_tensor(self.N_b, self.rmin[self.dimension], self.rmax[self.dimension])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":115},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":116},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_bc_l, t_bc], [x_bc_r, t_bc]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":117},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":118},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":119}]},\\\\\\\"score\\\\\\\":0.294616162776947},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\initial_conditions.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":180,\\\\\\\"column\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":340}},\\\\\\\"contents\\\\\\\":\\\\\\\"def _generate_power_spectrum_fallback(lam, v_1, x, seed=None):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Fallback power spectrum generation when shared fields are not available.\\\\\\\\n    Supports both 2D and 3D FFT.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        lam: Wavelength (unused for domain sizing in fallback)\\\\\\\\n        v_1: Velocity amplitude\\\\\\\\n        x: Collocation coordinates [x, y, ...] for 2D or [x, y, z, ...] for 3D\\\\\\\\n        seed: Random seed\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        Generated power spectrum field\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if seed is None:\\\\\\\\n        seed = RANDOM_SEED\\\\\\\\n    \\\\\\\\n    # Detect dimension from coordinates\\\\\\\\n    dim = _detect_dimension(x)\\\\\\\\n    \\\\\\\\n    # Infer domain extents directly from the collocation coordinates to support arbitrary num_of_waves\\\\\\\\n    # Use conservative defaults if tensors are degenerate (e.g., single point during a unit test)\\\\\\\\n    x_coords = x[0].detach()\\\\\\\\n    y_coords = x[1].detach() if len(x) &gt; 1 else x[0].detach()\\\\\\\\n    z_coords = x[2].detach() if len(x) &gt; 2 and dim == 3 else None\\\\\\\\n\\\\\\\\n    xmin_val = torch.min(x_coords).item() if x_coords.numel() &gt; 0 else 0.0\\\\\\\\n    xmax_val = torch.max(x_coords).item() if x_coords.numel() &gt; 0 else float(lam * 2.0)\\\\\\\\n    ymin_val = torch.min(y_coords).item() if y_coords.numel() &gt; 0 else 0.0\\\\\\\\n    ymax_val = torch.max(y_coords).item() if y_coords.numel() &gt; 0 else float(lam * 2.0)\\\\\\\\n    \\\\\\\\n    if dim == 3 and z_coords is not None:\\\\\\\\n        zmin_val = torch.min(z_coords).item() if z_coords.numel() &gt; 0 else 0.0\\\\\\\\n        zmax_val = torch.max(z_coords).item() if z_coords.numel() &gt; 0 else float(lam * 2.0)\\\\\\\\n    else:\\\\\\\\n        zmin_val = 0.0\\\\\\\\n        zmax_val = float(lam * 2.0)\\\\\\\\n\\\\\\\\n    # Ensure positive lengths; fall back to 2*lam if bounds collapse\\\\\\\\n    Lx = float(max(xmax_val - xmin_val, 1e-6))\\\\\\\\n    Ly = float(max(ymax_val - ymin_val, 1e-6))\\\\\\\\n    Lz = float(max(zmax_val - zmin_val, 1e-6)) if dim == 3 else None\\\\\\\\n    \\\\\\\\n    if not torch.isfinite(torch.tensor(Lx)) or Lx &lt; 1e-6:\\\\\\\\n        Lx = float(lam * 2.0)\\\\\\\\n    if not torch.isfinite(torch.tensor(Ly)) or Ly &lt; 1e-6:\\\\\\\\n        Ly = float(lam * 2.0)\\\\\\\\n    if dim == 3 and (Lz is None or not torch.isfinite(torch.tensor(Lz)) or Lz &lt; 1e-6):\\\\\\\\n        Lz = float(lam * 2.0)\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def _generate_power_spectrum_fallback(lam, v_1, x, seed=None):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":184,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":185},{\\\\\\\"text\\\\\\\":\\\\\\\"    Fallback power spectrum generation when shared fields are not available.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":186},{\\\\\\\"text\\\\\\\":\\\\\\\"    Supports both 2D and 3D FFT.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":187},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":188},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":189},{\\\\\\\"text\\\\\\\":\\\\\\\"        lam: Wavelength (unused for domain sizing in fallback)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":190},{\\\\\\\"text\\\\\\\":\\\\\\\"        v_1: Velocity amplitude\\\\\\\",\\\\\\\"lineNumber\\\\\\\":191},{\\\\\\\"text\\\\\\\":\\\\\\\"        x: Collocation coordinates [x, y, ...] for 2D or [x, y, z, ...] for 3D\\\\\\\",\\\\\\\"lineNumber\\\\\\\":192},{\\\\\\\"text\\\\\\\":\\\\\\\"        seed: Random seed\\\\\\\",\\\\\\\"lineNumber\\\\\\\":193},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":194},{\\\\\\\"text\\\\\\\":\\\\\\\"    Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":195},{\\\\\\\"text\\\\\\\":\\\\\\\"        Generated power spectrum field\\\\\\\",\\\\\\\"lineNumber\\\\\\\":196},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":197},{\\\\\\\"text\\\\\\\":\\\\\\\"    if seed is None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":198},{\\\\\\\"text\\\\\\\":\\\\\\\"        seed = RANDOM_SEED\\\\\\\",\\\\\\\"lineNumber\\\\\\\":199},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":200},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Detect dimension from coordinates\\\\\\\",\\\\\\\"lineNumber\\\\\\\":201},{\\\\\\\"text\\\\\\\":\\\\\\\"    dim = _detect_dimension(x)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":202},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":203},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Infer domain extents directly from the collocation coordinates to support arbitrary num_of_waves\\\\\\\",\\\\\\\"lineNumber\\\\\\\":204},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Use conservative defaults if tensors are degenerate (e.g., single point during a unit test)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":205},{\\\\\\\"text\\\\\\\":\\\\\\\"    x_coords = x[0].detach()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":206},{\\\\\\\"text\\\\\\\":\\\\\\\"    y_coords = x[1].detach() if len(x) &gt; 1 else x[0].detach()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":207},{\\\\\\\"text\\\\\\\":\\\\\\\"    z_coords = x[2].detach() if len(x) &gt; 2 and dim == 3 else None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":208},{\\\\\\\"lineNumber\\\\\\\":209},{\\\\\\\"text\\\\\\\":\\\\\\\"    xmin_val = torch.min(x_coords).item() if x_coords.numel() &gt; 0 else 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":210},{\\\\\\\"text\\\\\\\":\\\\\\\"    xmax_val = torch.max(x_coords).item() if x_coords.numel() &gt; 0 else float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":211},{\\\\\\\"text\\\\\\\":\\\\\\\"    ymin_val = torch.min(y_coords).item() if y_coords.numel() &gt; 0 else 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":212},{\\\\\\\"text\\\\\\\":\\\\\\\"    ymax_val = torch.max(y_coords).item() if y_coords.numel() &gt; 0 else float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":213},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":214},{\\\\\\\"text\\\\\\\":\\\\\\\"    if dim == 3 and z_coords is not None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":215},{\\\\\\\"text\\\\\\\":\\\\\\\"        zmin_val = torch.min(z_coords).item() if z_coords.numel() &gt; 0 else 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":216},{\\\\\\\"text\\\\\\\":\\\\\\\"        zmax_val = torch.max(z_coords).item() if z_coords.numel() &gt; 0 else float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":217},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":218},{\\\\\\\"text\\\\\\\":\\\\\\\"        zmin_val = 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":219},{\\\\\\\"text\\\\\\\":\\\\\\\"        zmax_val = float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":220},{\\\\\\\"lineNumber\\\\\\\":221},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Ensure positive lengths; fall back to 2*lam if bounds collapse\\\\\\\",\\\\\\\"lineNumber\\\\\\\":222},{\\\\\\\"text\\\\\\\":\\\\\\\"    Lx = float(max(xmax_val - xmin_val, 1e-6))\\\\\\\",\\\\\\\"lineNumber\\\\\\\":223},{\\\\\\\"text\\\\\\\":\\\\\\\"    Ly = float(max(ymax_val - ymin_val, 1e-6))\\\\\\\",\\\\\\\"lineNumber\\\\\\\":224},{\\\\\\\"text\\\\\\\":\\\\\\\"    Lz = float(max(zmax_val - zmin_val, 1e-6)) if dim == 3 else None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":225},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":226},{\\\\\\\"text\\\\\\\":\\\\\\\"    if not torch.isfinite(torch.tensor(Lx)) or Lx &lt; 1e-6:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":227},{\\\\\\\"text\\\\\\\":\\\\\\\"        Lx = float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":228},{\\\\\\\"text\\\\\\\":\\\\\\\"    if not torch.isfinite(torch.tensor(Ly)) or Ly &lt; 1e-6:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":229},{\\\\\\\"text\\\\\\\":\\\\\\\"        Ly = float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":230},{\\\\\\\"text\\\\\\\":\\\\\\\"    if dim == 3 and (Lz is None or not torch.isfinite(torch.tensor(Lz)) or Lz &lt; 1e-6):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":231},{\\\\\\\"text\\\\\\\":\\\\\\\"        Lz = float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":232}]},\\\\\\\"score\\\\\\\":0.2942143678665161},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":27},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282}},\\\\\\\"contents\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\\ndef geo_time_coord(self,option,coordinate=1):\\\\\\\\n\\\\\\\\n    \\\\\\\\n            \\\\\\\\n        if self.dimension == 3: \\\\\\\\n            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\\n                x_dom = self._generate_uniform_tensor(self.N_r, self.rmin[0], self.rmax[0])\\\\\\\\n                y_dom = self._generate_uniform_tensor(self.N_r, self.rmin[1], self.rmax[1])\\\\\\\\n                z_dom = self._generate_uniform_tensor(self.N_r, self.rmin[2], self.rmax[2])\\\\\\\\n                t_dom = self._generate_uniform_tensor(self.N_r, max(self.rmin[3], STARTUP_DT), self.rmax[3])\\\\\\\\n                return [x_dom, y_dom, z_dom, t_dom]\\\\\\\\n\\\\\\\\n            if option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\\n                x_0 = self._generate_uniform_tensor(self.N_0, self.rmin[0], self.rmax[0])\\\\\\\\n                y_0 = self._generate_uniform_tensor(self.N_0, self.rmin[1], self.rmax[1])\\\\\\\\n                z_0 = self._generate_uniform_tensor(self.N_0, self.rmin[2], self.rmax[2])\\\\\\\\n                t_0 = self._generate_constant_tensor(self.N_0, 0.0)\\\\\\\\n                return [x_0, y_0, z_0, t_0]\\\\\\\\n             \\\\\\\\n\\\\\\\\n            if option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":28,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":29,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":92,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":93,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class col_gen(object):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":28,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def geo_time_coord(self,option,coordinate=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":92},{\\\\\\\"lineNumber\\\\\\\":148},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":149},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":150},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 3: \\\\\\\",\\\\\\\"lineNumber\\\\\\\":151},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"Domain\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":152},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_dom = self._generate_uniform_tensor(self.N_r, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":153},{\\\\\\\"text\\\\\\\":\\\\\\\"                y_dom = self._generate_uniform_tensor(self.N_r, self.rmin[1], self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":154},{\\\\\\\"text\\\\\\\":\\\\\\\"                z_dom = self._generate_uniform_tensor(self.N_r, self.rmin[2], self.rmax[2])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":155},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_dom = self._generate_uniform_tensor(self.N_r, max(self.rmin[3], STARTUP_DT), self.rmax[3])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":156},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_dom, y_dom, z_dom, t_dom]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":157},{\\\\\\\"lineNumber\\\\\\\":158},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"IC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":159},{\\\\\\\"text\\\\\\\":\\\\\\\"                x_0 = self._generate_uniform_tensor(self.N_0, self.rmin[0], self.rmax[0])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":160},{\\\\\\\"text\\\\\\\":\\\\\\\"                y_0 = self._generate_uniform_tensor(self.N_0, self.rmin[1], self.rmax[1])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":161},{\\\\\\\"text\\\\\\\":\\\\\\\"                z_0 = self._generate_uniform_tensor(self.N_0, self.rmin[2], self.rmax[2])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":162},{\\\\\\\"text\\\\\\\":\\\\\\\"                t_0 = self._generate_constant_tensor(self.N_0, 0.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":163},{\\\\\\\"text\\\\\\\":\\\\\\\"                return [x_0, y_0, z_0, t_0]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":164},{\\\\\\\"text\\\\\\\":\\\\\\\"             \\\\\\\",\\\\\\\"lineNumber\\\\\\\":165},{\\\\\\\"lineNumber\\\\\\\":166},{\\\\\\\"text\\\\\\\":\\\\\\\"            if option == \\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":167}]},\\\\\\\"score\\\\\\\":0.28090208768844604},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":524,\\\\\\\"column\\\\\\\":47},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":637}},\\\\\\\"contents\\\\\\\":\\\\\\\"def Two_D_surface_plots(net, time, initial_params, ax=None, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", fd_cache=None):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Create 2D surface plots with velocity vectors\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        net: Trained neural network OR list of networks (for XPINN)\\\\\\\\n        time: Time to plot\\\\\\\\n        initial_params: Tuple containing (xmin, xmax, ymin, ymax, rho_1, alpha, lam, output_folder, tmax)\\\\\\\\n        ax: Optional axis to plot on\\\\\\\\n        which: \\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"velocity\\\\\\\\\\\\\\\"\\\\\\\\n        fd_cache: Optional FD cache for z-slice alignment in 3D power spectrum cases\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    xmin, xmax, ymin, ymax, rho_1, alpha, lam, output_folder, tmax = initial_params\\\\\\\\n    \\\\\\\\n    # Handle both single network and list of networks\\\\\\\\n    if isinstance(net, list):\\\\\\\\n        nets = net\\\\\\\\n        use_xpinn = len(nets) &gt; 1\\\\\\\\n    else:\\\\\\\\n        nets = [net]\\\\\\\\n        use_xpinn = False\\\\\\\\n    \\\\\\\\n    # Use N_GRID for consistency with FD solver resolution\\\\\\\\n    # Exclude right boundary for periodic domains to avoid double-counting\\\\\\\\n    Q = N_GRID\\\\\\\\n    xs = np.linspace(xmin, xmax, Q, endpoint=False)\\\\\\\\n    ys = np.linspace(ymin, ymax, Q, endpoint=False)\\\\\\\\n    tau, phi = np.meshgrid(xs, ys) \\\\\\\\n    Xgrid = np.vstack([tau.flatten(), phi.flatten()]).T\\\\\\\\n    t_00 = time * np.ones(Q**2).reshape(Q**2, 1)\\\\\\\\n    \\\\\\\\n    # Convert to tensors\\\\\\\\n    pt_x_collocation = Variable(torch.from_numpy(Xgrid[:, 0:1]).float(), requires_grad=True).to(device)\\\\\\\\n    pt_y_collocation = Variable(torch.from_numpy(Xgrid[:, 1:2]).float(), requires_grad=True).to(device) if DIMENSION &gt;= 2 else None\\\\\\\\n    if DIMENSION &gt;= 3:\\\\\\\\n        z_val_use = SLICE_Z\\\\\\\\n        if fd_cache is not None and time in fd_cache:\\\\\\\\n            z_val_use = fd_cache[time].get('z_val', SLICE_Z)\\\\\\\\n        pt_z_collocation = Variable(torch.from_numpy(np.full((Q**2, 1), z_val_use)).float(), requires_grad=True).to(device)\\\\\\\\n    else:\\\\\\\\n        pt_z_collocation = None\\\\\\\\n    pt_t_collocation = Variable(torch.from_numpy(t_00).float(), requires_grad=True).to(device)\\\\\\\\n    \\\\\\\\n    # Evaluate network(s)\\\\\\\\n    if use_xpinn\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def Two_D_surface_plots(net, time, initial_params, ax=None, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", fd_cache=None):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":528,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":529},{\\\\\\\"text\\\\\\\":\\\\\\\"    Create 2D surface plots with velocity vectors\\\\\\\",\\\\\\\"lineNumber\\\\\\\":530},{\\\\\\\"lineNumber\\\\\\\":531},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":532},{\\\\\\\"text\\\\\\\":\\\\\\\"        net: Trained neural network OR list of networks (for XPINN)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":533},{\\\\\\\"text\\\\\\\":\\\\\\\"        time: Time to plot\\\\\\\",\\\\\\\"lineNumber\\\\\\\":534},{\\\\\\\"text\\\\\\\":\\\\\\\"        initial_params: Tuple containing (xmin, xmax, ymin, ymax, rho_1, alpha, lam, output_folder, tmax)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":535},{\\\\\\\"text\\\\\\\":\\\\\\\"        ax: Optional axis to plot on\\\\\\\",\\\\\\\"lineNumber\\\\\\\":536},{\\\\\\\"text\\\\\\\":\\\\\\\"        which: \\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"velocity\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":537},{\\\\\\\"text\\\\\\\":\\\\\\\"        fd_cache: Optional FD cache for z-slice alignment in 3D power spectrum cases\\\\\\\",\\\\\\\"lineNumber\\\\\\\":538},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":539},{\\\\\\\"text\\\\\\\":\\\\\\\"    xmin, xmax, ymin, ymax, rho_1, alpha, lam, output_folder, tmax = initial_params\\\\\\\",\\\\\\\"lineNumber\\\\\\\":540},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":541},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Handle both single network and list of networks\\\\\\\",\\\\\\\"lineNumber\\\\\\\":542},{\\\\\\\"text\\\\\\\":\\\\\\\"    if isinstance(net, list):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":543},{\\\\\\\"text\\\\\\\":\\\\\\\"        nets = net\\\\\\\",\\\\\\\"lineNumber\\\\\\\":544},{\\\\\\\"text\\\\\\\":\\\\\\\"        use_xpinn = len(nets) &gt; 1\\\\\\\",\\\\\\\"lineNumber\\\\\\\":545},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":546},{\\\\\\\"text\\\\\\\":\\\\\\\"        nets = [net]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":547},{\\\\\\\"text\\\\\\\":\\\\\\\"        use_xpinn = False\\\\\\\",\\\\\\\"lineNumber\\\\\\\":548},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":549},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Use N_GRID for consistency with FD solver resolution\\\\\\\",\\\\\\\"lineNumber\\\\\\\":550},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Exclude right boundary for periodic domains to avoid double-counting\\\\\\\",\\\\\\\"lineNumber\\\\\\\":551},{\\\\\\\"text\\\\\\\":\\\\\\\"    Q = N_GRID\\\\\\\",\\\\\\\"lineNumber\\\\\\\":552},{\\\\\\\"text\\\\\\\":\\\\\\\"    xs = np.linspace(xmin, xmax, Q, endpoint=False)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":553},{\\\\\\\"text\\\\\\\":\\\\\\\"    ys = np.linspace(ymin, ymax, Q, endpoint=False)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":554},{\\\\\\\"text\\\\\\\":\\\\\\\"    tau, phi = np.meshgrid(xs, ys) \\\\\\\",\\\\\\\"lineNumber\\\\\\\":555},{\\\\\\\"text\\\\\\\":\\\\\\\"    Xgrid = np.vstack([tau.flatten(), phi.flatten()]).T\\\\\\\",\\\\\\\"lineNumber\\\\\\\":556},{\\\\\\\"text\\\\\\\":\\\\\\\"    t_00 = time * np.ones(Q**2).reshape(Q**2, 1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":557},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":558},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Convert to tensors\\\\\\\",\\\\\\\"lineNumber\\\\\\\":559},{\\\\\\\"text\\\\\\\":\\\\\\\"    pt_x_collocation = Variable(torch.from_numpy(Xgrid[:, 0:1]).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":560},{\\\\\\\"text\\\\\\\":\\\\\\\"    pt_y_collocation = Variable(torch.from_numpy(Xgrid[:, 1:2]).float(), requires_grad=True).to(device) if DIMENSION &gt;= 2 else None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":561},{\\\\\\\"text\\\\\\\":\\\\\\\"    if DIMENSION &gt;= 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":562},{\\\\\\\"text\\\\\\\":\\\\\\\"        z_val_use = SLICE_Z\\\\\\\",\\\\\\\"lineNumber\\\\\\\":563},{\\\\\\\"text\\\\\\\":\\\\\\\"        if fd_cache is not None and time in fd_cache:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":564},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_val_use = fd_cache[time].get('z_val', SLICE_Z)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":565},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_z_collocation = Variable(torch.from_numpy(np.full((Q**2, 1), z_val_use)).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":566},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":567},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_z_collocation = None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":568},{\\\\\\\"text\\\\\\\":\\\\\\\"    pt_t_collocation = Variable(torch.from_numpy(t_00).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":569},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":570},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Evaluate network(s)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":571},{\\\\\\\"text\\\\\\\":\\\\\\\"    if use_xpinn\\\\\\\",\\\\\\\"lineNumber\\\\\\\":572}]},\\\\\\\"score\\\\\\\":0.27729150652885437},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2262},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2629}},\\\\\\\"contents\\\\\\\":\\\\\\\"def create_5x3_comparison_table(net, initial_params, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", N=200, nu=None,\\\\\\\\n                                use_velocity_ps=None, ps_index=None, vel_rms=None, random_seed=None,\\\\\\\\n                                fd_cache=None):\\\\\\\\n\\\\\\\\n    \\\\\\\\n    print(f\\\\\\\\\\\\\\\"Creating 5x3 comparison table for {which}...\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Create 5x3 subplot grid\\\\\\\\n    fig, axes = plt.subplots(5, 3, figsize=(15, 20))\\\\\\\\n    \\\\\\\\n    # Store data for consistent color limits\\\\\\\\n    pinn_data = []\\\\\\\\n    fd_data = []\\\\\\\\n    pinn_velocity_data = []  # Store velocity components separately\\\\\\\\n    fd_velocity_data = []    # Store velocity components separately\\\\\\\\n    \\\\\\\\n    # First pass: collect data to determine consistent color limits\\\\\\\\n    for i, t in enumerate(time_points):\\\\\\\\n        # print(f\\\\\\\\\\\\\\\"Collecting data for t = {t:.2f}\\\\\\\\\\\\\\\")  # Commented out to reduce output noise\\\\\\\\n        \\\\\\\\n        # Get PINN data - use N_GRID for consistency with FD solver\\\\\\\\n        # Exclude right boundary for periodic domains to avoid double-counting\\\\\\\\n        Q = N_GRID\\\\\\\\n        xs = np.linspace(xmin, xmax, Q, endpoint=False)\\\\\\\\n        ys = np.linspace(ymin, ymax, Q, endpoint=False)\\\\\\\\n        tau, phi = np.meshgrid(xs, ys) \\\\\\\\n        Xgrid = np.vstack([tau.flatten(), phi.flatten()]).T\\\\\\\\n        t_00 = t * np.ones(Q**2).reshape(Q**2, 1)\\\\\\\\n        \\\\\\\\n        pt_x_collocation = Variable(torch.from_numpy(Xgrid[:, 0:1]).float(), requires_grad=True).to(device)\\\\\\\\n        pt_y_collocation = Variable(torch.from_numpy(Xgrid[:, 1:2]).float(), requires_grad=True).to(device) if DIMENSION &gt;= 2 else None\\\\\\\\n        if DIMENSION &gt;= 3:\\\\\\\\n            z_val_use = SLICE_Z\\\\\\\\n            if fd_cache is not None and t in fd_cache:\\\\\\\\n                z_val_use = fd_cache[t].get('z_val', SLICE_Z)\\\\\\\\n            pt_z_collocation = Variable(torch.from_numpy(np.full((Q**2, 1), z_val_use)).float(), requires_grad=True).to(device)\\\\\\\\n        else:\\\\\\\\n            pt_z_collocation = None\\\\\\\\n        pt_t_collocation = Variable(torch.from_numpy(t_00).float(), requires_grad=True).to(device)\\\\\\\\n        \\\\\\\\n        if use_xpinn:\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2263,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2266,\\\\\\\"column\\\\\\\":5}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def create_5x3_comparison_table(net, initial_params, which=\\\\\\\\\\\\\\\"density\\\\\\\\\\\\\\\", N=200, nu=None,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2263,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"                                use_velocity_ps=None, ps_index=None, vel_rms=None, random_seed=None,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2264,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"                                fd_cache=None):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2265,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":2304},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2305},{\\\\\\\"text\\\\\\\":\\\\\\\"    print(f\\\\\\\\\\\\\\\"Creating 5x3 comparison table for {which}...\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2306},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2307},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Create 5x3 subplot grid\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2308},{\\\\\\\"text\\\\\\\":\\\\\\\"    fig, axes = plt.subplots(5, 3, figsize=(15, 20))\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2309},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2310},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Store data for consistent color limits\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2311},{\\\\\\\"text\\\\\\\":\\\\\\\"    pinn_data = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2312},{\\\\\\\"text\\\\\\\":\\\\\\\"    fd_data = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2313},{\\\\\\\"text\\\\\\\":\\\\\\\"    pinn_velocity_data = []  # Store velocity components separately\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2314},{\\\\\\\"text\\\\\\\":\\\\\\\"    fd_velocity_data = []    # Store velocity components separately\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2315},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2316},{\\\\\\\"text\\\\\\\":\\\\\\\"    # First pass: collect data to determine consistent color limits\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2317},{\\\\\\\"text\\\\\\\":\\\\\\\"    for i, t in enumerate(time_points):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2318},{\\\\\\\"text\\\\\\\":\\\\\\\"        # print(f\\\\\\\\\\\\\\\"Collecting data for t = {t:.2f}\\\\\\\\\\\\\\\")  # Commented out to reduce output noise\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2319},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2320},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Get PINN data - use N_GRID for consistency with FD solver\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2321},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Exclude right boundary for periodic domains to avoid double-counting\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2322},{\\\\\\\"text\\\\\\\":\\\\\\\"        Q = N_GRID\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2323},{\\\\\\\"text\\\\\\\":\\\\\\\"        xs = np.linspace(xmin, xmax, Q, endpoint=False)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2324},{\\\\\\\"text\\\\\\\":\\\\\\\"        ys = np.linspace(ymin, ymax, Q, endpoint=False)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2325},{\\\\\\\"text\\\\\\\":\\\\\\\"        tau, phi = np.meshgrid(xs, ys) \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2326},{\\\\\\\"text\\\\\\\":\\\\\\\"        Xgrid = np.vstack([tau.flatten(), phi.flatten()]).T\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2327},{\\\\\\\"text\\\\\\\":\\\\\\\"        t_00 = t * np.ones(Q**2).reshape(Q**2, 1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2328},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2329},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_x_collocation = Variable(torch.from_numpy(Xgrid[:, 0:1]).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2330},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_y_collocation = Variable(torch.from_numpy(Xgrid[:, 1:2]).float(), requires_grad=True).to(device) if DIMENSION &gt;= 2 else None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2331},{\\\\\\\"text\\\\\\\":\\\\\\\"        if DIMENSION &gt;= 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2332},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_val_use = SLICE_Z\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2333},{\\\\\\\"text\\\\\\\":\\\\\\\"            if fd_cache is not None and t in fd_cache:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2334},{\\\\\\\"text\\\\\\\":\\\\\\\"                z_val_use = fd_cache[t].get('z_val', SLICE_Z)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2335},{\\\\\\\"text\\\\\\\":\\\\\\\"            pt_z_collocation = Variable(torch.from_numpy(np.full((Q**2, 1), z_val_use)).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2336},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2337},{\\\\\\\"text\\\\\\\":\\\\\\\"            pt_z_collocation = None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2338},{\\\\\\\"text\\\\\\\":\\\\\\\"        pt_t_collocation = Variable(torch.from_numpy(t_00).float(), requires_grad=True).to(device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2339},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2340},{\\\\\\\"text\\\\\\\":\\\\\\\"        if use_xpinn:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2341}]},\\\\\\\"score\\\\\\\":0.276975154876709},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":7},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2113}},\\\\\\\"contents\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\\ndef compute_field_spectrum_comparison(self, model, true_ic_data, n_grid=128):\\\\\\\\n\\\\\\\\n        \\\\\\\\n        if self.dimension == 3:\\\\\\\\n            z_ic = colloc_IC[2].detach().cpu().numpy().flatten()\\\\\\\\n            # Use points near z=middle for 2D slice\\\\\\\\n            zmid = (zmin + zmax) / 2.0\\\\\\\\n            z_tolerance = 0.1 * (zmax - zmin)  # 10% of domain\\\\\\\\n            mask_z = np.abs(z_ic - zmid) &lt; z_tolerance\\\\\\\\n            if mask_z.sum() &lt; 100:\\\\\\\\n                mask_z = np.ones(len(z_ic), dtype=bool)\\\\\\\\n        else:\\\\\\\\n            mask_z = np.ones(len(x_ic), dtype=bool)\\\\\\\\n        \\\\\\\\n        # Create regular grid for FFT\\\\\\\\n        # Get actual domain bounds\\\\\\\\n        xmin, xmax, ymin, ymax, zmin, zmax = self._get_domain_bounds(model, self.dimension)\\\\\\\\n        \\\\\\\\n        x_grid = np.linspace(xmin, xmax, n_grid)\\\\\\\\n        y_grid = np.linspace(ymin, ymax, n_grid)\\\\\\\\n        X_grid, Y_grid = np.meshgrid(x_grid, y_grid, indexing='ij')\\\\\\\\n        \\\\\\\\n        # Interpolate from scattered IC points to regular grid\\\\\\\\n        from scipy.interpolate import griddata\\\\\\\\n        points_ic = np.column_stack([x_ic[mask_z], y_ic[mask_z]])\\\\\\\\n        points_grid = np.column_stack([X_grid.flatten(), Y_grid.flatten()])\\\\\\\\n        \\\\\\\\n        # Interpolate density\\\\\\\\n        rho_pred_grid = griddata(points_ic, rho_pred[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\\n        rho_true_grid = griddata(points_ic, rho_true[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\\n        \\\\\\\\n        # Interpolate velocities\\\\\\\\n        vx_pred_grid = griddata(points_ic, vx_pred[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\\n        vy_pred_grid = griddata(points_ic, vy_pred[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\\n        \\\\\\\\n        vx_true_grid = griddata(points_ic, vx_true[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\\n        vy_true_grid = griddata(points_ic, vy_true[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\\n        \\\\\\\\n        if self.dimension == 3:\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":8,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":9,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1871,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1872,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":8,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def compute_field_spectrum_comparison(self, model, true_ic_data, n_grid=128):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1950},{\\\\\\\"lineNumber\\\\\\\":1980},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1981},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1982},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_ic = colloc_IC[2].detach().cpu().numpy().flatten()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1983},{\\\\\\\"text\\\\\\\":\\\\\\\"            # Use points near z=middle for 2D slice\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1984},{\\\\\\\"text\\\\\\\":\\\\\\\"            zmid = (zmin + zmax) / 2.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1985},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_tolerance = 0.1 * (zmax - zmin)  # 10% of domain\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1986},{\\\\\\\"text\\\\\\\":\\\\\\\"            mask_z = np.abs(z_ic - zmid) &lt; z_tolerance\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1987},{\\\\\\\"text\\\\\\\":\\\\\\\"            if mask_z.sum() &lt; 100:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1988},{\\\\\\\"text\\\\\\\":\\\\\\\"                mask_z = np.ones(len(z_ic), dtype=bool)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1989},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1990},{\\\\\\\"text\\\\\\\":\\\\\\\"            mask_z = np.ones(len(x_ic), dtype=bool)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1991},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1992},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Create regular grid for FFT\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1993},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Get actual domain bounds\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1994},{\\\\\\\"text\\\\\\\":\\\\\\\"        xmin, xmax, ymin, ymax, zmin, zmax = self._get_domain_bounds(model, self.dimension)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1995},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1996},{\\\\\\\"text\\\\\\\":\\\\\\\"        x_grid = np.linspace(xmin, xmax, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1997},{\\\\\\\"text\\\\\\\":\\\\\\\"        y_grid = np.linspace(ymin, ymax, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1998},{\\\\\\\"text\\\\\\\":\\\\\\\"        X_grid, Y_grid = np.meshgrid(x_grid, y_grid, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1999},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2000},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Interpolate from scattered IC points to regular grid\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2001},{\\\\\\\"text\\\\\\\":\\\\\\\"        from scipy.interpolate import griddata\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2002},{\\\\\\\"text\\\\\\\":\\\\\\\"        points_ic = np.column_stack([x_ic[mask_z], y_ic[mask_z]])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2003},{\\\\\\\"text\\\\\\\":\\\\\\\"        points_grid = np.column_stack([X_grid.flatten(), Y_grid.flatten()])\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2004},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2005},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Interpolate density\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2006},{\\\\\\\"text\\\\\\\":\\\\\\\"        rho_pred_grid = griddata(points_ic, rho_pred[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2007},{\\\\\\\"text\\\\\\\":\\\\\\\"        rho_true_grid = griddata(points_ic, rho_true[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2008},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2009},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Interpolate velocities\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2010},{\\\\\\\"text\\\\\\\":\\\\\\\"        vx_pred_grid = griddata(points_ic, vx_pred[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2011},{\\\\\\\"text\\\\\\\":\\\\\\\"        vy_pred_grid = griddata(points_ic, vy_pred[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2012},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2013},{\\\\\\\"text\\\\\\\":\\\\\\\"        vx_true_grid = griddata(points_ic, vx_true[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2014},{\\\\\\\"text\\\\\\\":\\\\\\\"        vy_true_grid = griddata(points_ic, vy_true[mask_z], points_grid, method='linear', fill_value=0).reshape(n_grid, n_grid)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2015},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":2016},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2017}]},\\\\\\\"score\\\\\\\":0.27626216411590576},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\initial_conditions.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":183},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":340}},\\\\\\\"contents\\\\\\\":\\\\\\\"def _generate_power_spectrum_fallback(lam, v_1, x, seed=None):\\\\\\\\n\\\\\\\\n    if dim == 3 and (Lz is None or not torch.isfinite(torch.tensor(Lz)) or Lz &lt; 1e-6):\\\\\\\\n        Lz = float(lam * 2.0)\\\\\\\\n\\\\\\\\n    # Select grid size based on dimension\\\\\\\\n    if dim == 2:\\\\\\\\n        nx, ny = N_GRID, N_GRID\\\\\\\\n        nz = None\\\\\\\\n        dx = Lx / nx\\\\\\\\n        dy = Ly / ny\\\\\\\\n        dz = None\\\\\\\\n    else:  # dim == 3\\\\\\\\n        # Use N_GRID_3D for all dimensions in 3D for consistency\\\\\\\\n        nx, ny, nz = N_GRID_3D, N_GRID_3D, N_GRID_3D\\\\\\\\n        dx = Lx / nx\\\\\\\\n        dy = Ly / ny\\\\\\\\n        dz = Lz / nz\\\\\\\\n    \\\\\\\\n    # Calculate wave numbers\\\\\\\\n    kx = 2 * np.pi * torch.fft.fftfreq(nx, dx, device=x[0].device)\\\\\\\\n    ky = 2 * np.pi * torch.fft.fftfreq(ny, dy, device=x[0].device)\\\\\\\\n    \\\\\\\\n    if dim == 2:\\\\\\\\n        KX_grid, KY_grid = torch.meshgrid(kx, ky, indexing='ij')\\\\\\\\n        \\\\\\\\n        # Calculate magnitude of wave number\\\\\\\\n        K = torch.sqrt(KX_grid**2 + KY_grid**2)\\\\\\\\n        \\\\\\\\n        # Power spectrum: P(k) ~ k^expon\\\\\\\\n        K_safe = torch.where(K == 0, torch.tensor(1e-10, device=x[0].device), K)\\\\\\\\n        power_spectrum = K_safe**POWER_EXPONENT\\\\\\\\n        \\\\\\\\n        # Remove DC (uniform) mode to avoid bulk drift\\\\\\\\n        power_spectrum[K == 0] = 0.0\\\\\\\\n        \\\\\\\\n        # Safety check: limit extreme values\\\\\\\\n        power_spectrum = torch.clamp(power_spectrum, 0, 1e6)\\\\\\\\n        \\\\\\\\n        # Generate random phases\\\\\\\\n        torch.manual_seed(seed)\\\\\\\\n        random_phases = torch.randn(nx, ny, device=x[0].device) + 1j * torch.randn(nx, ny, device=x[0].device)\\\\\\\\n        \\\\\\\\n        # Create complex field in Fourier space and transform to real space\\\\\\\\n        field_fourier = torch.sqrt(power_spectrum) * random_phases\\\\\\\\n        field_real = torch.real(torch.fft.ifft2(field_fourier))\\\\\\\\n        \\\\\\\\n        # Remove any residual mean (bulk flow) and normalize rms to v_1\\\\\\\\n        field_real = field_real - torch.mean(field_real)\\\\\\\\n        field_real = field_real / torch.std(field_real) * v_1\\\\\\\\n        \\\\\\\\n        # Interpolate to the actual collocation points\\\\\\\\n        x_norm = torch.clamp(((x[0] - xmin_val) / Lx) * (nx - 1), 0, nx - 1)\\\\\\\\n        if len(x) &gt; 1:\\\\\\\\n            y_norm =\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":184,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":185,\\\\\\\"column\\\\\\\":5}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def _generate_power_spectrum_fallback(lam, v_1, x, seed=None):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":184,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":230},{\\\\\\\"text\\\\\\\":\\\\\\\"    if dim == 3 and (Lz is None or not torch.isfinite(torch.tensor(Lz)) or Lz &lt; 1e-6):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":231},{\\\\\\\"text\\\\\\\":\\\\\\\"        Lz = float(lam * 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":232},{\\\\\\\"lineNumber\\\\\\\":233},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Select grid size based on dimension\\\\\\\",\\\\\\\"lineNumber\\\\\\\":234},{\\\\\\\"text\\\\\\\":\\\\\\\"    if dim == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":235},{\\\\\\\"text\\\\\\\":\\\\\\\"        nx, ny = N_GRID, N_GRID\\\\\\\",\\\\\\\"lineNumber\\\\\\\":236},{\\\\\\\"text\\\\\\\":\\\\\\\"        nz = None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":237},{\\\\\\\"text\\\\\\\":\\\\\\\"        dx = Lx / nx\\\\\\\",\\\\\\\"lineNumber\\\\\\\":238},{\\\\\\\"text\\\\\\\":\\\\\\\"        dy = Ly / ny\\\\\\\",\\\\\\\"lineNumber\\\\\\\":239},{\\\\\\\"text\\\\\\\":\\\\\\\"        dz = None\\\\\\\",\\\\\\\"lineNumber\\\\\\\":240},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:  # dim == 3\\\\\\\",\\\\\\\"lineNumber\\\\\\\":241},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Use N_GRID_3D for all dimensions in 3D for consistency\\\\\\\",\\\\\\\"lineNumber\\\\\\\":242},{\\\\\\\"text\\\\\\\":\\\\\\\"        nx, ny, nz = N_GRID_3D, N_GRID_3D, N_GRID_3D\\\\\\\",\\\\\\\"lineNumber\\\\\\\":243},{\\\\\\\"text\\\\\\\":\\\\\\\"        dx = Lx / nx\\\\\\\",\\\\\\\"lineNumber\\\\\\\":244},{\\\\\\\"text\\\\\\\":\\\\\\\"        dy = Ly / ny\\\\\\\",\\\\\\\"lineNumber\\\\\\\":245},{\\\\\\\"text\\\\\\\":\\\\\\\"        dz = Lz / nz\\\\\\\",\\\\\\\"lineNumber\\\\\\\":246},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":247},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Calculate wave numbers\\\\\\\",\\\\\\\"lineNumber\\\\\\\":248},{\\\\\\\"text\\\\\\\":\\\\\\\"    kx = 2 * np.pi * torch.fft.fftfreq(nx, dx, device=x[0].device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":249},{\\\\\\\"text\\\\\\\":\\\\\\\"    ky = 2 * np.pi * torch.fft.fftfreq(ny, dy, device=x[0].device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":250},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":251},{\\\\\\\"text\\\\\\\":\\\\\\\"    if dim == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":252},{\\\\\\\"text\\\\\\\":\\\\\\\"        KX_grid, KY_grid = torch.meshgrid(kx, ky, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":253},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":254},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Calculate magnitude of wave number\\\\\\\",\\\\\\\"lineNumber\\\\\\\":255},{\\\\\\\"text\\\\\\\":\\\\\\\"        K = torch.sqrt(KX_grid**2 + KY_grid**2)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":256},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":257},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Power spectrum: P(k) ~ k^expon\\\\\\\",\\\\\\\"lineNumber\\\\\\\":258},{\\\\\\\"text\\\\\\\":\\\\\\\"        K_safe = torch.where(K == 0, torch.tensor(1e-10, device=x[0].device), K)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":259},{\\\\\\\"text\\\\\\\":\\\\\\\"        power_spectrum = K_safe**POWER_EXPONENT\\\\\\\",\\\\\\\"lineNumber\\\\\\\":260},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":261},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Remove DC (uniform) mode to avoid bulk drift\\\\\\\",\\\\\\\"lineNumber\\\\\\\":262},{\\\\\\\"text\\\\\\\":\\\\\\\"        power_spectrum[K == 0] = 0.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":263},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":264},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Safety check: limit extreme values\\\\\\\",\\\\\\\"lineNumber\\\\\\\":265},{\\\\\\\"text\\\\\\\":\\\\\\\"        power_spectrum = torch.clamp(power_spectrum, 0, 1e6)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":266},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":267},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Generate random phases\\\\\\\",\\\\\\\"lineNumber\\\\\\\":268},{\\\\\\\"text\\\\\\\":\\\\\\\"        torch.manual_seed(seed)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":269},{\\\\\\\"text\\\\\\\":\\\\\\\"        random_phases = torch.randn(nx, ny, device=x[0].device) + 1j * torch.randn(nx, ny, device=x[0].device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":270},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":271},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Create complex field in Fourier space and transform to real space\\\\\\\",\\\\\\\"lineNumber\\\\\\\":272},{\\\\\\\"text\\\\\\\":\\\\\\\"        field_fourier = torch.sqrt(power_spectrum) * random_phases\\\\\\\",\\\\\\\"lineNumber\\\\\\\":273},{\\\\\\\"text\\\\\\\":\\\\\\\"        field_real = torch.real(torch.fft.ifft2(field_fourier))\\\\\\\",\\\\\\\"lineNumber\\\\\\\":274},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":275},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Remove any residual mean (bulk flow) and normalize rms to v_1\\\\\\\",\\\\\\\"lineNumber\\\\\\\":276},{\\\\\\\"text\\\\\\\":\\\\\\\"        field_real = field_real - torch.mean(field_real)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":277},{\\\\\\\"text\\\\\\\":\\\\\\\"        field_real = field_real / torch.std(field_real) * v_1\\\\\\\",\\\\\\\"lineNumber\\\\\\\":278},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":279},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Interpolate to the actual collocation points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":280},{\\\\\\\"text\\\\\\\":\\\\\\\"        x_norm = torch.clamp(((x[0] - xmin_val) / Lx) * (nx - 1), 0, nx - 1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":281},{\\\\\\\"text\\\\\\\":\\\\\\\"        if len(x) &gt; 1:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":282},{\\\\\\\"text\\\\\\\":\\\\\\\"            y_norm =\\\\\\\",\\\\\\\"lineNumber\\\\\\\":283}]},\\\\\\\"score\\\\\\\":0.27011069655418396},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":7},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2113}},\\\\\\\"contents\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\\ndef compute_temporal_error_accumulation(self, model, dimension, tmax, n_times=30):\\\\\\\\n\\\\\\\\n        \\\\\\\\n        for t_val in time_points:\\\\\\\\n            if dimension == 2:\\\\\\\\n                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\\n                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\\n                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\\n                T = torch.full_like(X, t_val)\\\\\\\\n                \\\\\\\\n                X_flat = X.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                Y_flat = Y.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                T_flat = T.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                \\\\\\\\n                colloc = [X_flat, Y_flat, T_flat]\\\\\\\\n            else:  # dimension == 3\\\\\\\\n                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\\n                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\\n                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\\n                Z = torch.full_like(X, (zmin + zmax) / 2.0)\\\\\\\\n                T = torch.full_like(X, t_val)\\\\\\\\n                \\\\\\\\n                X_flat = X.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                Y_flat = Y.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                Z_flat = Z.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                T_flat = T.reshape(-1, 1).requires_grad_(True)\\\\\\\\n                \\\\\\\\n                colloc = [X_flat, Y_flat, Z_flat, T_flat]\\\\\\\\n            \\\\\\\\n            # Compute ACTUAL PDE residuals using the proper residue function\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":8,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":9,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":800,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":801,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":8,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def compute_temporal_error_accumulation(self, model, dimension, tmax, n_times=30):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":800},{\\\\\\\"lineNumber\\\\\\\":828},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":829},{\\\\\\\"text\\\\\\\":\\\\\\\"        for t_val in time_points:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":830},{\\\\\\\"text\\\\\\\":\\\\\\\"            if dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":831},{\\\\\\\"text\\\\\\\":\\\\\\\"                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":832},{\\\\\\\"text\\\\\\\":\\\\\\\"                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":833},{\\\\\\\"text\\\\\\\":\\\\\\\"                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":834},{\\\\\\\"text\\\\\\\":\\\\\\\"                T = torch.full_like(X, t_val)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":835},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":836},{\\\\\\\"text\\\\\\\":\\\\\\\"                X_flat = X.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":837},{\\\\\\\"text\\\\\\\":\\\\\\\"                Y_flat = Y.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":838},{\\\\\\\"text\\\\\\\":\\\\\\\"                T_flat = T.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":839},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":840},{\\\\\\\"text\\\\\\\":\\\\\\\"                colloc = [X_flat, Y_flat, T_flat]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":841},{\\\\\\\"text\\\\\\\":\\\\\\\"            else:  # dimension == 3\\\\\\\",\\\\\\\"lineNumber\\\\\\\":842},{\\\\\\\"text\\\\\\\":\\\\\\\"                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":843},{\\\\\\\"text\\\\\\\":\\\\\\\"                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":844},{\\\\\\\"text\\\\\\\":\\\\\\\"                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":845},{\\\\\\\"text\\\\\\\":\\\\\\\"                Z = torch.full_like(X, (zmin + zmax) / 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":846},{\\\\\\\"text\\\\\\\":\\\\\\\"                T = torch.full_like(X, t_val)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":847},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":848},{\\\\\\\"text\\\\\\\":\\\\\\\"                X_flat = X.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":849},{\\\\\\\"text\\\\\\\":\\\\\\\"                Y_flat = Y.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":850},{\\\\\\\"text\\\\\\\":\\\\\\\"                Z_flat = Z.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":851},{\\\\\\\"text\\\\\\\":\\\\\\\"                T_flat = T.reshape(-1, 1).requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":852},{\\\\\\\"text\\\\\\\":\\\\\\\"                \\\\\\\",\\\\\\\"lineNumber\\\\\\\":853},{\\\\\\\"text\\\\\\\":\\\\\\\"                colloc = [X_flat, Y_flat, Z_flat, T_flat]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":854},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":855},{\\\\\\\"text\\\\\\\":\\\\\\\"            # Compute ACTUAL PDE residuals using the proper residue function\\\\\\\",\\\\\\\"lineNumber\\\\\\\":856}]},\\\\\\\"score\\\\\\\":0.2673049867153168},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":7},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2113}},\\\\\\\"contents\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\\ndef compute_solution_stability(self, model, dimension, tmax, stats_data, n_check=20):\\\\\\\\n\\\\\\\\n            if dimension == 2:\\\\\\\\n                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\\n                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\\n                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\\n                T = torch.full_like(X, t_val)\\\\\\\\n                colloc = [X.reshape(-1, 1), Y.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\\n            else:\\\\\\\\n                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\\n                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\\n                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\\n                Z = torch.full_like(X, (zmin + zmax) / 2.0)\\\\\\\\n                T = torch.full_like(X, t_val)\\\\\\\\n                colloc = [X.reshape(-1, 1), Y.reshape(-1, 1), Z.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\\n            \\\\\\\\n            with torch.no_grad():\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":8,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":9,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1156,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1157,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":8,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def compute_solution_stability(self, model, dimension, tmax, stats_data, n_check=20):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1156},{\\\\\\\"lineNumber\\\\\\\":1177},{\\\\\\\"text\\\\\\\":\\\\\\\"            if dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1178},{\\\\\\\"text\\\\\\\":\\\\\\\"                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1179},{\\\\\\\"text\\\\\\\":\\\\\\\"                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1180},{\\\\\\\"text\\\\\\\":\\\\\\\"                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1181},{\\\\\\\"text\\\\\\\":\\\\\\\"                T = torch.full_like(X, t_val)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1182},{\\\\\\\"text\\\\\\\":\\\\\\\"                colloc = [X.reshape(-1, 1), Y.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1183},{\\\\\\\"text\\\\\\\":\\\\\\\"            else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1184},{\\\\\\\"text\\\\\\\":\\\\\\\"                x = torch.linspace(xmin, xmax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1185},{\\\\\\\"text\\\\\\\":\\\\\\\"                y = torch.linspace(ymin, ymax, n_spatial, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1186},{\\\\\\\"text\\\\\\\":\\\\\\\"                X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1187},{\\\\\\\"text\\\\\\\":\\\\\\\"                Z = torch.full_like(X, (zmin + zmax) / 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1188},{\\\\\\\"text\\\\\\\":\\\\\\\"                T = torch.full_like(X, t_val)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1189},{\\\\\\\"text\\\\\\\":\\\\\\\"                colloc = [X.reshape(-1, 1), Y.reshape(-1, 1), Z.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1190},{\\\\\\\"text\\\\\\\":\\\\\\\"            \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1191},{\\\\\\\"text\\\\\\\":\\\\\\\"            with torch.no_grad():\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1192}]},\\\\\\\"score\\\\\\\":0.25774291157722473},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\trainer.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":237,\\\\\\\"column\\\\\\\":12},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":350}},\\\\\\\"contents\\\\\\\":\\\\\\\"def _compute_poisson_loss_from_ic(net, collocation_points, rho_1, lam, dimension):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Compute Poisson loss using IC density (Stage 1).\\\\\\\\n    \\\\\\\\n    The Poisson equation is: âˆ‡Â²Ï† = const * (Ï - Ïâ‚€)\\\\\\\\n    We use the true IC density Ï_ic from fun_rho_0 and the network's predicted Ï†.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    from core.data_generator import diff\\\\\\\\n    from core.initial_conditions import fun_rho_0\\\\\\\\n    from config import const, rho_o\\\\\\\\n    \\\\\\\\n    # Ensure coords is a list and enable gradient tracking\\\\\\\\n    if isinstance(collocation_points, (list, tuple)):\\\\\\\\n        coords = []\\\\\\\\n        for coord in collocation_points:\\\\\\\\n            if not coord.requires_grad:\\\\\\\\n                coord = coord.requires_grad_(True)\\\\\\\\n            coords.append(coord)\\\\\\\\n    else:\\\\\\\\n        # Single tensor format: split into [x, y, (z), t] and enable gradients\\\\\\\\n        coords = []\\\\\\\\n        for i in range(collocation_points.shape[1]):\\\\\\\\n            coord = collocation_points[:, i:i+1]\\\\\\\\n            if not coord.requires_grad:\\\\\\\\n                coord = coord.requires_grad_(True)\\\\\\\\n            coords.append(coord)\\\\\\\\n    \\\\\\\\n    # Forward pass (network expects list format)\\\\\\\\n    outputs = net(coords)\\\\\\\\n    phi = outputs[:, _phi_slice_index(dimension):_phi_slice_index(dimension) + 1]\\\\\\\\n\\\\\\\\n    if not torch.isfinite(phi).all():\\\\\\\\n        safe = torch.tensor(0.0, device=phi.device, requires_grad=True)\\\\\\\\n        return safe\\\\\\\\n    \\\\\\\\n    # Extract spatial coordinates\\\\\\\\n    x = coords[0]\\\\\\\\n    \\\\\\\\n    # Compute first derivative to detect blow-ups early\\\\\\\\n    phi_x = diff(phi, x, order=1)\\\\\\\\n    if torch.isinf(phi_x).any():\\\\\\\\n        safe = torch.tensor(1e10, device=phi.device, requires_grad=True)\\\\\\\\n        return safe\\\\\\\\n\\\\\\\\n    # Check for NaN in phi before computing laplacian\\\\\\\\n    if\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def _compute_poisson_loss_from_ic(net, collocation_points, rho_1, lam, dimension):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":241,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":242},{\\\\\\\"text\\\\\\\":\\\\\\\"    Compute Poisson loss using IC density (Stage 1).\\\\\\\",\\\\\\\"lineNumber\\\\\\\":243},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":244},{\\\\\\\"text\\\\\\\":\\\\\\\"    The Poisson equation is: âˆ‡Â²Ï† = const * (Ï - Ïâ‚€)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":245},{\\\\\\\"text\\\\\\\":\\\\\\\"    We use the true IC density Ï_ic from fun_rho_0 and the network's predicted Ï†.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":246},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":247},{\\\\\\\"text\\\\\\\":\\\\\\\"    from core.data_generator import diff\\\\\\\",\\\\\\\"lineNumber\\\\\\\":248},{\\\\\\\"text\\\\\\\":\\\\\\\"    from core.initial_conditions import fun_rho_0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":249},{\\\\\\\"text\\\\\\\":\\\\\\\"    from config import const, rho_o\\\\\\\",\\\\\\\"lineNumber\\\\\\\":250},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":251},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Ensure coords is a list and enable gradient tracking\\\\\\\",\\\\\\\"lineNumber\\\\\\\":252},{\\\\\\\"text\\\\\\\":\\\\\\\"    if isinstance(collocation_points, (list, tuple)):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":253},{\\\\\\\"text\\\\\\\":\\\\\\\"        coords = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":254},{\\\\\\\"text\\\\\\\":\\\\\\\"        for coord in collocation_points:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":255},{\\\\\\\"text\\\\\\\":\\\\\\\"            if not coord.requires_grad:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":256},{\\\\\\\"text\\\\\\\":\\\\\\\"                coord = coord.requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":257},{\\\\\\\"text\\\\\\\":\\\\\\\"            coords.append(coord)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":258},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":259},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Single tensor format: split into [x, y, (z), t] and enable gradients\\\\\\\",\\\\\\\"lineNumber\\\\\\\":260},{\\\\\\\"text\\\\\\\":\\\\\\\"        coords = []\\\\\\\",\\\\\\\"lineNumber\\\\\\\":261},{\\\\\\\"text\\\\\\\":\\\\\\\"        for i in range(collocation_points.shape[1]):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":262},{\\\\\\\"text\\\\\\\":\\\\\\\"            coord = collocation_points[:, i:i+1]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":263},{\\\\\\\"text\\\\\\\":\\\\\\\"            if not coord.requires_grad:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":264},{\\\\\\\"text\\\\\\\":\\\\\\\"                coord = coord.requires_grad_(True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":265},{\\\\\\\"text\\\\\\\":\\\\\\\"            coords.append(coord)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":266},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":267},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Forward pass (network expects list format)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":268},{\\\\\\\"text\\\\\\\":\\\\\\\"    outputs = net(coords)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":269},{\\\\\\\"text\\\\\\\":\\\\\\\"    phi = outputs[:, _phi_slice_index(dimension):_phi_slice_index(dimension) + 1]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":270},{\\\\\\\"lineNumber\\\\\\\":271},{\\\\\\\"text\\\\\\\":\\\\\\\"    if not torch.isfinite(phi).all():\\\\\\\",\\\\\\\"lineNumber\\\\\\\":272},{\\\\\\\"text\\\\\\\":\\\\\\\"        safe = torch.tensor(0.0, device=phi.device, requires_grad=True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":273},{\\\\\\\"text\\\\\\\":\\\\\\\"        return safe\\\\\\\",\\\\\\\"lineNumber\\\\\\\":274},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":275},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Extract spatial coordinates\\\\\\\",\\\\\\\"lineNumber\\\\\\\":276},{\\\\\\\"text\\\\\\\":\\\\\\\"    x = coords[0]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":277},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":278},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Compute first derivative to detect blow-ups early\\\\\\\",\\\\\\\"lineNumber\\\\\\\":279},{\\\\\\\"text\\\\\\\":\\\\\\\"    phi_x = diff(phi, x, order=1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":280},{\\\\\\\"text\\\\\\\":\\\\\\\"    if torch.isinf(phi_x).any():\\\\\\\",\\\\\\\"lineNumber\\\\\\\":281},{\\\\\\\"text\\\\\\\":\\\\\\\"        safe = torch.tensor(1e10, device=phi.device, requires_grad=True)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":282},{\\\\\\\"text\\\\\\\":\\\\\\\"        return safe\\\\\\\",\\\\\\\"lineNumber\\\\\\\":283},{\\\\\\\"lineNumber\\\\\\\":284},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Check for NaN in phi before computing laplacian\\\\\\\",\\\\\\\"lineNumber\\\\\\\":285},{\\\\\\\"text\\\\\\\":\\\\\\\"    if\\\\\\\",\\\\\\\"lineNumber\\\\\\\":286}]},\\\\\\\"score\\\\\\\":0.257255494594574},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":282,\\\\\\\"column\\\\\\\":96},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":345}},\\\\\\\"contents\\\\\\\":\\\\\\\"# ==================== Utility Functions ====================\\\\\\\\n\\\\\\\\ndef input_taker(lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Parse and validate input parameters for simulation.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        lam: Wavelength\\\\\\\\n        rho_1: Amplitude of perturbation\\\\\\\\n        num_of_waves: Number of waves\\\\\\\\n        tmax: Maximum time\\\\\\\\n        N_0: Number of initial condition points\\\\\\\\n        N_b: Number of boundary points (legacy, not used with hard constraints)\\\\\\\\n        N_r: Number of collocation points\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        Tuple (lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r) with correct types\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    lam = float(lam)\\\\\\\\n    rho_1 = float(rho_1)\\\\\\\\n    num_of_waves = float(num_of_waves)  # Allow fractional values for flexible domain sizing\\\\\\\\n    tmax = float(tmax)\\\\\\\\n    N_0 = int(N_0)\\\\\\\\n    N_r = int(N_r)\\\\\\\\n    \\\\\\\\n    return lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r\\\\\\\\n\\\\\\\\n\\\\\\\\ndef req_consts_calc(lam, rho_1):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"# ==================== Utility Functions ====================\\\\\\\",\\\\\\\"lineNumber\\\\\\\":286},{\\\\\\\"lineNumber\\\\\\\":287},{\\\\\\\"text\\\\\\\":\\\\\\\"def input_taker(lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":288,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":289},{\\\\\\\"text\\\\\\\":\\\\\\\"    Parse and validate input parameters for simulation.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":290},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":291},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":292},{\\\\\\\"text\\\\\\\":\\\\\\\"        lam: Wavelength\\\\\\\",\\\\\\\"lineNumber\\\\\\\":293},{\\\\\\\"text\\\\\\\":\\\\\\\"        rho_1: Amplitude of perturbation\\\\\\\",\\\\\\\"lineNumber\\\\\\\":294},{\\\\\\\"text\\\\\\\":\\\\\\\"        num_of_waves: Number of waves\\\\\\\",\\\\\\\"lineNumber\\\\\\\":295},{\\\\\\\"text\\\\\\\":\\\\\\\"        tmax: Maximum time\\\\\\\",\\\\\\\"lineNumber\\\\\\\":296},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_0: Number of initial condition points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":297},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_b: Number of boundary points (legacy, not used with hard constraints)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":298},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_r: Number of collocation points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":299},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":300},{\\\\\\\"text\\\\\\\":\\\\\\\"    Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":301},{\\\\\\\"text\\\\\\\":\\\\\\\"        Tuple (lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r) with correct types\\\\\\\",\\\\\\\"lineNumber\\\\\\\":302},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":303},{\\\\\\\"text\\\\\\\":\\\\\\\"    lam = float(lam)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":304},{\\\\\\\"text\\\\\\\":\\\\\\\"    rho_1 = float(rho_1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":305},{\\\\\\\"text\\\\\\\":\\\\\\\"    num_of_waves = float(num_of_waves)  # Allow fractional values for flexible domain sizing\\\\\\\",\\\\\\\"lineNumber\\\\\\\":306},{\\\\\\\"text\\\\\\\":\\\\\\\"    tmax = float(tmax)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":307},{\\\\\\\"text\\\\\\\":\\\\\\\"    N_0 = int(N_0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":308},{\\\\\\\"text\\\\\\\":\\\\\\\"    N_r = int(N_r)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":309},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":310},{\\\\\\\"text\\\\\\\":\\\\\\\"    return lam, rho_1, num_of_waves, tmax, N_0, N_b, N_r\\\\\\\",\\\\\\\"lineNumber\\\\\\\":311,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":312},{\\\\\\\"lineNumber\\\\\\\":313},{\\\\\\\"text\\\\\\\":\\\\\\\"def req_consts_calc(lam, rho_1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":314,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":315}]},\\\\\\\"score\\\\\\\":0.25563839077949524},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\visualization\\\\\\\\\\\\\\\\Plotting.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1238,\\\\\\\"column\\\\\\\":14},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1466}},\\\\\\\"contents\\\\\\\":\\\\\\\"def compute_fd_data_cache(initial_params, time_points, N=200, nu=None,\\\\\\\\n                          use_velocity_ps=None, ps_index=None, vel_rms=None, random_seed=None):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Compute and cache FD solver data for all time points to avoid redundant solver calls.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        initial_params: (xmin, xmax, ymin, ymax, rho_1, alpha, lam, output_folder, tmax)\\\\\\\\n        time_points: List of time points to compute\\\\\\\\n        N: Grid resolution for LAX solver\\\\\\\\n        nu: Courant number for LAX solver\\\\\\\\n        use_velocity_ps: Whether to use velocity power spectrum (defaults to config)\\\\\\\\n        ps_index: Power spectrum index (defaults to POWER_EXPONENT)\\\\\\\\n        vel_rms: Velocity RMS amplitude (defaults to a*cs)\\\\\\\\n        random_seed: Random seed (defaults to RANDOM_SEED)\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        Dictionary mapping time -&gt; FD data: {time: {'x': x_fd, 'y': y_fd, 'z': z_fd (if 3D),\\\\\\\\n                                                    'rho': rho_fd, 'vx': vx_fd, 'vy': vy_fd, 'phi': phi_fd}}\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    xmin, xmax, ymin, ymax, rho_1, _alpha, lam, _output_folder, _tmax = initial_params\\\\\\\\n    \\\\\\\\n    # Use config defaults if not specified\\\\\\\\n    if nu is None:\\\\\\\\n        nu = _get_fd_nu()\\\\\\\\n    if use_velocity_ps is None:\\\\\\\\n        use_velocity_ps = (str(PERTURBATION_TYPE).lower() == \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\")\\\\\\\\n    if ps_index is None:\\\\\\\\n        ps_index = POWER_EXPONENT\\\\\\\\n    if vel_rms is None:\\\\\\\\n        vel_rms = a * cs\\\\\\\\n    if random_seed is None:\\\\\\\\n        random_seed = RANDOM_SEED\\\\\\\\n    \\\\\\\\n    num_of_waves = (xmax - xmin) / lam\\\\\\\\n    \\\\\\\\n    # Decide grid resolution policy\\\\\\\\n    if str(PERTURBATION_TYPE).lower() == \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\":\\\\\\\\n        N_use = N_GRID\\\\\\\\n    else:\\\\\\\\n        N_use = FD_N_2D if N is None else N\\\\\\\\n    \\\\\\\\n    # Convert time_points to numpy array and sort\\\\\\\\n    time_points = np.array(time_points)\\\\\\\\n    time_points = np.sort(np.unique(time_points))\\\\\\\\n    max_time = float(np.max(time_points))\\\\\\\\n    \\\\\\\\n    print(f\\\\\\\\\\\\\\\"Computing FD data cache for {len(time_points)} time points (optimized: single run to t={max_time:.2f})...\\\\\\\\\\\\\\\")\\\\\\\\n    fd_cache = {}\\\\\\\\n    \\\\\\\\n    # OPTIMIZED: Run solver once to max_time with snapshots at all time points\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"def compute_fd_data_cache(initial_params, time_points, N=200, nu=None,\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1242,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"                          use_velocity_ps=None, ps_index=None, vel_rms=None, random_seed=None):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1243,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1244},{\\\\\\\"text\\\\\\\":\\\\\\\"    Compute and cache FD solver data for all time points to avoid redundant solver calls.\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1245},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1246},{\\\\\\\"text\\\\\\\":\\\\\\\"    Args:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1247},{\\\\\\\"text\\\\\\\":\\\\\\\"        initial_params: (xmin, xmax, ymin, ymax, rho_1, alpha, lam, output_folder, tmax)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1248},{\\\\\\\"text\\\\\\\":\\\\\\\"        time_points: List of time points to compute\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1249},{\\\\\\\"text\\\\\\\":\\\\\\\"        N: Grid resolution for LAX solver\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1250},{\\\\\\\"text\\\\\\\":\\\\\\\"        nu: Courant number for LAX solver\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1251},{\\\\\\\"text\\\\\\\":\\\\\\\"        use_velocity_ps: Whether to use velocity power spectrum (defaults to config)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1252},{\\\\\\\"text\\\\\\\":\\\\\\\"        ps_index: Power spectrum index (defaults to POWER_EXPONENT)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1253},{\\\\\\\"text\\\\\\\":\\\\\\\"        vel_rms: Velocity RMS amplitude (defaults to a*cs)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1254},{\\\\\\\"text\\\\\\\":\\\\\\\"        random_seed: Random seed (defaults to RANDOM_SEED)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1255},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1256},{\\\\\\\"text\\\\\\\":\\\\\\\"    Returns:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1257},{\\\\\\\"text\\\\\\\":\\\\\\\"        Dictionary mapping time -&gt; FD data: {time: {'x': x_fd, 'y': y_fd, 'z': z_fd (if 3D),\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1258},{\\\\\\\"text\\\\\\\":\\\\\\\"                                                    'rho': rho_fd, 'vx': vx_fd, 'vy': vy_fd, 'phi': phi_fd}}\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1259},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1260},{\\\\\\\"text\\\\\\\":\\\\\\\"    xmin, xmax, ymin, ymax, rho_1, _alpha, lam, _output_folder, _tmax = initial_params\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1261},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1262},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Use config defaults if not specified\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1263},{\\\\\\\"text\\\\\\\":\\\\\\\"    if nu is None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1264},{\\\\\\\"text\\\\\\\":\\\\\\\"        nu = _get_fd_nu()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1265},{\\\\\\\"text\\\\\\\":\\\\\\\"    if use_velocity_ps is None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1266},{\\\\\\\"text\\\\\\\":\\\\\\\"        use_velocity_ps = (str(PERTURBATION_TYPE).lower() == \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1267},{\\\\\\\"text\\\\\\\":\\\\\\\"    if ps_index is None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1268},{\\\\\\\"text\\\\\\\":\\\\\\\"        ps_index = POWER_EXPONENT\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1269},{\\\\\\\"text\\\\\\\":\\\\\\\"    if vel_rms is None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1270},{\\\\\\\"text\\\\\\\":\\\\\\\"        vel_rms = a * cs\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1271},{\\\\\\\"text\\\\\\\":\\\\\\\"    if random_seed is None:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1272},{\\\\\\\"text\\\\\\\":\\\\\\\"        random_seed = RANDOM_SEED\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1273},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1274},{\\\\\\\"text\\\\\\\":\\\\\\\"    num_of_waves = (xmax - xmin) / lam\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1275},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1276},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Decide grid resolution policy\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1277},{\\\\\\\"text\\\\\\\":\\\\\\\"    if str(PERTURBATION_TYPE).lower() == \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\":\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1278},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_use = N_GRID\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1279},{\\\\\\\"text\\\\\\\":\\\\\\\"    else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1280},{\\\\\\\"text\\\\\\\":\\\\\\\"        N_use = FD_N_2D if N is None else N\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1281},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1282},{\\\\\\\"text\\\\\\\":\\\\\\\"    # Convert time_points to numpy array and sort\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1283},{\\\\\\\"text\\\\\\\":\\\\\\\"    time_points = np.array(time_points)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1284},{\\\\\\\"text\\\\\\\":\\\\\\\"    time_points = np.sort(np.unique(time_points))\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1285},{\\\\\\\"text\\\\\\\":\\\\\\\"    max_time = float(np.max(time_points))\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1286},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1287},{\\\\\\\"text\\\\\\\":\\\\\\\"    print(f\\\\\\\\\\\\\\\"Computing FD data cache for {len(time_points)} time points (optimized: single run to t={max_time:.2f})...\\\\\\\\\\\\\\\")\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1288},{\\\\\\\"text\\\\\\\":\\\\\\\"    fd_cache = {}\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1289},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1290},{\\\\\\\"text\\\\\\\":\\\\\\\"    # OPTIMIZED: Run solver once to max_time with snapshots at all time points\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1291}]},\\\\\\\"score\\\\\\\":0.25446856021881104},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\losses.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":37}},\\\\\\\"contents\\\\\\\":\\\\\\\"from core.data_generator import col_gen\\\\\\\\nfrom core.data_generator import diff\\\\\\\\n\\\\\\\\nimport numpy as np\\\\\\\\n\\\\\\\\nimport torch\\\\\\\\nimport torch.nn as nn\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\nfrom config import cs, const, G, rho_o\\\\\\\\n\\\\\\\\nclass ASTPN(col_gen):\\\\\\\\n    \\\\\\\\n    def __init__(self, rmin=[0,0,0,0], rmax=[1,1,1,1], N_0 = 1000, N_b=1000, N_r=3000, dimension=1):\\\\\\\\n        super().__init__(rmin,rmax, N_0,0,N_r, dimension)  # N_b set to 0 due to hard constraints\\\\\\\\n        \\\\\\\\n       \\\\\\\\n        self.coord_Lx, self.coord_Rx = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=1)\\\\\\\\n        \\\\\\\\n        if dimension == 2:\\\\\\\\n            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\\n\\\\\\\\n        if dimension == 3:\\\\\\\\n            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\\n            self.coord_Lz, self.coord_Rz = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=3)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef pde_residue(colloc, net, dimension = 1):\\\\\\\\n    \\\\\\\\n    '''\\\\\\\",\\\\\\\"signatures\\\\\\\":{},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"from core.data_generator import col_gen\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1},{\\\\\\\"text\\\\\\\":\\\\\\\"from core.data_generator import diff\\\\\\\",\\\\\\\"lineNumber\\\\\\\":2},{\\\\\\\"lineNumber\\\\\\\":3},{\\\\\\\"text\\\\\\\":\\\\\\\"import numpy as np\\\\\\\",\\\\\\\"lineNumber\\\\\\\":4},{\\\\\\\"lineNumber\\\\\\\":5},{\\\\\\\"text\\\\\\\":\\\\\\\"import torch\\\\\\\",\\\\\\\"lineNumber\\\\\\\":6},{\\\\\\\"text\\\\\\\":\\\\\\\"import torch.nn as nn\\\\\\\",\\\\\\\"lineNumber\\\\\\\":7},{\\\\\\\"text\\\\\\\":\\\\\\\"from torch.autograd import Variable\\\\\\\",\\\\\\\"lineNumber\\\\\\\":8},{\\\\\\\"text\\\\\\\":\\\\\\\"from config import cs, const, G, rho_o\\\\\\\",\\\\\\\"lineNumber\\\\\\\":9},{\\\\\\\"lineNumber\\\\\\\":10},{\\\\\\\"text\\\\\\\":\\\\\\\"class ASTPN(col_gen):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":11,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":12},{\\\\\\\"text\\\\\\\":\\\\\\\"    def __init__(self, rmin=[0,0,0,0], rmax=[1,1,1,1], N_0 = 1000, N_b=1000, N_r=3000, dimension=1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":13},{\\\\\\\"text\\\\\\\":\\\\\\\"        super().__init__(rmin,rmax, N_0,0,N_r, dimension)  # N_b set to 0 due to hard constraints\\\\\\\",\\\\\\\"lineNumber\\\\\\\":14},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":15},{\\\\\\\"text\\\\\\\":\\\\\\\"       \\\\\\\",\\\\\\\"lineNumber\\\\\\\":16},{\\\\\\\"text\\\\\\\":\\\\\\\"        self.coord_Lx, self.coord_Rx = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=1)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":17},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":18},{\\\\\\\"text\\\\\\\":\\\\\\\"        if dimension == 2:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":19},{\\\\\\\"text\\\\\\\":\\\\\\\"            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":20},{\\\\\\\"lineNumber\\\\\\\":21},{\\\\\\\"text\\\\\\\":\\\\\\\"        if dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":22},{\\\\\\\"text\\\\\\\":\\\\\\\"            self.coord_Ly, self.coord_Ry = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=2)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":23},{\\\\\\\"text\\\\\\\":\\\\\\\"            self.coord_Lz, self.coord_Rz = self.geo_time_coord(option=\\\\\\\\\\\\\\\"BC\\\\\\\\\\\\\\\",coordinate=3)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":24,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"lineNumber\\\\\\\":25},{\\\\\\\"lineNumber\\\\\\\":26},{\\\\\\\"text\\\\\\\":\\\\\\\"def pde_residue(colloc, net, dimension = 1):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":27,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"    \\\\\\\",\\\\\\\"lineNumber\\\\\\\":28},{\\\\\\\"text\\\\\\\":\\\\\\\"    '''\\\\\\\",\\\\\\\"lineNumber\\\\\\\":29}]},\\\\\\\"score\\\\\\\":0.25028765201568604},{\\\\\\\"codeBlock\\\\\\\":{\\\\\\\"relativeWorkspacePath\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\training\\\\\\\\\\\\\\\\training_diagnostics.py\\\\\\\",\\\\\\\"range\\\\\\\":{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":7},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":2113}},\\\\\\\"contents\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\\ndef compute_ic_spatial_comparison(self, model, true_ic_data, n_grid=80):\\\\\\\\n\\\\\\\\n        \\\\\\\\n        x = torch.linspace(xmin, xmax, n_grid, device=device)\\\\\\\\n        y = torch.linspace(ymin, ymax, n_grid, device=device)\\\\\\\\n        X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\\n        T = torch.zeros_like(X)\\\\\\\\n        \\\\\\\\n        if self.dimension == 3:\\\\\\\\n            # For 3D, take z=middle slice\\\\\\\\n            Z = torch.full_like(X, (zmin + zmax) / 2.0)\\\\\\\\n            colloc_viz = [X.reshape(-1, 1), Y.reshape(-1, 1), Z.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\\n        else:\\\\\\\\n            # For 2D\\\\\\\\n            colloc_viz = [X.reshape(-1, 1), Y.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\\n        \\\\\\\\n        # Get predictions on visualization grid\\\\\\\\n        with torch.no_grad():\\\\\\\\n            pred_viz = model(colloc_viz)\\\\\\\\n            rho_pred_viz = pred_viz[:, 0].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\\n            vx_pred_viz = pred_viz[:, 1].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\\n            vy_pred_viz = pred_viz[:, 2].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\\n            if self.dimension == 3:\\\\\\\\n                vz_pred_viz = pred_viz[:, 3].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\\n                phi_pred_viz = pred_viz[:, 4].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\\n            else:\\\\\\\\n                phi_pred_viz = pred_viz[:, 3].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\\n        \\\\\\\\n        # For \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\" visualization, we need to interpolate from IC points to regular grid\\\\\\\\n        # Extract spatial coordinates from IC collocation points (detach first)\\\\\\\\n        x_ic = colloc_IC[0].detach().cpu().numpy().flatten()\\\\\\\\n        y_ic = colloc_IC[1].detach().cpu().numpy().flatten()\\\\\\\\n        \\\\\\\\n        if self.dimension == 3:\\\\\\\\n            z_ic = colloc_IC[2].detach().cpu().numpy().flatten()\\\\\\\\n            # Find points near z=middle for visualization\\\\\\\\n            zmid = (zmin + zmax) / 2.0\\\\\\\\n            z_tolerance = 0.1 * (zmax - zmin)  # 10% of domain\\\\\\\\n            mask_z = np.abs(z_ic - zmid) &lt; z_tolerance\\\\\\\\n        else:\\\\\\\\n            mask_z = np.ones(len(x_ic), dtype=bool)\\\\\\\\n        \\\\\\\\n        if mask_z.sum() &gt; 100:  # Need enough points for interpolation\\\\\\\\n            from scipy.interpolate import griddata\\\\\\\",\\\\\\\"signatures\\\\\\\":{\\\\\\\"ranges\\\\\\\":[{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":8,\\\\\\\"column\\\\\\\":1},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":9,\\\\\\\"column\\\\\\\":5}},{\\\\\\\"startPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1395,\\\\\\\"column\\\\\\\":5},\\\\\\\"endPosition\\\\\\\":{\\\\\\\"line\\\\\\\":1396,\\\\\\\"column\\\\\\\":9}}]},\\\\\\\"detailedLines\\\\\\\":[{\\\\\\\"text\\\\\\\":\\\\\\\"class TrainingDiagnostics:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":8,\\\\\\\"isSignature\\\\\\\":true},{\\\\\\\"text\\\\\\\":\\\\\\\"def compute_ic_spatial_comparison(self, model, true_ic_data, n_grid=80):\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1395},{\\\\\\\"lineNumber\\\\\\\":1438},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1439},{\\\\\\\"text\\\\\\\":\\\\\\\"        x = torch.linspace(xmin, xmax, n_grid, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1440},{\\\\\\\"text\\\\\\\":\\\\\\\"        y = torch.linspace(ymin, ymax, n_grid, device=device)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1441},{\\\\\\\"text\\\\\\\":\\\\\\\"        X, Y = torch.meshgrid(x, y, indexing='ij')\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1442},{\\\\\\\"text\\\\\\\":\\\\\\\"        T = torch.zeros_like(X)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1443},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1444},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1445},{\\\\\\\"text\\\\\\\":\\\\\\\"            # For 3D, take z=middle slice\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1446},{\\\\\\\"text\\\\\\\":\\\\\\\"            Z = torch.full_like(X, (zmin + zmax) / 2.0)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1447},{\\\\\\\"text\\\\\\\":\\\\\\\"            colloc_viz = [X.reshape(-1, 1), Y.reshape(-1, 1), Z.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1448},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1449},{\\\\\\\"text\\\\\\\":\\\\\\\"            # For 2D\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1450},{\\\\\\\"text\\\\\\\":\\\\\\\"            colloc_viz = [X.reshape(-1, 1), Y.reshape(-1, 1), T.reshape(-1, 1)]\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1451},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1452},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Get predictions on visualization grid\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1453},{\\\\\\\"text\\\\\\\":\\\\\\\"        with torch.no_grad():\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1454},{\\\\\\\"text\\\\\\\":\\\\\\\"            pred_viz = model(colloc_viz)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1455},{\\\\\\\"text\\\\\\\":\\\\\\\"            rho_pred_viz = pred_viz[:, 0].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1456},{\\\\\\\"text\\\\\\\":\\\\\\\"            vx_pred_viz = pred_viz[:, 1].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1457},{\\\\\\\"text\\\\\\\":\\\\\\\"            vy_pred_viz = pred_viz[:, 2].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1458},{\\\\\\\"text\\\\\\\":\\\\\\\"            if self.dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1459},{\\\\\\\"text\\\\\\\":\\\\\\\"                vz_pred_viz = pred_viz[:, 3].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1460},{\\\\\\\"text\\\\\\\":\\\\\\\"                phi_pred_viz = pred_viz[:, 4].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1461},{\\\\\\\"text\\\\\\\":\\\\\\\"            else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1462},{\\\\\\\"text\\\\\\\":\\\\\\\"                phi_pred_viz = pred_viz[:, 3].reshape(n_grid, n_grid).cpu().numpy()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1463},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1464},{\\\\\\\"text\\\\\\\":\\\\\\\"        # For \\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\" visualization, we need to interpolate from IC points to regular grid\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1465},{\\\\\\\"text\\\\\\\":\\\\\\\"        # Extract spatial coordinates from IC collocation points (detach first)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1466},{\\\\\\\"text\\\\\\\":\\\\\\\"        x_ic = colloc_IC[0].detach().cpu().numpy().flatten()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1467},{\\\\\\\"text\\\\\\\":\\\\\\\"        y_ic = colloc_IC[1].detach().cpu().numpy().flatten()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1468},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1469},{\\\\\\\"text\\\\\\\":\\\\\\\"        if self.dimension == 3:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1470},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_ic = colloc_IC[2].detach().cpu().numpy().flatten()\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1471},{\\\\\\\"text\\\\\\\":\\\\\\\"            # Find points near z=middle for visualization\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1472},{\\\\\\\"text\\\\\\\":\\\\\\\"            zmid = (zmin + zmax) / 2.0\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1473},{\\\\\\\"text\\\\\\\":\\\\\\\"            z_tolerance = 0.1 * (zmax - zmin)  # 10% of domain\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1474},{\\\\\\\"text\\\\\\\":\\\\\\\"            mask_z = np.abs(z_ic - zmid) &lt; z_tolerance\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1475},{\\\\\\\"text\\\\\\\":\\\\\\\"        else:\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1476},{\\\\\\\"text\\\\\\\":\\\\\\\"            mask_z = np.ones(len(x_ic), dtype=bool)\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1477},{\\\\\\\"text\\\\\\\":\\\\\\\"        \\\\\\\",\\\\\\\"lineNumber\\\\\\\":1478},{\\\\\\\"text\\\\\\\":\\\\\\\"        if mask_z.sum() &gt; 100:  # Need enough points for interpolation\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1479},{\\\\\\\"text\\\\\\\":\\\\\\\"            from scipy.interpolate import griddata\\\\\\\",\\\\\\\"lineNumber\\\\\\\":1480}]},\\\\\\\"score\\\\\\\":0.2490265965461731}]}\\\"},\\\"capabilityType\\\":15}\",\"65b67be5-286a-42c7-95a4-f2a67c820e15\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"b7c8892c-4a9f-469d-b5ec-cc0fc52314d8\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.722Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_c4d29ccd-fe72-4520-93ef-d8970dacffd\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_c4d29ccd-fe72-4520-93ef-d8970dacffd\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"offset\\\\\\\":349,\\\\\\\"limit\\\\\\\":30}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"offset\\\\\\\":349,\\\\\\\"limit\\\\\\\":30,\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"def distribute_collocation_points(n_total, num_subdomains):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Distribute collocation points across subdomains for XPINN.\\\\\\\\n    \\\\\\\\n    Args:\\\\\\\\n        n_total: Total number of collocation points\\\\\\\\n        num_subdomains: Number of subdomains\\\\\\\\n    \\\\\\\\n    Returns:\\\\\\\\n        List of point counts per subdomain\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    # If per-subdomain count is specified, use it\\\\\\\\n    if n_total == N_r_PER_SUBDOMAIN and N_r_PER_SUBDOMAIN is not None:\\\\\\\\n        return [N_r_PER_SUBDOMAIN] * num_subdomains\\\\\\\\n    elif n_total == N_0_PER_SUBDOMAIN and N_0_PER_SUBDOMAIN is not None:\\\\\\\\n        return [N_0_PER_SUBDOMAIN] * num_subdomains\\\\\\\\n    \\\\\\\\n    # Otherwise, auto-distribute evenly\\\\\\\\n    base_count = n_total // num_subdomains\\\\\\\\n    remainder = n_total % num_subdomains\\\\\\\\n    \\\\\\\\n    counts = [base_count] * num_subdomains\\\\\\\\n    # Distribute remainder to first few subdomains\\\\\\\\n    for i in range(remainder):\\\\\\\\n        counts[i] += 1\\\\\\\\n    \\\\\\\\n    return counts\\\\\\\\n\\\\\\\\n\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":422}\\\"},\\\"capabilityType\\\":15}\",\"0544c272-6681-4ef1-8edd-277edfc1dae0\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"95f6084b-2f0e-462e-b6fd-7eab6d888919\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.722Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nChecking config.py for XPINN-related variables and verifying the import reference:\\\\n\\\"}\",\"09222754-1d9f-4972-a043-5a9bee286359\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"09ce1f70-0a76-4cab-807d-c04789f22312\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.722Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_36367122-0804-4ca1-a7ca-cc11764b44c\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_36367122-0804-4ca1-a7ca-cc11764b44c\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"N_r_PER_SUBDOMAIN|N_0_PER_SUBDOMAIN|PER_SUBDOMAIN\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":false,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_36367122-0804-4ca1-a7ca-cc11764b44c\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"N_r_PER_SUBDOMAIN|N_0_PER_SUBDOMAIN|PER_SUBDOMAIN\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":false}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"N_r_PER_SUBDOMAIN|N_0_PER_SUBDOMAIN|PER_SUBDOMAIN\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":521,\\\\\\\"content\\\\\\\":\\\\\\\"- N_r_PER_SUBDOMAIN = None  # Residual points per subdomain (None = auto-distribute N_r)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":522,\\\\\\\"content\\\\\\\":\\\\\\\"- N_0_PER_SUBDOMAIN = None  # IC points per subdomain (None = auto-distribute N_0)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2808,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import N_r_PER_SUBDOMAIN, N_0_PER_SUBDOMAIN\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2870,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_r_PER_SUBDOMAIN&amp;#96;: Residual points per subdomain (None = auto-distribute)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2871,\\\\\\\"content\\\\\\\":\\\\\\\"- - &amp;#96;N_0_PER_SUBDOMAIN&amp;#96;: IC points per subdomain (None = auto-distribute)\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3019,\\\\\\\"content\\\\\\\":\\\\\\\"   - Removed imports of &#96;N_r_PER_SUBDOMAIN&#96;, &#96;N_0_PER_SUBDOMAIN&#96;\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":362,\\\\\\\"content\\\\\\\":\\\\\\\"    if n_total == N_r_PER_SUBDOMAIN and N_r_PER_SUBDOMAIN is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":363,\\\\\\\"content\\\\\\\":\\\\\\\"        return [N_r_PER_SUBDOMAIN] * num_subdomains\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":364,\\\\\\\"content\\\\\\\":\\\\\\\"    elif n_total == N_0_PER_SUBDOMAIN and N_0_PER_SUBDOMAIN is not None:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":365,\\\\\\\"content\\\\\\\":\\\\\\\"        return [N_0_PER_SUBDOMAIN] * num_subdomains\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":11,\\\\\\\"totalMatchedLines\\\\\\\":11}}}}}\\\"},\\\"capabilityType\\\":15}\",\"054589bf-2781-41b5-9c2a-62747af75e55\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"59d6c3b5-31e3-4fb1-8283-7c7f9972db62\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.722Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_00039fb6-becf-4324-9d40-d25ad1b0569\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_00039fb6-becf-4324-9d40-d25ad1b0569\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\config.py\\\\\\\"}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\config.py\\\\\\\",\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\config.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"import numpy as np\\\\\\\\n\\\\\\\\n# Random seed for reproducibility across all functions\\\\\\\\nRANDOM_SEED = 78\\\\\\\\n\\\\\\\\n# Perturbation selection: \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"sinusoidal\\\\\\\\\\\\\\\"\\\\\\\\nPERTURBATION_TYPE = \\\\\\\\\\\\\\\"power_spectrum\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nxmin = 0.0\\\\\\\\nymin = 0.0\\\\\\\\nzmin = 0.0\\\\\\\\ncs = 1.0\\\\\\\\nrho_o = 1.0\\\\\\\\nconst = 1.0\\\\\\\\nG = 1.0\\\\\\\\n\\\\\\\\n# Collocation point parameters\\\\\\\\nN_0 = 25000  # Number of initial condition points\\\\\\\\nN_r = 50000 # Number of residual/collocation points\\\\\\\\nDIMENSION = 2  # Spatial dimension\\\\\\\\n\\\\\\\\nBATCH_SIZE = 75000  # Max collocation points per mini-batch (controls peak GPU memory)\\\\\\\\nNUM_BATCHES = 1  # Mini-batches per optimizer step; gradients accumulate, memory stays constant\\\\\\\\n\\\\\\\\na = 0.1\\\\\\\\n\\\\\\\\ntmin = 0.\\\\\\\\ntmax = 3.0\\\\\\\\n\\\\\\\\nnum_neurons = 64\\\\\\\\nharmonics = 3\\\\\\\\nnum_layers = 5\\\\\\\\nDEFAULT_ACTIVATION = 'sin'  # Default activation function for PINN ('sin', 'tanh', 'relu', etc.)\\\\\\\\n\\\\\\\\nwave = 7.0\\\\\\\\nk = 2 * np.pi / wave\\\\\\\\nnum_of_waves = 2.0\\\\\\\\n\\\\\\\\niteration_adam_2D = 1001\\\\\\\\niteration_lbgfs_2D = 201\\\\\\\\n\\\\\\\\nIC_WEIGHT = 1.0\\\\\\\\n\\\\\\\\n# Extra collocation points at t=0 to strongly enforce Poisson equation\\\\\\\\nN_POISSON_IC = 0  # Number of extra spatial points at t=0 for Poisson\\\\\\\\nPOISSON_IC_WEIGHT = 0.0  # Weight for Poisson residual at t=0\\\\\\\\nPHI_MEAN_CONSTRAINT_WEIGHT = 0.0  # Weight for mean(Ï†)=0 constraint at t=0 (fixes gauge freedom)\\\\\\\\n\\\\\\\\n# Output/snapshot controls\\\\\\\\nSAVE_STATIC_SNAPSHOTS = False\\\\\\\\n\\\\\\\\n# Directory to save snapshots; default keeps Kaggle working dir\\\\\\\\nSNAPSHOT_DIR = \\\\\\\\\\\\\\\"/kaggle/working/\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Training diagnostics\\\\\\\\nENABLE_TRAINING_DIAGNOSTICS = True  # Enable automatic training diagnostics plots and logging\\\\\\\\n\\\\\\\\n# Density growth comparison plot controls\\\\\\\\nPLOT_DENSITY_GROWTH = False\\\\\\\\nGROWTH_PLOT_TMAX = 4.0\\\\\\\\nGROWTH_PLOT_DT = 0.1\\\\\\\\n\\\\\\\\nKX = k\\\\\\\\nKY = 0\\\\\\\\nKZ = 0\\\\\\\\nTIMES_1D = [2.5, 3.0, 3.5] # 1D cross-section times to plot (used for sinusoidal panel plots\\\\\\\\nFD_N_1D = 300  # Grid points for 1D LAX (when used)\\\\\\\\nFD_N_2D = 300  # Grid points per dimension for 2D LAX\\\\\\\\nFD_N_3D = 300  # Grid points per dimension for 3D LAX slices\\\\\\\\nFD_NU_SINUSOIDAL = 0.5  # Courant number for LAX solver\\\\\\\\nSLICE_Y = 0.6  # Default y slice for visualization/cross-sections\\\\\\\\nSLICE_Z = 0.6  # Default z slice for visualization/cross-sections\\\\\\\\nSHOW_LINEAR_THEORY = False\\\\\\\\n\\\\\\\\n# 3D Interactive plot settings\\\\\\\\nENABLE_INTERACTIVE_3D = True  # Toggle interactive 3D plot generation\\\\\\\\nINTERACTIVE_3D_RESOLUTION = 50  # Grid resolution per axis\\\\\\\\nINTERACTIVE_3D_TIME_STEPS = 10  # Number of time steps in slider\\\\\\\\n\\\\\\\\n# Power spectrum parameters\\\\\\\\nN_GRID = 400  # Grid resolution for power spectrum generation\\\\\\\\nN_GRID_3D = 400 #In 3D\\\\\\\\nFD_NU_POWER = 0.25  # Courant number for LAX solver\\\\\\\\nPOWER_EXPONENT = -4  # Power spectrum exponent\\\\\\\\nSTARTUP_DT = 0.01 # Time offset after which PDE is enforced (ICs remain at t=0)\\\\\\\\nUSE_PARAMETERIZATION = \\\\\\\\\\\\\\\"exponential\\\\\\\\\\\\\\\"  # Options: \\\\\\\\\\\\\\\"exponential\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"linear\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"none\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":86}\\\"},\\\"capabilityType\\\":15}\",\"2b5cccb0-3e8a-434b-bb8d-8270e3831f81\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"76049031-fe24-47b6-b2c0-9c1f750a54bc\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.722Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_57614056-4bca-4218-ba72-e0146bbe27b\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_57614056-4bca-4218-ba72-e0146bbe27b\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"from methods\\\\\\\\\\\\\\\\.xpinn|import.*xpinn\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_57614056-4bca-4218-ba72-e0146bbe27b\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"from methods\\\\\\\\\\\\\\\\.xpinn|import.*xpinn\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":true}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"from methods\\\\\\\\\\\\\\\\.xpinn|import.*xpinn\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-08_16-13Z-pinn-and-lax-solver-comparison.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":53,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_01Ge7Gp3bAyP6gPHvnm5Xage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2181a25a-ff2a-4ce1-a9d1-d46ecaab11f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c3b0e4e0-e73f-4892-8e4d-03cc82eb0ea8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"34bfe595-59cb-4523-bff5-3f4300330ed0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"33540af8-647a-4e47-82a4-9cdb1e12ed91\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a711058d-5b60-4bd9-aadb-bbcdf5a05997\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f2453eb5-db26-4a76-a33d-fd8c048e33e7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"80d06c8b-c1a8-43d0-a429-96e1a89e3d9b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ca1c992e-415f-4d0f-8865-aa6db3640726\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"9abf266b-2593-4837-8938-c423f6d17585\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"29295441-351f-480f-9a9b-386f8377b75b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"99fb6f39-d980-49ff-8f5c-57e29b5c79f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ebaedb63-e0c4-4546-a7f6-c32f773c06d6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a907e52a-dd [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2803,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4551,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":31077,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"composerData\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"composerId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"task-toolu_019aNmsGakgw5VbE2Soqf7P3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"richText\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hasLoaded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":true,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fullConversationHeadersOnly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b530dce-d1e9-4fc1-a61b-33f822115c6a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a89bb8c4-b830-4dca-a69b-74bdc6bbb79e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"49c90654-5f1c-487e-8e5d-01d0e7d99f87\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5b8e7ad8-4676-4a3a-bf19-c48fae4dbbb7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f6a38903-c908-4c54-b5a4-801a38b9c87a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"90a27c62-d770-447d-be4d-1cd0669127f8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"4ac40ee8-f125-44bc-bc87-3352c7db6894\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2},{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bubbleId\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"02473f18-b861-43a0-95c0-b4271492196e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2}],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conversationMap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a7dbcb45-3130-410d-8b22-b561c7c0ce49\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"approximateLintErrors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"lints\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"codebaseContextChunks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pullRequests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":[],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"atta [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-25_12-05Z-3d-power-spectrum-comparison-plot-verification.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":543,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":576,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":623,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":648,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":697,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":722,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1237,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1279,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1321,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1363,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1405,\\\\\\\"content\\\\\\\":\\\\\\\"    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n        gc. [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1430,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"contentsAfterEdit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"from scipy import signal\\\\\\\\\\\\\\\\nimport numpy as np\\\\\\\\\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\\\\\\\\\nimport matplotlib.animation as animation\\\\\\\\\\\\\\\\nfrom torch.autograd import Variable\\\\\\\\\\\\\\\\nimport torch\\\\\\\\\\\\\\\\nimport scipy\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution, lax_solution_3d_sinusoidal, lax_solver\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX import lax_solution1D_sinusoidal as lax_solution1D_sin\\\\\\\\\\\\\\\\nfrom numerical_solvers.LAX_torch import lax_solution_torch, lax_solution_3d_sinusoidal_torch, lax_solver_torch\\\\\\\\\\\\\\\\ndef _clear_cuda_cache():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Comprehensive GPU cache clearing before FD solver runs.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This function does more than just empty_cache() - it also:\\\\\\\\\\\\\\\\n    1. Forces garbage collection\\\\\\\\\\\\\\\\n    2. Synchronizes CUDA operations\\\\\\\\\\\\\\\\n    3. Clears the cache allocator\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    This helps prevent OOM errors when FD solver needs GPU memory.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if torch.cuda.is_available():\\\\\\\\\\\\\\\\n        import gc\\\\\\\\\\\\\\\\n        # Force garbage collection first to free Python objects\\\\\\\\\\\\\\\\n    [... omitted end of long line]\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-01-14_06-30Z-causal-training-and-xpinn-configuration-cleanup.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":254,\\\\\\\"content\\\\\\\":\\\\\\\"  \\\\\\\\\\\\\\\"plan\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Remove Causal Training and XPINN Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\nThis plan will systematically remove all causal training and XPINN domain decomposition features from the codebase, leaving only the standard single PINN training implementation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Delete Entirely\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **[methods/causal_training.py](methods/causal_training.py)** - Complete causal training module\\\\\\\\\\\\\\\\n2. **[methods/xpinn_decomposition.py](methods/xpinn_decomposition.py)** - Complete XPINN domain decomposition module\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Files to Modify\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. [config.py](config.py)\\\\\\\\\\\\\\\\nRemove configuration sections:\\\\\\\\\\\\\\\\n- Lines 82-111: All &amp;#96;CAUSAL_*&amp;#96; parameters (30 lines)\\\\\\\\\\\\\\\\n- Lines 113-143: All &amp;#96;XPINN_*&amp;#96;, &amp;#96;USE_XPINN&amp;#96;, &amp;#96;NUM_SUBDOMAINS_*&amp;#96;, &amp;#96;INTERFACE_*&amp;#96;, &amp;#96;SUBDOMAIN_CONFIGS&amp;#96;, etc. (31 lines)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. [train.py](train.py)\\\\\\\\\\\\\\\\nMajor simplification:\\\\\\\\\\\\\\\\n- Remove imports (lines 32-51): &amp;#96;USE_XPINN&amp;#96;, &amp;#96;USE_CAUSAL_TRAINING&amp;#96;, all causal/xpinn imports\\\\\\\\\\\\\\\\n- Remove entire XPINN mode block [... omitted end of long line]\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":586,\\\\\\\"content\\\\\\\":\\\\\\\"- from training.trainer import train, train_xpinn\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":592,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, DEFAULT_ACTIVATION, RANDOM_SEED\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":593,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import N_INTERFACE, XPINN_OPTIMIZER_STRATEGY, USE_MULTI_GPU, CACHE_IC_VALUES, STARTUP_DT\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":601,\\\\\\\"content\\\\\\\":\\\\\\\"- from core.losses import ASTPN, XPINN_Loss\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":615,\\\\\\\"content\\\\\\\":\\\\\\\"- import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":616,\\\\\\\"content\\\\\\\":\\\\\\\"- from methods.xpinn_decomposition import (setup_xpinn_devices, setup_xpinn_networks,\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1373,\\\\\\\"content\\\\\\\":\\\\\\\"-     from training.physics import closure_xpinn, closure_xpinn_batched, _random_batch_indices, _make_batch_tensors\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1380,\\\\\\\"content\\\\\\\":\\\\\\\"-     from config import XPINN_ALTERNATING_TRAINING, USE_XPINN_BATCHING\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":1749,\\\\\\\"content\\\\\\\":\\\\\\\"Now let me remove the causal import and update closure_batched signature, then remove the xpinn closures:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2557,\\\\\\\"content\\\\\\\":\\\\\\\"| &#96;visualization/Plotting.py&#96; | &#96;from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY&#96; | L168 |\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2605,\\\\\\\"content\\\\\\\":\\\\\\\"- from config import USE_XPINN, NUM_SUBDOMAINS_X, NUM_SUBDOMAINS_Y, SHOW_INTERFACE_LINES, INTERFACE_AVERAGING, RANDOM_SEED, SHOW_LINEAR_THEORY\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2653,\\\\\\\"content\\\\\\\":\\\\\\\"-     import methods.xpinn_decomposition as xpinn_utils\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3048,\\\\\\\"content\\\\\\\":\\\\\\\"The error shows that &#96;DEFAULT_ACTIVATION&#96; is being imported in &#96;core/model_architecture.py&#96; but it no longer exists in &#96;config.py&#96; because I removed it as part of the XPINN cleanup. I need to check what this parameter was used for and either:\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":3056,\\\\\\\"content\\\\\\\":\\\\\\\"I see the issue! The &#96;DEFAULT_ACTIVATION&#96; parameter was removed from &#96;config.py&#96; but it's still being imported in &#96;core/model_architecture.py&#96;. This parameter is actually needed for the standard PINN architecture, not just XPINN. Let me fix this by adding it back to config.py:\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":274,\\\\\\\"content\\\\\\\":\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":32,\\\\\\\"totalMatchedLines\\\\\\\":32}}}}}\\\"},\\\"capabilityType\\\":15}\",\"9b87580c-a74a-43a6-9d69-2c04fb17b589\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"dc4f83d8-99ff-4586-8766-461123224d21\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.722Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\nChecking if the import in &#96;data_generator.py&#96; would cause an error:\\\\n\\\"}\",\"e4d1c351-618f-42a5-81bd-e0b2091bbef7\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"956baa68-4d3d-44d8-8ebd-781355b549c3\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.723Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_38d48b68-cbe3-4e19-ab89-2c582f46f8c\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_38d48b68-cbe3-4e19-ab89-2c582f46f8c\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"read_file_v2\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"path\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"offset\\\\\\\":260,\\\\\\\"limit\\\\\\\":25}\\\",\\\"tool\\\":40,\\\"params\\\":\\\"{\\\\\\\"targetFile\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"offset\\\\\\\":260,\\\\\\\"limit\\\\\\\":25,\\\\\\\"charsLimit\\\\\\\":1000000,\\\\\\\"effectiveUri\\\\\\\":\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\"}\\\",\\\"result\\\":\\\"{\\\\\\\"contents\\\\\\\":\\\\\\\"    \\\\\\\\n    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Determine which boundaries of a subdomain are exterior boundaries.\\\\\\\\n        Uses xpinn_decomposition utilities.\\\\\\\\n        \\\\\\\\n        Args:\\\\\\\\n            subdomain_idx: Linear subdomain index\\\\\\\\n            nx_sub: Number of subdomain splits in x-direction\\\\\\\\n            ny_sub: Number of subdomain splits in y-direction\\\\\\\\n        \\\\\\\\n        Returns:\\\\\\\\n            Dict with keys 'left', 'right', 'bottom', 'top' indicating if boundary is exterior\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\n        \\\\\\\\n        # Extract global domain bounds from self.rmin, self.rmax\\\\\\\\n        if self.dimension == 2:\\\\\\\\n            xmin, ymin = self.rmin[0], self.rmin[1]\\\\\\\\n            xmax, ymax = self.rmax[0], self.rmax[1]\\\\\\\\n        else:\\\\\\\\n            raise NotImplementedError(f\\\\\\\\\\\\\\\"Exterior boundary info not yet implemented for dimension {self.dimension}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\n\\\\\\\",\\\\\\\"totalLinesInFile\\\\\\\":422}\\\"},\\\"capabilityType\\\":15}\",\"999b18f0-0a37-4d90-8839-c27532c75930\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"81309620-7a37-4018-a008-23974b5b1346\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.723Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\",\\\"toolFormerData\\\":{\\\"toolCallId\\\":\\\"tool_4778e550-5ecc-4c28-8646-0eeb85b16d6\\\",\\\"toolIndex\\\":0,\\\"modelCallId\\\":\\\"tool_4778e550-5ecc-4c28-8646-0eeb85b16d6\\\",\\\"status\\\":\\\"completed\\\",\\\"name\\\":\\\"ripgrep_raw_search\\\",\\\"rawArgs\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"get_exterior_boundary_info\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":false,\\\\\\\"multiline\\\\\\\":false,\\\\\\\"toolCallId\\\\\\\":\\\\\\\"tool_4778e550-5ecc-4c28-8646-0eeb85b16d6\\\\\\\"}\\\",\\\"tool\\\":41,\\\"params\\\":\\\"{\\\\\\\"pattern\\\\\\\":\\\\\\\"get_exterior_boundary_info\\\\\\\",\\\\\\\"caseInsensitive\\\\\\\":false}\\\",\\\"result\\\":\\\"{\\\\\\\"success\\\\\\\":{\\\\\\\"pattern\\\\\\\":\\\\\\\"get_exterior_boundary_info\\\\\\\",\\\\\\\"outputMode\\\\\\\":\\\\\\\"content\\\\\\\",\\\\\\\"workspaceResults\\\\\\\":{\\\\\\\"c:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\tirth\\\\\\\\\\\\\\\\Documents\\\\\\\\\\\\\\\\Projects\\\\\\\\\\\\\\\\GRINN\\\\\\\\\\\\\\\\Power spectrum perturbations\\\\\\\":{\\\\\\\"content\\\\\\\":{\\\\\\\"matches\\\\\\\":[{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\.specstory\\\\\\\\\\\\\\\\history\\\\\\\\\\\\\\\\2026-02-07_10-59Z-mass-conservation-test-explanation.md\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":2633,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # This is handled by get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2760,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2803,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":2846,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4381,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # This is handled by get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4508,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4551,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":4594,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6304,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # This is handled by get_exterior_boundary_info\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":6759,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"                # This is handled by get_exterior_boundary_info\\\\\\\\\\\\\\\",\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":10818,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":18798,\\\\\\\"content\\\\\\\":\\\\\\\"                  \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\\\\\\\\\"\\\\\\\"}]},{\\\\\\\"file\\\\\\\":\\\\\\\".\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\data_generator.py\\\\\\\",\\\\\\\"matches\\\\\\\":[{\\\\\\\"lineNumber\\\\\\\":233,\\\\\\\"content\\\\\\\":\\\\\\\"                # This is handled by get_exterior_boundary_info\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":261,\\\\\\\"content\\\\\\\":\\\\\\\"    def get_exterior_boundary_info(self, subdomain_idx, nx_sub, ny_sub):\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":274,\\\\\\\"content\\\\\\\":\\\\\\\"        from methods.xpinn_decomposition import get_exterior_boundary_info\\\\\\\"},{\\\\\\\"lineNumber\\\\\\\":283,\\\\\\\"content\\\\\\\":\\\\\\\"        return get_exterior_boundary_info(subdomain_idx, nx_sub, ny_sub, xmin, xmax, ymin, ymax)\\\\\\\"}]}],\\\\\\\"totalLines\\\\\\\":16,\\\\\\\"totalMatchedLines\\\\\\\":16}}}}}\\\"},\\\"capabilityType\\\":15}\",\"69e0e98c-70be-4bd2-a0fd-bdbecac85779\":\"{\\\"_v\\\":3,\\\"type\\\":2,\\\"approximateLintErrors\\\":[],\\\"lints\\\":[],\\\"codebaseContextChunks\\\":[],\\\"commits\\\":[],\\\"pullRequests\\\":[],\\\"attachedCodeChunks\\\":[],\\\"assistantSuggestedDiffs\\\":[],\\\"gitDiffs\\\":[],\\\"interpreterResults\\\":[],\\\"images\\\":[],\\\"attachedFolders\\\":[],\\\"attachedFoldersNew\\\":[],\\\"bubbleId\\\":\\\"db9caa31-d4f8-4856-8799-cd409922d786\\\",\\\"userResponsesToSuggestedCodeBlocks\\\":[],\\\"suggestedCodeBlocks\\\":[],\\\"diffsForCompressingFiles\\\":[],\\\"relevantFiles\\\":[],\\\"toolResults\\\":[],\\\"notepads\\\":[],\\\"capabilities\\\":[],\\\"multiFileLinterErrors\\\":[],\\\"diffHistories\\\":[],\\\"recentLocationsHistory\\\":[],\\\"recentlyViewedFiles\\\":[],\\\"isAgentic\\\":false,\\\"fileDiffTrajectories\\\":[],\\\"existedSubsequentTerminalCommand\\\":false,\\\"existedPreviousTerminalCommand\\\":false,\\\"docsReferences\\\":[],\\\"webReferences\\\":[],\\\"aiWebSearchResults\\\":[],\\\"requestId\\\":\\\"\\\",\\\"attachedFoldersListDirResults\\\":[],\\\"humanChanges\\\":[],\\\"attachedHumanChanges\\\":false,\\\"summarizedComposers\\\":[],\\\"cursorRules\\\":[],\\\"contextPieces\\\":[],\\\"editTrailContexts\\\":[],\\\"allThinkingBlocks\\\":[],\\\"diffsSinceLastApply\\\":[],\\\"deletedFiles\\\":[],\\\"supportedTools\\\":[],\\\"tokenCount\\\":{\\\"inputTokens\\\":0,\\\"outputTokens\\\":0},\\\"attachedFileCodeChunksMetadataOnly\\\":[],\\\"consoleLogs\\\":[],\\\"uiElementPicked\\\":[],\\\"isRefunded\\\":false,\\\"knowledgeItems\\\":[],\\\"documentationSelections\\\":[],\\\"externalLinks\\\":[],\\\"projectLayouts\\\":[],\\\"unifiedMode\\\":2,\\\"capabilityContexts\\\":[],\\\"todos\\\":[],\\\"createdAt\\\":\\\"2026-02-08T19:19:08.723Z\\\",\\\"mcpDescriptors\\\":[],\\\"workspaceUris\\\":[],\\\"conversationState\\\":{\\\"rootPromptMessagesJson\\\":[],\\\"turnsOld\\\":[],\\\"todos\\\":[],\\\"pendingToolCalls\\\":[],\\\"turns\\\":[],\\\"previousWorkspaceUris\\\":[],\\\"fileStates\\\":{},\\\"summaryArchives\\\":[],\\\"turnTimings\\\":[],\\\"fileStatesV2\\\":{},\\\"subagentStates\\\":{},\\\"selfSummaryCount\\\":0,\\\"readPaths\\\":[]},\\\"text\\\":\\\"\\\\n## Detailed findings: XPINN scaffolding in codebase\\\\n\\\\n### 1. Methods directory structure\\\\n- &#96;methods/__init__.py&#96; exists but is empty (only a comment: \\\\\\\"# Enhancement methods for PINN training\\\\\\\")\\\\n- No &#96;methods/xpinn_decomposition.py&#96; file exists (removed in a previous cleanup)\\\\n\\\\n### 2. Existing XPINN-related code in &#96;core/data_generator.py&#96;\\\\n\\\\n#### Subdomain collocation point generation (Lines 194-259)\\\\n- &#96;geo_time_coord_subdomain()&#96; method in &#96;col_gen&#96; class:\\\\n  - Generates Domain, IC, and BC collocation points within subdomain bounds\\\\n  - Currently implemented for 2D only (&#96;dimension == 2&#96;)\\\\n  - Takes &#96;subdomain_bounds&#96; tuple &#96;(x_min, x_max, y_min, y_max)&#96;\\\\n  - BC generation includes a comment: \\\\\\\"Only generate BC if subdomain touches exterior boundary\\\\\\\"\\\\n\\\\n#### Exterior boundary detection (Lines 261-283)\\\\n- &#96;get_exterior_boundary_info()&#96; method:\\\\n  - Determines which boundaries are exterior vs interior\\\\n  - Currently broken: imports from &#96;methods.xpinn_decomposition&#96; which doesn't exist\\\\n  - Would raise &#96;ImportError&#96; if called\\\\n  - Returns dict with keys: &#96;'left'&#96;, &#96;'right'&#96;, &#96;'bottom'&#96;, &#96;'top'&#96;\\\\n\\\\n#### Collocation point distribution (Lines 349-376)\\\\n- &#96;distribute_collocation_points()&#96; function:\\\\n  - Distributes points across subdomains for XPINN\\\\n  - References undefined config variables: &#96;N_r_PER_SUBDOMAIN&#96; and &#96;N_0_PER_SUBDOMAIN&#96; (not in &#96;config.py&#96;)\\\\n  - Would raise &#96;NameError&#96; if called\\\\n  - Falls back to even distribution if those variables are None\\\\n\\\\n### 3. Training infrastructure (&#96;training/trainer.py&#96; and &#96;training/physics.py&#96;)\\\\n\\\\n#### Trainer module (Lines 1-5)\\\\n- Module docstring mentions \\\\\\\"XPINN decomposition training\\\\\\\"\\\\n- No actual XPINN training code remains\\\\n\\\\n#### Physics module (&#96;training/physics.py&#96;)\\\\n- No XPINN-specific loss computation\\\\n- Standard single-network closure functions (&#96;closure&#96;, &#96;closure_batched&#96;, &#96;closure_batched_cached&#96;)\\\\n- No interface/boundary stitching logic\\\\n\\\\n### 4. Loss computation structure (&#96;core/losses.py&#96;)\\\\n\\\\n#### PDE residual computation\\\\n- &#96;pde_residue()&#96; and &#96;pde_residue_standard()&#96; compute residuals for a single network\\\\n- No subdomain-specific loss functions\\\\n- No interface continuity enforcement\\\\n\\\\n#### Structure\\\\n- Standard PINN loss: IC loss + PDE residual loss\\\\n- No multi-network or interface loss terms\\\\n\\\\n### 5. Historical references (from &#96;.specstory&#96; history)\\\\n- Evidence of previous XPINN implementation that was removed\\\\n- Comments like \\\\\\\"XPINN removed - this function is now a no-op for compatibility\\\\\\\"\\\\n- References to interface stitching and boundary continuity enforcement\\\\n\\\\n### 6. Broken dependencies\\\\n\\\\n#### Critical issues\\\\n1. &#96;core/data_generator.py:274&#96;: Import from non-existent module\\\\n   &#96;&#96;&#96;python\\\\n   from methods.xpinn_decomposition import get_exterior_boundary_info\\\\n   &#96;&#96;&#96;\\\\n   This will fail if &#96;get_exterior_boundary_info()&#96; is called.\\\\n\\\\n2. &#96;core/data_generator.py:362-365&#96;: Undefined config variables\\\\n   &#96;&#96;&#96;python\\\\n   if n_total == N_r_PER_SUBDOMAIN and N_r_PER_SUBDOMAIN is not None:\\\\n   &#96;&#96;&#96;\\\\n   &#96;N_r_PER_SUBDOMAIN&#96; and &#96;N_0_PER_SUBDOMAIN&#96; are not defined in &#96;config.py&#96;.\\\\n\\\\n### 7. What exists vs what's missing\\\\n\\\\n#### Existing scaffolding\\\\n- Subdomain collocation point generation (&#96;geo_time_coord_subdomain&#96;)\\\\n- Function signature for exterior boundary detection (&#96;get_exterior_boundary_info&#96;)\\\\n- Collocation point distribution function (&#96;distribute_collocation_points&#96;)\\\\n- Empty &#96;methods/&#96; directory structure\\\\n\\\\n#### Missing components\\\\n- &#96;methods/xpinn_decomposition.py&#96; module (deleted)\\\\n- Multi-network training loop\\\\n- Interface/boundary continuity loss terms\\\\n- Subdomain boundary detection implementation\\\\n- Configuration variables (&#96;N_r_PER_SUBDOMAIN&#96;, &#96;N_0_PER_SUBDOMAIN&#96;, XPINN flags)\\\\n- Network initialization for multiple subdomains\\\\n- Interface point generation\\\\n- Boundary stitching logic\\\\n\\\\n### 8. File structure summary\\\\n\\\\n&#96;&#96;&#96;\\\\ncore/data_generator.py:\\\\n  - col_gen.geo_time_coord_subdomain() [WORKING - 2D only]\\\\n  - col_gen.get_exterior_boundary_info() [BROKEN - missing import]\\\\n  - distribute_collocation_points() [BROKEN - undefined config vars]\\\\n\\\\ncore/losses.py:\\\\n  - Standard single-network PDE residuals only\\\\n  - No interface/continuity losses\\\\n\\\\ntraining/trainer.py:\\\\n  - Standard single-network training loop\\\\n  - Docstring mentions XPINN but no implementation\\\\n\\\\ntraining/physics.py:\\\\n  - Standard closure functions\\\\n  - No multi-network support\\\\n\\\\nmethods/__init__.py:\\\\n  - Empty placeholder\\\\n\\\\nmethods/xpinn_decomposition.py:\\\\n  - DOES NOT EXIST (was deleted)\\\\n&#96;&#96;&#96;\\\\n\\\\n### 9. Recommendations for XPINN implementation\\\\n\\\\nTo implement XPINN, you would need to:\\\\n\\\\n1. Create &#96;methods/xpinn_decomposition.py&#96; with:\\\\n   - &#96;get_exterior_boundary_info()&#96; function\\\\n   - Subdomain boundary calculation utilities\\\\n   - Interface point generation\\\\n\\\\n2. Fix &#96;core/data_generator.py&#96;:\\\\n   - Remove broken import or implement the function locally\\\\n   - Add config variables or remove references to undefined ones\\\\n\\\\n3. Extend &#96;training/physics.py&#96;:\\\\n   - Add interface continuity loss computation\\\\n   - Add multi-network closure functions\\\\n\\\\n4. Extend &#96;training/trainer.py&#96;:\\\\n   - Add XPINN training loop that trains multiple networks\\\\n   - Handle interface loss terms\\\\n\\\\n5. Add to &#96;config.py&#96;:\\\\n   - XPINN enable flag\\\\n   - Number of subdomains (nx_sub, ny_sub)\\\\n   - Interface point counts\\\\n   - Interface loss weights\\\\n\\\\nThe existing scaffolding provides a starting point (subdomain collocation generation), but the implementation is incomplete and partially broken.\\\"}\"},\"status\":\"completed\",\"context\":{\"composers\":[],\"selectedCommits\":[],\"selectedPullRequests\":[],\"selectedImages\":[],\"folderSelections\":[],\"fileSelections\":[],\"selections\":[],\"terminalSelections\":[],\"selectedDocs\":[],\"externalLinks\":[],\"cursorRules\":[],\"cursorCommands\":[],\"gitPRDiffSelections\":[],\"subagentSelections\":[],\"browserSelections\":[],\"mentions\":{\"composers\":{},\"selectedCommits\":{},\"selectedPullRequests\":{},\"gitDiff\":[],\"gitDiffFromBranchToMain\":[],\"selectedImages\":{},\"folderSelections\":{},\"fileSelections\":{},\"terminalFiles\":{},\"selections\":{},\"terminalSelections\":{},\"selectedDocs\":{},\"externalLinks\":{},\"diffHistory\":[],\"cursorRules\":{},\"cursorCommands\":{},\"uiElementSelections\":[],\"consoleLogs\":[],\"ideEditorsState\":[],\"gitPRDiffSelections\":{},\"subagentSelections\":{},\"browserSelections\":{}}},\"generatingBubbleIds\":[],\"isReadingLongFile\":false,\"codeBlockData\":{},\"originalFileStates\":{},\"newlyCreatedFiles\":[],\"newlyCreatedFolders\":[],\"createdAt\":1770577193691,\"hasChangedContext\":false,\"activeTabsShouldBeReactive\":true,\"capabilities\":[{\"type\":30,\"data\":{}},{\"type\":15,\"data\":{\"bubbleDataMap\":\"{}\"}}],\"name\":\"Find XPINN references in codebase\",\"isFileListExpanded\":false,\"browserChipManuallyDisabled\":false,\"browserChipManuallyEnabled\":false,\"unifiedMode\":\"agent\",\"forceMode\":\"edit\",\"usageData\":{},\"allAttachedFileCodeChunksUris\":[],\"modelConfig\":{\"modelName\":\"composer-1\",\"maxMode\":false},\"subComposerIds\":[],\"capabilityContexts\":[],\"todos\":[],\"isQueueExpanded\":true,\"hasUnreadMessages\":false,\"gitHubPromptDismissed\":false,\"totalLinesAdded\":0,\"totalLinesRemoved\":0,\"addedFiles\":0,\"removedFiles\":0,\"isDraft\":false,\"isCreatingWorktree\":false,\"isApplyingWorktree\":false,\"isUndoingWorktree\":false,\"applied\":false,\"pendingCreateWorktree\":false,\"isBestOfNSubcomposer\":false,\"isBestOfNParent\":false,\"bestOfNJudgeWinner\":false,\"isSpec\":false,\"isProject\":false,\"isSpecSubagentDone\":false,\"stopHookLoopCount\":0,\"speculativeSummarizationEncryptionKey\":\"aYM7QRtY68nEXhyIMlxb5kArARzNwOCux2SVswfkhmM=\",\"isNAL\":true,\"planModeSuggestionUsed\":false,\"debugModeSuggestionUsed\":false,\"conversationState\":\"~\",\"queueItems\":[],\"isAgentic\":true}"
}
```
Result:

```json
{
  "agentId": "a9d33eec-ac30-40b6-bbdb-1fcced337dc9"
}
```
Status: **completed**


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I have a comprehensive understanding of the codebase. Let me provide a high-level qualitative discussion about implementing XPINN-style domain decomposition for this PINN project solving the Jeans instability problem.

Key considerations:
1. The physics: self-gravitating fluid dynamics with continuity, momentum, and Poisson equations
2. The domain: periodic boundaries, 1D/2D/3D support
3. The current architecture: single PINN with periodic embeddings, two-phase training (Adam + L-BFGS)
4. Existing scaffolding: partial subdomain collocation generation, broken references


5. The implementation strategy: I need to think through how to decompose the domain into overlapping subdomains, manage interface conditions between them, and coordinate the training across multiple neural networks.</details></think>

---

Now I have a thorough understanding of the codebase. Here's a high-level discussion of how XPINN-style domain decomposition could be implemented for your Jeans instability PINN solver.

---

## High-Level Plan for XPINN Domain Decomposition

### What XPINN Means for This Problem

The core idea of XPINN (Extended Physics-Informed Neural Networks) is to replace a single monolithic network with **multiple smaller networks**, each responsible for a subdomain of the spatiotemporal problem. The subdomains overlap (or share interfaces), and the networks are stitched together by enforcing **continuity conditions** at the interfaces. For your system -- continuity, momentum, and Poisson equations on a periodic domain -- this has some nuances worth thinking through.

### 1. Domain Decomposition Strategy

**Temporal vs. Spatial vs. Spatiotemporal decomposition:**

The most natural first choice is **temporal decomposition** -- splitting `[tmin, tmax]` into windows like `[0, 1]`, `[1, 2]`, `[2, 3]`. This is appealing because your system evolves in time and the PINN's biggest struggle is typically capturing long-time dynamics (which your `.specstory` history confirms). Temporal slicing lets each sub-network focus on a shorter time horizon where the solution is smoother and easier to learn.

Spatial decomposition (tiling the box in x, y, z) is also possible but more delicate here because of your **periodic boundary conditions**. The periodic embeddings (Fourier features) are baked into the model architecture and are designed for the full spatial domain. Splitting spatially would mean either (a) each sub-network loses the global periodic structure and you enforce periodicity through interface conditions at the domain edges, or (b) you keep periodic embeddings within each spatial tile, which is awkward if the tile doesn't correspond to a full wavelength.

**Recommendation:** Start with **temporal decomposition only**. It's conceptually cleaner, sidesteps the periodicity issue entirely, and directly attacks the hardest part of your problem (long-time accuracy). Spatial decomposition can be layered on later if needed.

### 2. Architecture: One Network Per Subdomain

Each temporal subdomain gets its own `PINN` instance -- same architecture (same number of layers, neurons, harmonics) but independent weights. So if you split time into 3 windows, you'd have 3 independent networks: `net_1`, `net_2`, `net_3`.

Each network maps `(x, [y, z], t)` -> `(rho, vx, [vy, vz], phi)` for its local time window. The spatial inputs span the full periodic domain; only the temporal input is restricted to the subdomain's window.

This is a clean extension of your current architecture. The `PINN` class doesn't need modification -- you just instantiate multiple copies. The key design question is whether they share any parameters (typically no in standard XPINN).

### 3. Collocation Point Generation

Your existing `ASTPN` class generates IC points at `t=0` and domain points over the full `[tmin, tmax]`. For XPINN, each sub-network needs:

- **Interior collocation points**: Sampled within its temporal window (e.g., `[t_k, t_{k+1}]`) across the full spatial domain. These are used for PDE residual enforcement, exactly as now.
- **IC points**: Only the first sub-network gets the true initial conditions at `t=0`. Subsequent sub-networks get their "initial conditions" from the interface stitching (see below).
- **Interface points**: Sampled at the temporal boundaries between adjacent subdomains (e.g., at `t=1.0` between window 1 and window 2). These are spatial points at a fixed time, used to enforce continuity.

The existing `geo_time_coord_subdomain()` scaffolding in `data_generator.py` was aimed at spatial decomposition. For temporal decomposition, the collocation generation is actually simpler -- you just restrict the time sampling range per sub-network. A new helper function could generate interface points as a grid or random sample over the spatial domain at a fixed time.

### 4. The Interface Loss -- The Critical Piece

This is where XPINN differs from just training separate PINNs. At each temporal interface `t = t_k`, two adjacent sub-networks (`net_k` and `net_{k+1}`) must agree. You enforce this via additional loss terms:

- **Solution continuity**: `|rho_k(x, t_k) - rho_{k+1}(x, t_k)|^2`, and similarly for `vx`, `vy`, `vz`, `phi`. Both networks are evaluated at the same interface points, and their outputs must match.
- **Flux/gradient continuity** (optional but recommended): `|d(rho_k)/dt(x, t_k) - d(rho_{k+1})/dt(x, t_k)|^2`, ensuring not just value matching but smooth derivative handoff. This prevents kinks at the interfaces.

For your system, you have 3 output fields in 1D (rho, vx, phi), 4 in 2D, 5 in 3D. Each field needs its own continuity enforcement at each interface. The **interface loss weight** is a hyperparameter that balances stitching quality against PDE accuracy -- too low and the solutions drift apart at interfaces, too high and it dominates the PDE loss.

**Poisson equation caveat:** The Poisson equation `nabla^2(phi) = const * (rho - rho_0)` is an elliptic constraint, not an evolution equation. It must hold at every time instant, including at interfaces. This is already part of the PDE residual, but it's worth noting that `phi` continuity at interfaces is especially important since Poisson relates to the global spatial structure of the density field.

### 5. Training Strategy

There are two main approaches:

**A. Sequential training (simpler, recommended first):**
1. Train `net_1` on `[t_0, t_1]` with the true IC at `t=0`. This is essentially the same as your current training, just on a shorter time window.
2. Freeze `net_1`. Use its predictions at `t=t_1` as the "initial condition" for `net_2` on `[t_1, t_2]`. Train `net_2` with IC loss against `net_1`'s output at the interface.
3. Repeat for subsequent windows.

This is sometimes called "time-marching PINN" or "bc-PINN". It's simple, avoids the complexity of simultaneous multi-network optimization, and directly leverages your existing training pipeline (Adam + L-BFGS). Each sub-network trains independently with a well-defined IC.

**Drawback:** Errors accumulate forward in time. If `net_1` is slightly wrong at `t_1`, that error propagates into `net_2`'s initial condition.

**B. Simultaneous/iterative training (full XPINN, more complex):**
1. All sub-networks train concurrently.
2. The total loss is the sum of each sub-network's PDE loss + IC loss (for the first one) + interface losses between all adjacent pairs.
3. Optimization alternates between sub-networks or uses a combined optimizer.

This is the "true" XPINN approach. It allows information to flow both forward and backward in time through the interface conditions, potentially giving better solutions. But it's harder to implement and tune -- you're optimizing multiple networks simultaneously with coupled losses.

**Practical recommendation:** Implement sequential first. It's a much smaller delta from your current code, and it will tell you immediately whether temporal decomposition helps. If it does, upgrading to simultaneous training is a natural next step.

### 6. How This Plugs into the Existing Codebase

The `methods/` folder is the right place for this. Here's a conceptual module layout:

- **`methods/xpinn.py`** (or `methods/temporal_decomposition.py`): The core logic -- subdomain definition, interface point generation, interface loss computation, and the multi-network training orchestrator.
- **`config.py` additions**: New config variables like `USE_XPINN`, `NUM_TIME_SUBDOMAINS`, `INTERFACE_LOSS_WEIGHT`, `N_INTERFACE_POINTS`, and `XPINN_TRAINING_MODE` (sequential vs. simultaneous).
- **`train.py` modification**: A branch that, when `USE_XPINN` is true, instantiates multiple `PINN` networks and delegates to the XPINN training orchestrator instead of the standard single-network trainer.
- **`training/physics.py` extension**: A new closure function (or a wrapper around the existing one) that includes the interface loss terms in addition to the standard PDE + IC losses.
- **`core/losses.py` extension**: An `interface_loss()` function that computes the continuity mismatch between two networks at shared interface points.

The key architectural insight is that the PINN model itself (`core/model_architecture.py`) **does not need to change**. The decomposition is entirely an outer-loop concern -- how you partition the problem, generate points, compute losses, and train. The model is just a function approximator that doesn't care whether it's covering the full domain or a subdomain.

### 7. Density Parameterization Consideration

Your model uses a density parameterization (`rho = rho_0 * exp(t_eff * rho_hat)`) with a `STARTUP_DT` causality delay for power spectrum perturbations. In a temporal decomposition setting, only the **first** sub-network needs this startup behavior. Subsequent sub-networks start from a non-trivial state (the previous network's output) and don't need the startup delay. This needs careful handling -- the density parameterization logic may need to be made subdomain-aware, or simply disabled for sub-networks beyond the first.

### 8. Diagnostics and Evaluation

Your existing diagnostics (residual heatmaps, conservation checks, spectral analysis) would need to stitch together the outputs from all sub-networks to produce a unified view. This is straightforward -- at evaluation time, for any query point `(x, t)`, you just route it to the appropriate sub-network based on which time window `t` falls into. A thin wrapper that dispatches queries to the correct network would let all existing visualization code work unchanged.

### 9. What to Test and How to Know It's Working

- **Baseline comparison**: Train a single PINN on `[0, 3]` as you do now. Then train with 3 temporal subdomains. Compare PDE residuals, conservation violations, and agreement with the LAX finite-difference solver.
- **Interface quality**: Plot the solution fields at interface times and check for discontinuities. Measure the interface loss separately to see how well the networks agree.
- **Scaling**: Try different numbers of subdomains (2, 3, 5, 10) and see how accuracy vs. total training cost scales.
- **Long-time benefit**: The main hypothesis is that XPINN helps with long-time accuracy. Specifically check whether the power spectrum evolution at late times improves.

### Summary

The cleanest path forward is:

1. **Temporal decomposition only** (avoids periodic BC complications)
2. **Sequential training first** (minimal code changes, validates the concept)
3. **Same model architecture**, just multiple instances
4. **Interface losses** enforcing value (and optionally gradient) continuity between adjacent time windows
5. **Methods folder** houses the decomposition logic, with config flags to toggle it on/off
6. **Existing training/visualization infrastructure** largely reusable with minor wrappers

This approach is incremental -- each step is testable on its own, and you don't have to build the full simultaneous XPINN machinery before seeing whether domain decomposition helps your problem.

---

_**User**_

As you mentioned, the "true" XPINN approach is much more complex to implement. But apart from that, how much complex is it to run? by complex I mean how much more resources it needs (like memory or time etc)?

---

_**Agent (model claude-4.6-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is asking about the computational complexity/resource requirements of the "true" simultaneous XPINN approach (not the sequential one) - specifically memory and time costs compared to single-network training.

This is a good question about practical implementation considerations. Let me think through the resource implications:

1. **Memory costs**
2. **Time/compute costs**
3. **Trade-offs**

I should be specific and quantitative where possible, relating it to their existing setup.</details></think>

---

Great question -- this gets at the practical feasibility of the approach. Let me break down the resource implications of the "true" simultaneous XPINN approach:

## Memory Requirements

**The good news:** Memory scales almost linearly with the number of subdomains, but with smart implementation, it's manageable.

**Network parameters:**
- If you split into N subdomains, you have N independent networks, so **N times the parameters**.
- Your current model is relatively small (default: 5 layers Ã— 64 neurons). Even with periodic embeddings and multi-branch architecture, a single network is probably ~50-100K parameters. With 3 subdomains, that's 150-300K parameters total -- still tiny by modern standards. Even 10 subdomains would be ~1M parameters, which fits easily on any GPU you'd use for training.

**Collocation points:**
- Here's where it gets interesting. In your current setup, you sample `N_r` domain points and `N_0` IC points across the entire spatiotemporal domain.
- For XPINN, you have two options:
  
  **Option A (naive):** Sample `N_r` points *per subdomain* â†’ N times more collocation points total â†’ N times more memory for gradients.
  
  **Option B (smart):** Keep total `N_r` constant and *distribute* it across subdomains (e.g., `N_r/N` points per subdomain). Each subdomain covers a smaller region, so it arguably needs fewer points. Plus you add `N_interface` points at each of the `N-1` interfaces.

Your existing `distribute_collocation_points()` function suggests you were thinking along the lines of Option B. This means **memory for collocation points is roughly constant**, just reorganized.

**Gradient computation:**
- During backpropagation, you need gradients for all N networks simultaneously (in the simultaneous training approach).
- With your batched training setup (`NUM_BATCHES` with gradient accumulation), you can process one subdomain's batch at a time and accumulate gradients. This keeps peak memory similar to single-network training.
- The **interface loss computation** is the added cost -- you need to evaluate two networks at interface points and compute their derivatives. But interface points are typically much fewer than domain points (say, 1000-5000 spatial points at each interface vs. 100K-1M domain points total).

**Practical estimate:** If your current training uses, say, 2-4 GB GPU memory, simultaneous XPINN with 3-5 temporal subdomains would likely use **3-8 GB** -- scaling roughly linearly but staying within the capacity of a typical research GPU (8-16 GB).

## Time/Compute Requirements

This is more complex and has several counteracting factors:

**Cost increases:**
1. **More forward passes:** Evaluating N networks instead of 1 means N times the forward pass cost per iteration. If you're computing PDE residuals, that means N times the automatic differentiation cost as well.

2. **Interface loss:** Each interface requires evaluating two networks and computing continuity losses. With `N-1` interfaces and, say, 5000 points per interface, this adds maybe 5-10% overhead for a 3-subdomain case.

3. **Optimizer overhead:** Some optimizers (especially L-BFGS) need to store histories. With N networks, you have N optimizer states. Your current L-BFGS probably stores ~20-50 past gradients -- multiply that by N.

**Cost decreases (the crucial part):**
1. **Each subdomain is easier to learn:** This is the whole point. A network learning dynamics on `[0, 1]` instead of `[0, 3]` has an easier job. The solution is smoother over a shorter time window. This typically means **faster convergence** -- fewer iterations to reach the same accuracy.

2. **Better conditioning:** PINNs often struggle because the loss landscape is rough when the solution varies rapidly over the domain. Subdomains have gentler loss landscapes, which can mean the optimizer takes fewer steps and experiences less stalling.

3. **Potential for lower total collocation count:** If you can get away with fewer points per subdomain (Option B above), the cost per iteration actually *decreases*.

**Net effect -- highly problem-dependent:**
- In the **worst case** (each subdomain needs as many iterations as the original, and no speedup from easier learning), you'd pay **NÃ— the wall-clock time** per epoch, and if convergence speed is the same, total training time is **NÃ— longer**.
  
- In **realistic scenarios** from the XPINN literature, the convergence speedup often partially or fully compensates for the added cost. For problems with long-time evolution (like yours), temporal decomposition can mean each subdomain converges in **1/2 to 1/3 the iterations** of the monolithic approach. Combined with N times more networks, this means **1.5Ã— to 3Ã— total training time** for, say, N=3 subdomains -- not a full 3Ã— penalty.

- If you use **sequential training** instead of simultaneous, the story changes entirely. Each subdomain trains independently, so wall-clock time is just the sum of training times for N smaller problems. Typically this ends up being **similar or slightly longer** than single-network training, because you train N times but each converges faster. The bigger issue with sequential is error accumulation, not cost.

## Parallelization Opportunities

One big advantage: **subdomain networks can be trained on separate GPUs** (or even machines) in the simultaneous approach. The interface loss couples them, so you need to synchronize gradients, but this is standard in distributed training. If you have access to multiple GPUs, you can train a 3-subdomain XPINN in roughly **the same wall-clock time** as a single network (modulo communication overhead and the need for more total iterations).

For sequential training, parallelization is even easier -- each subdomain is completely independent during its training phase, so no synchronization needed.

## Practical Recommendation for Your Setup

Given your existing config (`iteration_adam_2D = 30000`, `iteration_lbfgs_2D = 5000` for 2D), let's estimate:

- **Current training time:** Let's say ~30 minutes for Adam + 20 minutes for L-BFGS = 50 minutes total for a 2D run (rough guess based on typical PINN training).

- **Simultaneous XPINN with 3 temporal subdomains:**
  - **Memory:** 3Ã— networks, but you're still well under typical GPU limits. Likely 4-6 GB on a modern GPU.
  - **Time per iteration:** ~3Ã— slower (3 networks to evaluate).
  - **Convergence speed:** Probably **2-2.5Ã— fewer iterations needed** per subdomain (shorter time windows are easier).
  - **Net training time:** 3Ã— / 2.5Ã— â‰ˆ **1.2-1.5Ã— longer**, so ~60-75 minutes instead of 50 minutes.
  - **Plus implementation complexity:** The code is harder to write, debug, and tune.

- **Sequential XPINN with 3 temporal subdomains:**
  - **Memory:** Only 1 network at a time, so **same as current**.
  - **Time per subdomain:** Maybe **40-50% of original** (shorter, easier problem). So 20-25 minutes per subdomain.
  - **Total time:** 3 Ã— 25 minutes = **75 minutes** (1.5Ã— longer).
  - **Implementation complexity:** Much simpler -- minimal changes to existing code.

## Bottom Line

The "true" simultaneous XPINN is **not prohibitively expensive** computationally -- you're looking at maybe **1.5-2Ã— the training time and memory** for modest subdomain counts (3-5), assuming the convergence speedup kicks in. The bigger barrier is **implementation complexity and hyperparameter tuning** (interface loss weight, subdomain overlap, etc.).

The sequential approach is the sweet spot for your situation: **minimal added resource cost** (maybe 1.5Ã— wall-clock time, same memory), **much simpler to implement**, and you get most of the benefit (focused learning on shorter time windows). The main risk is error accumulation across interfaces, but that's something you can measure empirically.

If sequential works well, upgrading to simultaneous becomes a refinement step, not a necessity.

---

_**User**_

Can the training be made truly parallelizable? I have zero idea on parallelization, but have heard lbfgs creates problems in doing that (and I need lbfgs, adam is just pretraining, main training happens through lbfgs)

---

_**Agent (model claude-4.6-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is asking about parallelizing the XPINN training, specifically with L-BFGS as the primary optimizer. This is a great question because L-BFGS does have fundamental properties that make parallelization tricky. Let me think through this carefully.

Key points to address:
1. Why L-BFGS is inherently sequential (line search, curvature updates)
2. Whether XPINN subdomains can be parallelized despite L-BFGS
3. The distinction between data parallelism and model/task parallelism
4. Practical options for their setup

Let me think about this carefully:

**L-BFGS and parallelism:**


L-BFGS maintains a running approximation of the inverse Hessian using gradient and parameter history, and each iteration requires computing a gradient, determining a search direction from that history, performing a line search with multiple sequential loss evaluations, and updating the history. The line search is the bottleneckâ€”it needs to evaluate the loss at different step sizes sequentially, where each evaluation depends on the previous result. While the gradient computation itself can be parallelized across data, the line search steps can't be overlapped.

Now with XPINN, the challenge is different. Sequential XPINN trains subdomains one after another with no parallelism, but simultaneous XPINN couples subdomains through interface losses. If I use a single shared L-BFGS optimizer across all subdomains' parameters, it's just one massive optimization problem with the same sequential bottleneck. If each subdomain gets its own L-BFGS optimizer, they could theoretically run in parallel, but the interface loss couples themâ€”so the question becomes whether that coupling breaks the parallelism advantage.

One approach is block coordinate descent: freeze other networks and optimize one subdomain's L-BFGS at a time, then switch. Another is Jacobi-style updates: evaluate interface losses with frozen neighbor parameters, run L-BFGS independently on each subdomain, then synchronize. But there's a practical issue with PyTorch's L-BFGS implementationâ€”it calls the closure function multiple times per step for line search, and those evaluations are inherently sequential.

The real insight is that XPINN parallelism isn't about parallelizing a single L-BFGS run, but rather running multiple independent L-BFGS optimizations simultaneously on different GPUs, one per subdomain, with coupling handled through alternating or Schwarz-like iterations. Adam might actually be better suited for this since it has no line search overhead and doesn't have the same sequential dependencies, which is why some people use it for XPINN. There are also research-level parallel variants like P-LBFGS, but they're not standard.

So the architecture would be: each subdomain gets its own L-BFGS optimizer that runs sequentially on a single GPU, but multiple subdomains train in parallel across different GPUs, with outer iterations syncing the interface conditions between them. The line search within each subdomain is inherently sequential, but that's unavoidable regardless of the XPINN setup.

The key distinction is that this is task parallelismâ€”different subdomains solving independently on different hardwareâ€”not data parallelism within a single optimization, which is where L-BFGS struggles. This approach is actually quite compatible with L-BFGS.</details></think>

---

This is an important question, and your instinct about L-BFGS being problematic for parallelism is correct -- but the reasons are specific and worth understanding, because the picture isn't entirely bleak.

## Why L-BFGS Resists Parallelism

L-BFGS has two properties that make it fundamentally sequential:

**1. The line search is serial.**
Each L-BFGS step goes: compute gradient â†’ compute search direction (from curvature history) â†’ line search along that direction. The line search evaluates the loss at multiple trial step sizes to find a good one (your code uses Strong Wolfe conditions). Each trial evaluation depends on the outcome of the previous trial -- you can't pre-compute them in parallel. This is why your `closure_batched_cached` gets called multiple times per L-BFGS step.

**2. Step k+1 depends entirely on step k.**
L-BFGS maintains a rolling history of past gradient differences and parameter changes (typically the last 10-20 steps). This history determines the search direction for the next step. You cannot start computing step k+1 until step k is fully complete -- there's no way to "pipeline" steps the way you might with simpler methods.

**Contrast with Adam:** Adam's update rule is essentially `params -= lr * m_hat / (sqrt(v_hat) + eps)`. Each parameter's update depends only on its own gradient and running statistics. There's no line search, no global curvature information, no inter-step dependency beyond the momentum terms. That's why Adam is trivially parallelizable.

## Two Different Kinds of Parallelism

This is a crucial distinction that often gets conflated:

**Data parallelism** = splitting a single network's collocation points across multiple GPUs to compute the gradient faster. Each GPU evaluates PDE residuals on a subset of points, then gradients are averaged.

**Task parallelism** = putting different subdomain networks on different GPUs, each training semi-independently.

L-BFGS has problems with **data parallelism** -- the line search needs to evaluate the *total* loss (across all data) at each trial point. You can distribute the loss computation across GPUs, but you still need to synchronize after every trial evaluation, and the number of trials is unpredictable. The communication overhead often kills the speedup, especially for PINN training where the "batch" computation (PDE residuals with autograd) is already fast per-point.

But **task parallelism** -- the XPINN kind -- is a different story.

## How XPINN Parallelism Actually Works with L-BFGS

The key insight: in XPINN, each subdomain has its **own independent L-BFGS optimizer** operating on its own network's parameters. The subdomains are coupled only through the interface loss. This opens the door to an **alternating optimization** or **Schwarz iteration** scheme:

**Outer loop** (Schwarz-like iterations):
1. Freeze the interface information (neighboring networks' outputs at interface points).
2. **Inner loop (parallel):** Each subdomain runs its own L-BFGS optimization independently, using the frozen neighbor values for the interface loss. Each subdomain runs on its own GPU (or sequentially on one GPU if that's all you have).
3. **Sync step:** After inner optimization converges (or runs for a fixed number of steps), exchange updated interface values between neighbors.
4. Repeat the outer loop until the global solution stabilizes.

Within each subdomain, L-BFGS runs exactly as it does now -- fully sequential line search, curvature history, everything. That's fine. The parallelism comes from multiple subdomains running their own L-BFGS simultaneously, not from parallelizing a single L-BFGS.

**This is genuinely parallel.** If you have 3 subdomains and 3 GPUs, each GPU runs its own L-BFGS on its own subdomain, and they only need to talk to each other at the sync step.

## The Catch: Convergence of the Outer Loop

The Schwarz outer loop adds a new convergence concern. When subdomain 1 optimizes with frozen interface values from subdomain 2, it finds a solution that's optimal *given those frozen values*. But then subdomain 2 updates, changing the interface values, so subdomain 1's solution is no longer optimal. You iterate back and forth until everyone agrees.

This outer loop:
- **Usually converges** for well-posed problems, especially with temporal decomposition where information flows naturally forward in time.
- **Convergence speed** depends on how strongly coupled the subdomains are. Weak coupling (small interface loss weight, mostly independent dynamics in each window) â†’ fast convergence (3-10 outer iterations). Strong coupling â†’ slower convergence, potentially defeating the purpose.
- **Is not guaranteed** to converge in general, especially if the interface loss weight is poorly chosen or if the physics has strong global coupling.

For your Jeans instability problem, the temporal coupling is causal (the future depends on the past, not vice versa), which is favorable for Schwarz convergence.

## What This Means Practically

**Single GPU (your likely setup):**
Even on one GPU, the Schwarz approach has value -- not for wall-clock parallelism, but for optimization quality. Each subdomain's L-BFGS operates on a smaller, better-conditioned problem. L-BFGS is highly sensitive to the conditioning of the loss landscape, and a single network trying to represent the solution over a long time interval creates a poorly conditioned landscape that L-BFGS struggles with. Smaller subdomains â†’ better conditioned â†’ L-BFGS converges faster and to better minima per subdomain.

On a single GPU, you'd train subdomains sequentially within each outer iteration. The outer loop adds overhead, but each inner L-BFGS solve is faster.

**Multiple GPUs:**
True parallelism. Each GPU handles one subdomain. The sync step is cheap (just exchanging network predictions at a few thousand interface points). The wall-clock time per outer iteration is determined by the slowest subdomain.

**The honest answer about L-BFGS:**
L-BFGS doesn't prevent XPINN parallelism -- it just means the parallelism operates at the subdomain level (task parallelism), not within a single subdomain's optimization. The line search remains sequential *within each subdomain*, but that's fine because each subdomain's problem is smaller. The real question isn't "can I parallelize L-BFGS?" but rather "does decomposition make each L-BFGS solve easier enough to justify the Schwarz overhead?" For temporal decomposition of long-time evolution problems, the answer from the literature is generally yes.

## A Pragmatic Middle Ground

If you're worried about the Schwarz convergence complexity, there's a hybrid that leverages L-BFGS while avoiding the outer loop entirely:

1. **Adam phase (simultaneous, all subdomains):** Train all networks together with Adam, including interface losses. Adam handles the coupling naturally since it doesn't need a line search. This gets you into the right neighborhood.
2. **L-BFGS phase (sequential, per subdomain):** Freeze all networks except one. Polish each subdomain with L-BFGS one at a time, using frozen neighbors for interface conditions. Cycle through subdomains a few times.

This uses Adam for what it's good at (rough, coupled, parallel-friendly optimization) and L-BFGS for what it's good at (precise, per-subdomain polishing). It's essentially what your current two-phase training already does, just extended to multiple networks. And the L-BFGS polishing step is trivially parallelizable across GPUs since each subdomain is independent during its polish phase.

---

_**User**_

I am not sure I understand everything you said, but give me a high level plan overview to start working on. I hope my intentions are clear are you; I can start slow and test "simpler" versions, but one day I would like to test "proper" XPINN. If you do recommend to start from a simpler approach, just give a plan to follow to implement that so that I can keep track. No need of any codes, just a descriptive plan to follow

---

_**Agent (model claude-4.6-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user wants a clear, staged implementation plan that starts simple and builds toward full XPINN. They want it as a roadmap they can follow step by step, with each stage being testable on its own. Let me structure this as a phased plan that's easy to track.</details></think>

---

Here's a phased roadmap. Each phase is self-contained and testable before moving to the next. You never throw away work -- each phase builds on the previous one.

---

## Phase 0: Cleanup and Baseline

Before building anything new, fix the broken scaffolding from the previous attempt.

- Remove the dead references in `data_generator.py` (the broken import from `methods.xpinn_decomposition`, the undefined config variables `N_r_PER_SUBDOMAIN` / `N_0_PER_SUBDOMAIN`, and the unused `distribute_collocation_points` and `get_exterior_boundary_info` functions). These will be rewritten properly later. The `geo_time_coord_subdomain` function can also go since it was for spatial decomposition and you'll be doing temporal decomposition instead.
- Run a clean baseline training on your standard test case (say, 2D sinusoidal perturbation, `tmax=3`). Save the results -- loss curves, PDE residuals, agreement with the LAX solver. This is your benchmark to beat.

---

## Phase 1: Sequential Time-Marching (The Simplest Version)

**Goal:** Split the time domain into windows and train one network per window, sequentially. No simultaneous training, no Schwarz iterations. Just "train window 1, use its output as IC for window 2, train window 2, repeat."

**Step 1 -- Config additions:**
Add a few new config variables: a flag to enable time-marching, the number of time subdomains, and the number of interface points. Keep it minimal. Everything else (network size, optimizer settings, collocation counts) stays the same per subdomain.

**Step 2 -- Time window manager:**
Write a small utility (in `methods/`) that takes `tmin`, `tmax`, and the number of subdomains, and returns a list of time windows. For example, 3 subdomains on `[0, 3]` gives `[(0, 1), (1, 2), (2, 3)]`. This is trivial but having it as a proper function keeps things clean.

**Step 3 -- Modify collocation generation:**
For each time window, generate collocation points restricted to that window's time range. IC points for the first window come from the true initial conditions (as now). IC points for subsequent windows come from the previous network's predictions at the interface time. Domain points are sampled uniformly within the window's time range.

**Step 4 -- Training loop wrapper:**
Write a loop that iterates over time windows. For each window: instantiate a fresh `PINN`, generate collocation points for that window, train with your existing Adam + L-BFGS pipeline (the existing `trainer.py` code), save the trained model. For the second window onward, the "true IC" used in the IC loss is obtained by evaluating the previous window's frozen network at the interface time.

**Step 5 -- Evaluation stitcher:**
Write a thin wrapper that, given a query point `(x, t)`, routes it to the correct subdomain network based on which time window `t` falls into. Plug this into your existing visualization and comparison code so you can generate plots and animations across the full time domain as if it were a single model.

**Step 6 -- Test and compare:**
Run the same test case as Phase 0. Compare loss, residuals, and LAX agreement. Pay special attention to the interface times -- plot the solution fields at `t=1` and `t=2` and check for visible discontinuities. Also check whether late-time accuracy improved (this is the main hypothesis).

**What you learn:** Does temporal decomposition help at all? Is the interface handoff clean? How sensitive is it to the number of subdomains?

---

## Phase 2: Interface Loss (Soft Stitching)

**Goal:** Instead of just using the previous network's output as a hard IC, add a loss term that encourages continuity at the interface. This is still sequential training, but with better stitching quality.

**Step 1 -- Interface loss function:**
Write a function (in `methods/` or `core/losses.py`) that takes two networks and a set of interface points, evaluates both networks at those points, and returns the MSE of their output differences. This covers all fields: density, velocities, and potential.

**Step 2 -- Integrate into training:**
When training window k (for k > 1), the loss becomes: PDE residual loss + IC loss (from previous network's predictions) + interface continuity loss (difference between current network and previous network at the interface). The previous network is frozen. Add a config variable for the interface loss weight.

**Step 3 -- Optional gradient continuity:**
Add a second interface term: the MSE of the time-derivative differences between the two networks at the interface. This enforces not just value matching but smooth derivative handoff. This is more expensive (requires computing `d/dt` of both networks at interface points) but improves stitching quality. Make it toggleable.

**Step 4 -- Test and compare:**
Same test case. Compare against Phase 1 results. The interface discontinuities should be smaller. Check whether the added loss term causes any training instability or significantly changes convergence speed.

**What you learn:** How much does explicit interface enforcement help over the naive handoff? What interface loss weight works well?

---

## Phase 3: Iterative Refinement (Schwarz-Style Outer Loop)

**Goal:** After sequential training, cycle back through the subdomains and retrain each one using updated neighbor information. This lets information flow backward in time (later windows influencing earlier ones) without full simultaneous training.

**Step 1 -- Outer iteration loop:**
Wrap the Phase 2 sequential training in an outer loop. In the first pass, train windows 1 â†’ 2 â†’ 3 sequentially (exactly as Phase 2). In subsequent passes, retrain each window using the *updated* neighboring networks from the previous pass. Window 1 uses window 2's current output at their interface; window 2 uses both window 1 and window 3's outputs.

**Step 2 -- Warm-starting:**
When retraining a subdomain in a later outer iteration, don't start from scratch. Load the network weights from the previous outer iteration and continue training (fewer iterations needed since it's already close). Add a config variable for the number of Adam/L-BFGS iterations in refinement passes (typically much less than the initial pass).

**Step 3 -- Convergence monitoring:**
Track the interface mismatch across outer iterations. When the interface loss stops decreasing meaningfully, stop the outer loop. Add a tolerance parameter.

**Step 4 -- Test and compare:**
Compare against Phase 2. The main question: does backward information flow (later windows correcting earlier ones) improve the solution? Especially relevant if Phase 2 showed error accumulation.

**What you learn:** How many outer iterations are needed? Does the Schwarz iteration converge reliably? Is the improvement worth the extra compute?

---

## Phase 4: Full Simultaneous XPINN

**Goal:** Train all subdomain networks at the same time, with a combined loss that includes all PDE residuals and all interface terms. This is the "true" XPINN.

**Step 1 -- Combined

---

